{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bb514a1",
   "metadata": {},
   "source": [
    "# AgriGuru Agricultural AI Agent Training in Google Colab\n",
    "\n",
    "## Overview\n",
    "This notebook provides a complete training pipeline for the AgriGuru agricultural AI agent, featuring:\n",
    "- Plant disease classification using EfficientNet\n",
    "- Weather integration for crop recommendations\n",
    "- Custom agricultural response system\n",
    "- MongoDB integration for user data\n",
    "- Model deployment preparation\n",
    "\n",
    "## Plant Disease Classes\n",
    "The model will be trained to classify:\n",
    "1. Healthy plant\n",
    "2. Bacterial leaf blight\n",
    "3. Leaf spot\n",
    "4. Brown rust\n",
    "5. Yellow rust\n",
    "6. Powdery mildew\n",
    "7. Nitrogen deficiency\n",
    "8. Phosphorus deficiency\n",
    "9. Potassium deficiency\n",
    "10. Water stress\n",
    "\n",
    "## Prerequisites\n",
    "- Google Colab Pro (recommended for GPU/TPU access)\n",
    "- Google Drive account for model storage\n",
    "- Basic knowledge of PyTorch and agricultural concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8015f185",
   "metadata": {},
   "source": [
    "# 1. Setup Environment and Install Dependencies\n",
    "\n",
    "First, we'll install all required packages for training the agricultural AI agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0d07a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Collecting torch\n",
      "  Downloading https://download.pytorch.org/whl/cu118/torch-2.7.1%2Bcu118-cp313-cp313-win_amd64.whl.metadata (27 kB)\n",
      "Collecting torchvision\n",
      "  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.22.1%2Bcu118-cp313-cp313-win_amd64.whl.metadata (6.3 kB)\n",
      "Collecting torchaudio\n",
      "  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.7.1%2Bcu118-cp313-cp313-win_amd64.whl.metadata (6.8 kB)\n",
      "Collecting filelock (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/filelock-3.13.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting typing-extensions>=4.10.0 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting sympy>=1.13.3 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/sympy-1.13.3-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/networkx-3.3-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting jinja2 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/Jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting fsspec (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/fsspec-2024.6.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting setuptools (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/setuptools-70.2.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting numpy (from torchvision)\n",
      "  Downloading https://download.pytorch.org/whl/numpy-2.1.2-cp313-cp313-win_amd64.whl.metadata (59 kB)\n",
      "Collecting pillow!=8.3.*,>=5.3.0 (from torchvision)\n",
      "  Downloading https://download.pytorch.org/whl/pillow-11.0.0-cp313-cp313-win_amd64.whl.metadata (9.3 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch)\n",
      "  Downloading https://download.pytorch.org/whl/mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "     ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "     ------------------- -------------------- 262.1/536.2 kB ? eta -:--:--\n",
      "     -------------------------------------- 536.2/536.2 kB 2.1 MB/s eta 0:00:00\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch)\n",
      "  Downloading https://download.pytorch.org/whl/MarkupSafe-2.1.5.tar.gz (19 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Downloading https://download.pytorch.org/whl/cu118/torch-2.7.1%2Bcu118-cp313-cp313-win_amd64.whl (2817.2 MB)\n",
      "   ---------------------------------------- 0.0/2.8 GB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.8 GB 12.9 MB/s eta 0:03:38\n",
      "   ---------------------------------------- 0.0/2.8 GB 3.9 MB/s eta 0:12:06\n",
      "   ---------------------------------------- 0.0/2.8 GB 4.7 MB/s eta 0:10:01\n",
      "   ---------------------------------------- 0.0/2.8 GB 5.3 MB/s eta 0:08:49\n",
      "   ---------------------------------------- 0.0/2.8 GB 6.2 MB/s eta 0:07:31\n",
      "   ---------------------------------------- 0.0/2.8 GB 6.4 MB/s eta 0:07:20\n",
      "   ---------------------------------------- 0.0/2.8 GB 6.8 MB/s eta 0:06:51\n",
      "   ---------------------------------------- 0.0/2.8 GB 7.1 MB/s eta 0:06:38\n",
      "   ---------------------------------------- 0.0/2.8 GB 7.2 MB/s eta 0:06:29\n",
      "   ---------------------------------------- 0.0/2.8 GB 6.8 MB/s eta 0:06:52\n",
      "   ---------------------------------------- 0.0/2.8 GB 6.5 MB/s eta 0:07:11\n",
      "   ---------------------------------------- 0.0/2.8 GB 6.0 MB/s eta 0:07:47\n",
      "   ---------------------------------------- 0.0/2.8 GB 5.8 MB/s eta 0:08:03\n",
      "   ---------------------------------------- 0.0/2.8 GB 5.8 MB/s eta 0:08:04\n",
      "   ---------------------------------------- 0.0/2.8 GB 5.9 MB/s eta 0:07:57\n",
      "   ---------------------------------------- 0.0/2.8 GB 5.9 MB/s eta 0:07:57\n",
      "   ---------------------------------------- 0.0/2.8 GB 5.6 MB/s eta 0:08:22\n",
      "   ---------------------------------------- 0.0/2.8 GB 5.4 MB/s eta 0:08:39\n",
      "   ---------------------------------------- 0.0/2.8 GB 5.3 MB/s eta 0:08:45\n",
      "   ---------------------------------------- 0.0/2.8 GB 5.4 MB/s eta 0:08:35\n",
      "   ---------------------------------------- 0.0/2.8 GB 5.6 MB/s eta 0:08:21\n",
      "   ---------------------------------------- 0.0/2.8 GB 5.7 MB/s eta 0:08:09\n",
      "   ---------------------------------------- 0.0/2.8 GB 5.9 MB/s eta 0:07:52\n",
      "   ---------------------------------------- 0.0/2.8 GB 6.3 MB/s eta 0:07:25\n",
      "   ---------------------------------------- 0.0/2.8 GB 6.3 MB/s eta 0:07:20\n",
      "   ---------------------------------------- 0.0/2.8 GB 6.5 MB/s eta 0:07:10\n",
      "    --------------------------------------- 0.0/2.8 GB 6.6 MB/s eta 0:07:01\n",
      "    --------------------------------------- 0.0/2.8 GB 6.7 MB/s eta 0:06:58\n",
      "    --------------------------------------- 0.0/2.8 GB 6.8 MB/s eta 0:06:46\n",
      "    --------------------------------------- 0.0/2.8 GB 6.9 MB/s eta 0:06:40\n",
      "    --------------------------------------- 0.0/2.8 GB 7.0 MB/s eta 0:06:37\n",
      "    --------------------------------------- 0.0/2.8 GB 7.1 MB/s eta 0:06:30\n",
      "    --------------------------------------- 0.1/2.8 GB 7.3 MB/s eta 0:06:20\n",
      "    --------------------------------------- 0.1/2.8 GB 7.4 MB/s eta 0:06:16\n",
      "    --------------------------------------- 0.1/2.8 GB 7.4 MB/s eta 0:06:12\n",
      "    --------------------------------------- 0.1/2.8 GB 7.4 MB/s eta 0:06:13\n",
      "    --------------------------------------- 0.1/2.8 GB 7.5 MB/s eta 0:06:09\n",
      "    --------------------------------------- 0.1/2.8 GB 7.7 MB/s eta 0:06:00\n",
      "    --------------------------------------- 0.1/2.8 GB 7.6 MB/s eta 0:06:01\n",
      "    --------------------------------------- 0.1/2.8 GB 7.6 MB/s eta 0:06:00\n",
      "    --------------------------------------- 0.1/2.8 GB 7.6 MB/s eta 0:06:01\n",
      "    --------------------------------------- 0.1/2.8 GB 7.6 MB/s eta 0:06:03\n",
      "    --------------------------------------- 0.1/2.8 GB 7.5 MB/s eta 0:06:07\n",
      "    --------------------------------------- 0.1/2.8 GB 7.4 MB/s eta 0:06:10\n",
      "    --------------------------------------- 0.1/2.8 GB 7.4 MB/s eta 0:06:10\n",
      "   - -------------------------------------- 0.1/2.8 GB 7.3 MB/s eta 0:06:16\n",
      "   - -------------------------------------- 0.1/2.8 GB 7.3 MB/s eta 0:06:17\n",
      "   - -------------------------------------- 0.1/2.8 GB 7.2 MB/s eta 0:06:19\n",
      "   - -------------------------------------- 0.1/2.8 GB 7.2 MB/s eta 0:06:21\n",
      "   - -------------------------------------- 0.1/2.8 GB 7.2 MB/s eta 0:06:23\n",
      "   - -------------------------------------- 0.1/2.8 GB 7.2 MB/s eta 0:06:23\n",
      "   - -------------------------------------- 0.1/2.8 GB 7.2 MB/s eta 0:06:23\n",
      "   - -------------------------------------- 0.1/2.8 GB 7.2 MB/s eta 0:06:23\n",
      "   - -------------------------------------- 0.1/2.8 GB 7.2 MB/s eta 0:06:23\n",
      "   - -------------------------------------- 0.1/2.8 GB 7.2 MB/s eta 0:06:23\n",
      "   - -------------------------------------- 0.1/2.8 GB 7.2 MB/s eta 0:06:23\n",
      "   - -------------------------------------- 0.1/2.8 GB 6.2 MB/s eta 0:07:23\n",
      "   - -------------------------------------- 0.1/2.8 GB 6.2 MB/s eta 0:07:22\n",
      "   - -------------------------------------- 0.1/2.8 GB 6.2 MB/s eta 0:07:19\n",
      "   - -------------------------------------- 0.1/2.8 GB 6.3 MB/s eta 0:07:12\n",
      "   - -------------------------------------- 0.1/2.8 GB 6.4 MB/s eta 0:07:09\n",
      "   - -------------------------------------- 0.1/2.8 GB 6.4 MB/s eta 0:07:07\n",
      "   - -------------------------------------- 0.1/2.8 GB 6.4 MB/s eta 0:07:05\n",
      "   - -------------------------------------- 0.1/2.8 GB 6.4 MB/s eta 0:07:10\n",
      "   - -------------------------------------- 0.1/2.8 GB 6.4 MB/s eta 0:07:07\n",
      "   - -------------------------------------- 0.1/2.8 GB 6.4 MB/s eta 0:07:07\n",
      "   - -------------------------------------- 0.1/2.8 GB 6.4 MB/s eta 0:07:09\n",
      "   - -------------------------------------- 0.1/2.8 GB 6.3 MB/s eta 0:07:16\n",
      "   - -------------------------------------- 0.1/2.8 GB 6.2 MB/s eta 0:07:23\n",
      "   - -------------------------------------- 0.1/2.8 GB 6.1 MB/s eta 0:07:27\n",
      "   - -------------------------------------- 0.1/2.8 GB 6.1 MB/s eta 0:07:28\n",
      "   - -------------------------------------- 0.1/2.8 GB 6.1 MB/s eta 0:07:29\n",
      "   - -------------------------------------- 0.1/2.8 GB 6.0 MB/s eta 0:07:35\n",
      "   - -------------------------------------- 0.1/2.8 GB 6.0 MB/s eta 0:07:35\n",
      "   - -------------------------------------- 0.1/2.8 GB 6.0 MB/s eta 0:07:35\n",
      "   - -------------------------------------- 0.1/2.8 GB 5.8 MB/s eta 0:07:47\n",
      "   - -------------------------------------- 0.1/2.8 GB 5.8 MB/s eta 0:07:47\n",
      "   - -------------------------------------- 0.1/2.8 GB 5.8 MB/s eta 0:07:51\n",
      "   - -------------------------------------- 0.1/2.8 GB 5.7 MB/s eta 0:07:56\n",
      "   - -------------------------------------- 0.1/2.8 GB 5.7 MB/s eta 0:07:56\n",
      "   - -------------------------------------- 0.1/2.8 GB 5.7 MB/s eta 0:07:56\n",
      "   - -------------------------------------- 0.1/2.8 GB 5.6 MB/s eta 0:08:09\n",
      "   - -------------------------------------- 0.1/2.8 GB 5.5 MB/s eta 0:08:15\n",
      "   - -------------------------------------- 0.1/2.8 GB 5.4 MB/s eta 0:08:20\n",
      "   - -------------------------------------- 0.1/2.8 GB 5.4 MB/s eta 0:08:22\n",
      "   - -------------------------------------- 0.1/2.8 GB 5.4 MB/s eta 0:08:23\n",
      "   - -------------------------------------- 0.1/2.8 GB 5.4 MB/s eta 0:08:23\n",
      "   - -------------------------------------- 0.1/2.8 GB 5.4 MB/s eta 0:08:23\n",
      "   - -------------------------------------- 0.1/2.8 GB 5.4 MB/s eta 0:08:21\n",
      "   - -------------------------------------- 0.1/2.8 GB 5.4 MB/s eta 0:08:19\n",
      "   - -------------------------------------- 0.1/2.8 GB 5.5 MB/s eta 0:08:18\n",
      "   - -------------------------------------- 0.1/2.8 GB 5.4 MB/s eta 0:08:19\n",
      "   - -------------------------------------- 0.1/2.8 GB 5.5 MB/s eta 0:08:14\n",
      "   - -------------------------------------- 0.1/2.8 GB 5.5 MB/s eta 0:08:13\n",
      "   - -------------------------------------- 0.1/2.8 GB 5.5 MB/s eta 0:08:13\n",
      "   - -------------------------------------- 0.1/2.8 GB 5.5 MB/s eta 0:08:13\n",
      "   - -------------------------------------- 0.1/2.8 GB 5.4 MB/s eta 0:08:23\n",
      "   - -------------------------------------- 0.1/2.8 GB 5.4 MB/s eta 0:08:23\n",
      "   - -------------------------------------- 0.1/2.8 GB 5.4 MB/s eta 0:08:23\n",
      "   - -------------------------------------- 0.1/2.8 GB 5.4 MB/s eta 0:08:23\n",
      "   - -------------------------------------- 0.1/2.8 GB 5.4 MB/s eta 0:08:23\n",
      "   - -------------------------------------- 0.1/2.8 GB 5.4 MB/s eta 0:08:23\n",
      "   - -------------------------------------- 0.1/2.8 GB 5.4 MB/s eta 0:08:23\n",
      "   - -------------------------------------- 0.1/2.8 GB 5.0 MB/s eta 0:09:01\n",
      "   - -------------------------------------- 0.1/2.8 GB 5.0 MB/s eta 0:09:01\n",
      "   - -------------------------------------- 0.1/2.8 GB 5.0 MB/s eta 0:09:01\n",
      "   - -------------------------------------- 0.1/2.8 GB 4.9 MB/s eta 0:09:07\n",
      "   - -------------------------------------- 0.1/2.8 GB 4.9 MB/s eta 0:09:11\n",
      "   - -------------------------------------- 0.1/2.8 GB 4.9 MB/s eta 0:09:13\n",
      "   - -------------------------------------- 0.1/2.8 GB 4.9 MB/s eta 0:09:13\n",
      "   - -------------------------------------- 0.1/2.8 GB 4.9 MB/s eta 0:09:13\n",
      "   - -------------------------------------- 0.1/2.8 GB 4.9 MB/s eta 0:09:13\n",
      "   - -------------------------------------- 0.1/2.8 GB 4.7 MB/s eta 0:09:32\n",
      "   - -------------------------------------- 0.1/2.8 GB 4.7 MB/s eta 0:09:33\n",
      "   - -------------------------------------- 0.1/2.8 GB 4.7 MB/s eta 0:09:38\n",
      "   - -------------------------------------- 0.1/2.8 GB 4.7 MB/s eta 0:09:39\n",
      "   - -------------------------------------- 0.1/2.8 GB 4.7 MB/s eta 0:09:39\n",
      "   - -------------------------------------- 0.1/2.8 GB 4.6 MB/s eta 0:09:47\n",
      "   - -------------------------------------- 0.1/2.8 GB 4.6 MB/s eta 0:09:51\n",
      "   - -------------------------------------- 0.1/2.8 GB 4.6 MB/s eta 0:09:51\n",
      "   - -------------------------------------- 0.1/2.8 GB 4.5 MB/s eta 0:09:55\n",
      "   - -------------------------------------- 0.1/2.8 GB 4.5 MB/s eta 0:09:55\n",
      "   - -------------------------------------- 0.1/2.8 GB 4.5 MB/s eta 0:10:02\n",
      "   - -------------------------------------- 0.1/2.8 GB 4.5 MB/s eta 0:10:03\n",
      "   - -------------------------------------- 0.1/2.8 GB 4.5 MB/s eta 0:10:06\n",
      "   - -------------------------------------- 0.1/2.8 GB 4.4 MB/s eta 0:10:08\n",
      "   - -------------------------------------- 0.1/2.8 GB 4.4 MB/s eta 0:10:10\n",
      "   - -------------------------------------- 0.1/2.8 GB 4.4 MB/s eta 0:10:12\n",
      "   - -------------------------------------- 0.1/2.8 GB 4.4 MB/s eta 0:10:14\n",
      "   - -------------------------------------- 0.1/2.8 GB 4.4 MB/s eta 0:10:15\n",
      "   - -------------------------------------- 0.1/2.8 GB 4.3 MB/s eta 0:10:20\n",
      "   - -------------------------------------- 0.1/2.8 GB 4.3 MB/s eta 0:10:20\n",
      "   - -------------------------------------- 0.1/2.8 GB 4.3 MB/s eta 0:10:22\n",
      "   - -------------------------------------- 0.1/2.8 GB 4.3 MB/s eta 0:10:22\n",
      "   - -------------------------------------- 0.1/2.8 GB 4.3 MB/s eta 0:10:22\n",
      "   - -------------------------------------- 0.1/2.8 GB 4.2 MB/s eta 0:10:36\n",
      "   - -------------------------------------- 0.1/2.8 GB 4.2 MB/s eta 0:10:37\n",
      "   - -------------------------------------- 0.1/2.8 GB 4.2 MB/s eta 0:10:38\n",
      "   - -------------------------------------- 0.1/2.8 GB 4.2 MB/s eta 0:10:38\n",
      "   - -------------------------------------- 0.1/2.8 GB 4.2 MB/s eta 0:10:39\n",
      "   - -------------------------------------- 0.1/2.8 GB 4.2 MB/s eta 0:10:39\n",
      "   - -------------------------------------- 0.1/2.8 GB 4.2 MB/s eta 0:10:38\n",
      "   - -------------------------------------- 0.1/2.8 GB 4.2 MB/s eta 0:10:38\n",
      "   - -------------------------------------- 0.1/2.8 GB 4.2 MB/s eta 0:10:38\n",
      "   - -------------------------------------- 0.1/2.8 GB 4.2 MB/s eta 0:10:38\n",
      "   - -------------------------------------- 0.1/2.8 GB 4.2 MB/s eta 0:10:41\n",
      "   - -------------------------------------- 0.1/2.8 GB 4.1 MB/s eta 0:10:52\n",
      "   - -------------------------------------- 0.1/2.8 GB 4.1 MB/s eta 0:10:53\n",
      "   - -------------------------------------- 0.1/2.8 GB 4.1 MB/s eta 0:10:58\n",
      "   - -------------------------------------- 0.1/2.8 GB 4.1 MB/s eta 0:10:58\n",
      "   - -------------------------------------- 0.1/2.8 GB 4.1 MB/s eta 0:10:58\n",
      "   - -------------------------------------- 0.1/2.8 GB 4.1 MB/s eta 0:10:58\n",
      "   - -------------------------------------- 0.1/2.8 GB 4.1 MB/s eta 0:10:56\n",
      "   - -------------------------------------- 0.1/2.8 GB 4.1 MB/s eta 0:10:57\n",
      "   - -------------------------------------- 0.1/2.8 GB 4.1 MB/s eta 0:10:59\n",
      "   - -------------------------------------- 0.1/2.8 GB 4.0 MB/s eta 0:11:02\n",
      "   - -------------------------------------- 0.1/2.8 GB 4.0 MB/s eta 0:11:04\n",
      "   - -------------------------------------- 0.1/2.8 GB 4.0 MB/s eta 0:11:02\n",
      "   -- ------------------------------------- 0.1/2.8 GB 4.1 MB/s eta 0:10:59\n",
      "   -- ------------------------------------- 0.1/2.8 GB 4.1 MB/s eta 0:10:57\n",
      "   -- ------------------------------------- 0.1/2.8 GB 4.1 MB/s eta 0:10:57\n",
      "   -- ------------------------------------- 0.1/2.8 GB 4.1 MB/s eta 0:10:58\n",
      "   -- ------------------------------------- 0.1/2.8 GB 4.1 MB/s eta 0:10:55\n",
      "   -- ------------------------------------- 0.1/2.8 GB 4.0 MB/s eta 0:11:00\n",
      "   -- ------------------------------------- 0.2/2.8 GB 4.0 MB/s eta 0:11:02\n",
      "   -- ------------------------------------- 0.2/2.8 GB 4.0 MB/s eta 0:11:05\n",
      "   -- ------------------------------------- 0.2/2.8 GB 4.0 MB/s eta 0:11:04\n",
      "   -- ------------------------------------- 0.2/2.8 GB 4.0 MB/s eta 0:11:08\n",
      "   -- ------------------------------------- 0.2/2.8 GB 4.0 MB/s eta 0:11:12\n",
      "   -- ------------------------------------- 0.2/2.8 GB 3.9 MB/s eta 0:11:21\n",
      "   -- ------------------------------------- 0.2/2.8 GB 3.8 MB/s eta 0:11:33\n",
      "   -- ------------------------------------- 0.2/2.8 GB 3.8 MB/s eta 0:11:33\n",
      "   -- ------------------------------------- 0.2/2.8 GB 3.7 MB/s eta 0:11:51\n",
      "   -- ------------------------------------- 0.2/2.8 GB 3.7 MB/s eta 0:12:05\n",
      "   -- ------------------------------------- 0.2/2.8 GB 3.6 MB/s eta 0:12:22\n",
      "   -- ------------------------------------- 0.2/2.8 GB 3.5 MB/s eta 0:12:31\n",
      "   -- ------------------------------------- 0.2/2.8 GB 3.5 MB/s eta 0:12:31\n",
      "   -- ------------------------------------- 0.2/2.8 GB 3.5 MB/s eta 0:12:34\n",
      "   -- ------------------------------------- 0.2/2.8 GB 3.5 MB/s eta 0:12:39\n",
      "   -- ------------------------------------- 0.2/2.8 GB 3.5 MB/s eta 0:12:39\n",
      "   -- ------------------------------------- 0.2/2.8 GB 3.5 MB/s eta 0:12:36\n",
      "   -- ------------------------------------- 0.2/2.8 GB 3.5 MB/s eta 0:12:29\n",
      "   -- ------------------------------------- 0.2/2.8 GB 3.6 MB/s eta 0:12:18\n",
      "   -- ------------------------------------- 0.2/2.8 GB 3.6 MB/s eta 0:12:07\n",
      "   -- ------------------------------------- 0.2/2.8 GB 3.6 MB/s eta 0:12:08\n",
      "   -- ------------------------------------- 0.2/2.8 GB 3.6 MB/s eta 0:12:13\n",
      "   -- ------------------------------------- 0.2/2.8 GB 3.6 MB/s eta 0:12:13\n",
      "   -- ------------------------------------- 0.2/2.8 GB 3.6 MB/s eta 0:12:09\n",
      "   -- ------------------------------------- 0.2/2.8 GB 3.6 MB/s eta 0:12:05\n",
      "   -- ------------------------------------- 0.2/2.8 GB 3.7 MB/s eta 0:12:01\n",
      "   -- ------------------------------------- 0.2/2.8 GB 3.9 MB/s eta 0:11:14\n",
      "   -- ------------------------------------- 0.2/2.8 GB 4.0 MB/s eta 0:11:01\n",
      "   -- ------------------------------------- 0.2/2.8 GB 4.1 MB/s eta 0:10:47\n",
      "   -- ------------------------------------- 0.2/2.8 GB 4.1 MB/s eta 0:10:43\n",
      "   -- ------------------------------------- 0.2/2.8 GB 4.1 MB/s eta 0:10:43\n",
      "   -- ------------------------------------- 0.2/2.8 GB 4.1 MB/s eta 0:10:43\n",
      "   -- ------------------------------------- 0.2/2.8 GB 4.1 MB/s eta 0:10:36\n",
      "   -- ------------------------------------- 0.2/2.8 GB 4.1 MB/s eta 0:10:35\n",
      "   -- ------------------------------------- 0.2/2.8 GB 4.1 MB/s eta 0:10:35\n",
      "   -- ------------------------------------- 0.2/2.8 GB 4.1 MB/s eta 0:10:35\n",
      "   -- ------------------------------------- 0.2/2.8 GB 4.1 MB/s eta 0:10:46\n",
      "   -- ------------------------------------- 0.2/2.8 GB 4.1 MB/s eta 0:10:42\n",
      "   -- ------------------------------------- 0.2/2.8 GB 4.2 MB/s eta 0:10:28\n",
      "   -- ------------------------------------- 0.2/2.8 GB 4.2 MB/s eta 0:10:27\n",
      "   --- ------------------------------------ 0.2/2.8 GB 4.3 MB/s eta 0:10:13\n",
      "   --- ------------------------------------ 0.2/2.8 GB 4.4 MB/s eta 0:09:58\n",
      "   --- ------------------------------------ 0.2/2.8 GB 4.4 MB/s eta 0:09:56\n",
      "   --- ------------------------------------ 0.2/2.8 GB 4.4 MB/s eta 0:09:52\n",
      "   --- ------------------------------------ 0.2/2.8 GB 4.5 MB/s eta 0:09:33\n",
      "   --- ------------------------------------ 0.2/2.8 GB 4.6 MB/s eta 0:09:25\n",
      "   --- ------------------------------------ 0.2/2.8 GB 4.7 MB/s eta 0:09:16\n",
      "   --- ------------------------------------ 0.2/2.8 GB 4.8 MB/s eta 0:09:01\n",
      "   --- ------------------------------------ 0.2/2.8 GB 4.9 MB/s eta 0:08:50\n",
      "   --- ------------------------------------ 0.2/2.8 GB 4.9 MB/s eta 0:08:45\n",
      "   --- ------------------------------------ 0.2/2.8 GB 5.0 MB/s eta 0:08:38\n",
      "   --- ------------------------------------ 0.2/2.8 GB 5.1 MB/s eta 0:08:29\n",
      "   --- ------------------------------------ 0.2/2.8 GB 5.1 MB/s eta 0:08:24\n",
      "   --- ------------------------------------ 0.2/2.8 GB 5.2 MB/s eta 0:08:11\n",
      "   --- ------------------------------------ 0.2/2.8 GB 5.3 MB/s eta 0:08:07\n",
      "   --- ------------------------------------ 0.3/2.8 GB 5.3 MB/s eta 0:08:04\n",
      "   --- ------------------------------------ 0.3/2.8 GB 5.3 MB/s eta 0:08:06\n",
      "   --- ------------------------------------ 0.3/2.8 GB 5.4 MB/s eta 0:07:55\n",
      "   --- ------------------------------------ 0.3/2.8 GB 5.4 MB/s eta 0:07:56\n",
      "   --- ------------------------------------ 0.3/2.8 GB 5.4 MB/s eta 0:07:54\n",
      "   --- ------------------------------------ 0.3/2.8 GB 5.5 MB/s eta 0:07:48\n",
      "   --- ------------------------------------ 0.3/2.8 GB 5.5 MB/s eta 0:07:43\n",
      "   --- ------------------------------------ 0.3/2.8 GB 5.5 MB/s eta 0:07:42\n",
      "   --- ------------------------------------ 0.3/2.8 GB 5.5 MB/s eta 0:07:43\n",
      "   --- ------------------------------------ 0.3/2.8 GB 5.5 MB/s eta 0:07:44\n",
      "   --- ------------------------------------ 0.3/2.8 GB 5.5 MB/s eta 0:07:42\n",
      "   --- ------------------------------------ 0.3/2.8 GB 5.5 MB/s eta 0:07:43\n",
      "   --- ------------------------------------ 0.3/2.8 GB 5.5 MB/s eta 0:07:43\n",
      "   --- ------------------------------------ 0.3/2.8 GB 5.5 MB/s eta 0:07:45\n",
      "   --- ------------------------------------ 0.3/2.8 GB 5.5 MB/s eta 0:07:44\n",
      "   --- ------------------------------------ 0.3/2.8 GB 5.5 MB/s eta 0:07:44\n",
      "   --- ------------------------------------ 0.3/2.8 GB 5.4 MB/s eta 0:07:53\n",
      "   --- ------------------------------------ 0.3/2.8 GB 5.5 MB/s eta 0:07:47\n",
      "   --- ------------------------------------ 0.3/2.8 GB 5.5 MB/s eta 0:07:45\n",
      "   --- ------------------------------------ 0.3/2.8 GB 5.8 MB/s eta 0:07:18\n",
      "   --- ------------------------------------ 0.3/2.8 GB 5.8 MB/s eta 0:07:16\n",
      "   --- ------------------------------------ 0.3/2.8 GB 5.9 MB/s eta 0:07:13\n",
      "   --- ------------------------------------ 0.3/2.8 GB 5.9 MB/s eta 0:07:13\n",
      "   ---- ----------------------------------- 0.3/2.8 GB 5.9 MB/s eta 0:07:09\n",
      "   ---- ----------------------------------- 0.3/2.8 GB 6.0 MB/s eta 0:07:05\n",
      "   ---- ----------------------------------- 0.3/2.8 GB 6.0 MB/s eta 0:07:01\n",
      "   ---- ----------------------------------- 0.3/2.8 GB 6.1 MB/s eta 0:06:56\n",
      "   ---- ----------------------------------- 0.3/2.8 GB 6.2 MB/s eta 0:06:45\n",
      "   ---- ----------------------------------- 0.3/2.8 GB 6.2 MB/s eta 0:06:44\n",
      "   ---- ----------------------------------- 0.3/2.8 GB 6.2 MB/s eta 0:06:45\n",
      "   ---- ----------------------------------- 0.3/2.8 GB 6.2 MB/s eta 0:06:46\n",
      "   ---- ----------------------------------- 0.3/2.8 GB 6.2 MB/s eta 0:06:44\n",
      "   ---- ----------------------------------- 0.3/2.8 GB 6.4 MB/s eta 0:06:33\n",
      "   ---- ----------------------------------- 0.3/2.8 GB 6.4 MB/s eta 0:06:34\n",
      "   ---- ----------------------------------- 0.3/2.8 GB 6.4 MB/s eta 0:06:32\n",
      "   ---- ----------------------------------- 0.3/2.8 GB 6.5 MB/s eta 0:06:28\n",
      "   ---- ----------------------------------- 0.3/2.8 GB 6.6 MB/s eta 0:06:22\n",
      "   ---- ----------------------------------- 0.3/2.8 GB 6.6 MB/s eta 0:06:18\n",
      "   ---- ----------------------------------- 0.3/2.8 GB 6.6 MB/s eta 0:06:18\n",
      "   ---- ----------------------------------- 0.3/2.8 GB 6.7 MB/s eta 0:06:15\n",
      "   ---- ----------------------------------- 0.3/2.8 GB 6.7 MB/s eta 0:06:13\n",
      "   ---- ----------------------------------- 0.3/2.8 GB 6.8 MB/s eta 0:06:08\n",
      "   ---- ----------------------------------- 0.3/2.8 GB 6.9 MB/s eta 0:06:04\n",
      "   ---- ----------------------------------- 0.3/2.8 GB 6.9 MB/s eta 0:06:02\n",
      "   ---- ----------------------------------- 0.3/2.8 GB 7.0 MB/s eta 0:05:59\n",
      "   ---- ----------------------------------- 0.3/2.8 GB 6.9 MB/s eta 0:06:00\n",
      "   ---- ----------------------------------- 0.3/2.8 GB 7.0 MB/s eta 0:05:57\n",
      "   ---- ----------------------------------- 0.3/2.8 GB 7.0 MB/s eta 0:05:56\n",
      "   ---- ----------------------------------- 0.3/2.8 GB 7.1 MB/s eta 0:05:53\n",
      "   ---- ----------------------------------- 0.3/2.8 GB 7.1 MB/s eta 0:05:51\n",
      "   ---- ----------------------------------- 0.3/2.8 GB 7.1 MB/s eta 0:05:49\n",
      "   ---- ----------------------------------- 0.3/2.8 GB 7.1 MB/s eta 0:05:49\n",
      "   ---- ----------------------------------- 0.3/2.8 GB 7.1 MB/s eta 0:05:48\n",
      "   ---- ----------------------------------- 0.3/2.8 GB 7.2 MB/s eta 0:05:47\n",
      "   ---- ----------------------------------- 0.3/2.8 GB 7.2 MB/s eta 0:05:45\n",
      "   ---- ----------------------------------- 0.3/2.8 GB 7.2 MB/s eta 0:05:44\n",
      "   ---- ----------------------------------- 0.3/2.8 GB 7.4 MB/s eta 0:05:37\n",
      "   ---- ----------------------------------- 0.3/2.8 GB 7.4 MB/s eta 0:05:37\n",
      "   ---- ----------------------------------- 0.3/2.8 GB 7.3 MB/s eta 0:05:38\n",
      "   ---- ----------------------------------- 0.3/2.8 GB 7.3 MB/s eta 0:05:37\n",
      "   ---- ----------------------------------- 0.3/2.8 GB 7.4 MB/s eta 0:05:35\n",
      "   ---- ----------------------------------- 0.3/2.8 GB 7.4 MB/s eta 0:05:33\n",
      "   ---- ----------------------------------- 0.3/2.8 GB 7.5 MB/s eta 0:05:30\n",
      "   ---- ----------------------------------- 0.4/2.8 GB 7.6 MB/s eta 0:05:27\n",
      "   ----- ---------------------------------- 0.4/2.8 GB 7.6 MB/s eta 0:05:24\n",
      "   ----- ---------------------------------- 0.4/2.8 GB 7.7 MB/s eta 0:05:22\n",
      "   ----- ---------------------------------- 0.4/2.8 GB 7.7 MB/s eta 0:05:20\n",
      "   ----- ---------------------------------- 0.4/2.8 GB 7.8 MB/s eta 0:05:16\n",
      "   ----- ---------------------------------- 0.4/2.8 GB 7.8 MB/s eta 0:05:14\n",
      "   ----- ---------------------------------- 0.4/2.8 GB 7.9 MB/s eta 0:05:09\n",
      "   ----- ---------------------------------- 0.4/2.8 GB 8.0 MB/s eta 0:05:06\n",
      "   ----- ---------------------------------- 0.4/2.8 GB 8.1 MB/s eta 0:05:04\n",
      "   ----- ---------------------------------- 0.4/2.8 GB 8.1 MB/s eta 0:05:02\n",
      "   ----- ---------------------------------- 0.4/2.8 GB 8.1 MB/s eta 0:05:00\n",
      "   ----- ---------------------------------- 0.4/2.8 GB 8.2 MB/s eta 0:04:59\n",
      "   ----- ---------------------------------- 0.4/2.8 GB 8.1 MB/s eta 0:05:00\n",
      "   ----- ---------------------------------- 0.4/2.8 GB 8.1 MB/s eta 0:05:01\n",
      "   ----- ---------------------------------- 0.4/2.8 GB 8.2 MB/s eta 0:04:58\n",
      "   ----- ---------------------------------- 0.4/2.8 GB 8.3 MB/s eta 0:04:53\n",
      "   ----- ---------------------------------- 0.4/2.8 GB 8.4 MB/s eta 0:04:50\n",
      "   ----- ---------------------------------- 0.4/2.8 GB 8.5 MB/s eta 0:04:47\n",
      "   ----- ---------------------------------- 0.4/2.8 GB 8.5 MB/s eta 0:04:45\n",
      "   ----- ---------------------------------- 0.4/2.8 GB 8.5 MB/s eta 0:04:45\n",
      "   ----- ---------------------------------- 0.4/2.8 GB 8.5 MB/s eta 0:04:45\n",
      "   ----- ---------------------------------- 0.4/2.8 GB 8.5 MB/s eta 0:04:45\n",
      "   ----- ---------------------------------- 0.4/2.8 GB 8.5 MB/s eta 0:04:43\n",
      "   ----- ---------------------------------- 0.4/2.8 GB 8.6 MB/s eta 0:04:41\n",
      "   ----- ---------------------------------- 0.4/2.8 GB 8.6 MB/s eta 0:04:39\n",
      "   ----- ---------------------------------- 0.4/2.8 GB 8.6 MB/s eta 0:04:40\n",
      "   ----- ---------------------------------- 0.4/2.8 GB 8.6 MB/s eta 0:04:39\n",
      "   ----- ---------------------------------- 0.4/2.8 GB 8.7 MB/s eta 0:04:37\n",
      "   ----- ---------------------------------- 0.4/2.8 GB 8.7 MB/s eta 0:04:35\n",
      "   ----- ---------------------------------- 0.4/2.8 GB 9.1 MB/s eta 0:04:23\n",
      "   ------ --------------------------------- 0.4/2.8 GB 9.2 MB/s eta 0:04:20\n",
      "   ------ --------------------------------- 0.4/2.8 GB 9.2 MB/s eta 0:04:21\n",
      "   ------ --------------------------------- 0.4/2.8 GB 9.2 MB/s eta 0:04:20\n",
      "   ------ --------------------------------- 0.4/2.8 GB 9.2 MB/s eta 0:04:21\n",
      "   ------ --------------------------------- 0.4/2.8 GB 9.2 MB/s eta 0:04:20\n",
      "   ------ --------------------------------- 0.4/2.8 GB 9.2 MB/s eta 0:04:21\n",
      "   ------ --------------------------------- 0.4/2.8 GB 9.1 MB/s eta 0:04:21\n",
      "   ------ --------------------------------- 0.4/2.8 GB 9.1 MB/s eta 0:04:22\n",
      "   ------ --------------------------------- 0.4/2.8 GB 9.1 MB/s eta 0:04:23\n",
      "   ------ --------------------------------- 0.4/2.8 GB 9.1 MB/s eta 0:04:22\n",
      "   ------ --------------------------------- 0.4/2.8 GB 9.2 MB/s eta 0:04:19\n",
      "   ------ --------------------------------- 0.4/2.8 GB 9.2 MB/s eta 0:04:17\n",
      "   ------ --------------------------------- 0.4/2.8 GB 9.2 MB/s eta 0:04:17\n",
      "   ------ --------------------------------- 0.4/2.8 GB 9.2 MB/s eta 0:04:18\n",
      "   ------ --------------------------------- 0.4/2.8 GB 9.2 MB/s eta 0:04:19\n",
      "   ------ --------------------------------- 0.4/2.8 GB 9.1 MB/s eta 0:04:20\n",
      "   ------ --------------------------------- 0.4/2.8 GB 9.1 MB/s eta 0:04:21\n",
      "   ------ --------------------------------- 0.4/2.8 GB 9.0 MB/s eta 0:04:23\n",
      "   ------ --------------------------------- 0.5/2.8 GB 9.0 MB/s eta 0:04:24\n",
      "   ------ --------------------------------- 0.5/2.8 GB 8.9 MB/s eta 0:04:25\n",
      "   ------ --------------------------------- 0.5/2.8 GB 8.9 MB/s eta 0:04:26\n",
      "   ------ --------------------------------- 0.5/2.8 GB 8.8 MB/s eta 0:04:28\n",
      "   ------ --------------------------------- 0.5/2.8 GB 8.8 MB/s eta 0:04:29\n",
      "   ------ --------------------------------- 0.5/2.8 GB 8.8 MB/s eta 0:04:30\n",
      "   ------ --------------------------------- 0.5/2.8 GB 8.8 MB/s eta 0:04:29\n",
      "   ------ --------------------------------- 0.5/2.8 GB 8.8 MB/s eta 0:04:29\n",
      "   ------ --------------------------------- 0.5/2.8 GB 8.8 MB/s eta 0:04:29\n",
      "   ------ --------------------------------- 0.5/2.8 GB 8.9 MB/s eta 0:04:24\n",
      "   ------ --------------------------------- 0.5/2.8 GB 8.9 MB/s eta 0:04:24\n",
      "   ------ --------------------------------- 0.5/2.8 GB 8.9 MB/s eta 0:04:25\n",
      "   ------ --------------------------------- 0.5/2.8 GB 8.9 MB/s eta 0:04:25\n",
      "   ------ --------------------------------- 0.5/2.8 GB 8.9 MB/s eta 0:04:25\n",
      "   ------ --------------------------------- 0.5/2.8 GB 8.8 MB/s eta 0:04:26\n",
      "   ------ --------------------------------- 0.5/2.8 GB 8.8 MB/s eta 0:04:27\n",
      "   ------ --------------------------------- 0.5/2.8 GB 8.8 MB/s eta 0:04:27\n",
      "   ------ --------------------------------- 0.5/2.8 GB 8.7 MB/s eta 0:04:28\n",
      "   ------ --------------------------------- 0.5/2.8 GB 8.7 MB/s eta 0:04:31\n",
      "   ------ --------------------------------- 0.5/2.8 GB 8.6 MB/s eta 0:04:31\n",
      "   ------ --------------------------------- 0.5/2.8 GB 8.6 MB/s eta 0:04:32\n",
      "   ------ --------------------------------- 0.5/2.8 GB 8.6 MB/s eta 0:04:33\n",
      "   ------ --------------------------------- 0.5/2.8 GB 8.6 MB/s eta 0:04:32\n",
      "   ------ --------------------------------- 0.5/2.8 GB 8.5 MB/s eta 0:04:34\n",
      "   ------ --------------------------------- 0.5/2.8 GB 8.5 MB/s eta 0:04:35\n",
      "   ------ --------------------------------- 0.5/2.8 GB 8.4 MB/s eta 0:04:39\n",
      "   ------ --------------------------------- 0.5/2.8 GB 8.3 MB/s eta 0:04:40\n",
      "   ------ --------------------------------- 0.5/2.8 GB 8.3 MB/s eta 0:04:40\n",
      "   ------ --------------------------------- 0.5/2.8 GB 8.3 MB/s eta 0:04:41\n",
      "   ------- -------------------------------- 0.5/2.8 GB 8.2 MB/s eta 0:04:43\n",
      "   ------- -------------------------------- 0.5/2.8 GB 8.2 MB/s eta 0:04:44\n",
      "   ------- -------------------------------- 0.5/2.8 GB 8.2 MB/s eta 0:04:44\n",
      "   ------- -------------------------------- 0.5/2.8 GB 8.2 MB/s eta 0:04:45\n",
      "   ------- -------------------------------- 0.5/2.8 GB 8.1 MB/s eta 0:04:45\n",
      "   ------- -------------------------------- 0.5/2.8 GB 8.2 MB/s eta 0:04:43\n",
      "   ------- -------------------------------- 0.5/2.8 GB 8.2 MB/s eta 0:04:42\n",
      "   ------- -------------------------------- 0.5/2.8 GB 8.2 MB/s eta 0:04:43\n",
      "   ------- -------------------------------- 0.5/2.8 GB 8.2 MB/s eta 0:04:42\n",
      "   ------- -------------------------------- 0.5/2.8 GB 8.3 MB/s eta 0:04:40\n",
      "   ------- -------------------------------- 0.5/2.8 GB 8.3 MB/s eta 0:04:38\n",
      "   ------- -------------------------------- 0.5/2.8 GB 8.4 MB/s eta 0:04:36\n",
      "   ------- -------------------------------- 0.5/2.8 GB 8.4 MB/s eta 0:04:35\n",
      "   ------- -------------------------------- 0.5/2.8 GB 8.4 MB/s eta 0:04:36\n",
      "   ------- -------------------------------- 0.5/2.8 GB 8.3 MB/s eta 0:04:36\n",
      "   ------- -------------------------------- 0.5/2.8 GB 8.3 MB/s eta 0:04:36\n",
      "   ------- -------------------------------- 0.5/2.8 GB 8.3 MB/s eta 0:04:37\n",
      "   ------- -------------------------------- 0.5/2.8 GB 8.4 MB/s eta 0:04:34\n",
      "   ------- -------------------------------- 0.5/2.8 GB 8.4 MB/s eta 0:04:35\n",
      "   ------- -------------------------------- 0.5/2.8 GB 8.3 MB/s eta 0:04:36\n",
      "   ------- -------------------------------- 0.5/2.8 GB 8.3 MB/s eta 0:04:36\n",
      "   ------- -------------------------------- 0.5/2.8 GB 8.3 MB/s eta 0:04:36\n",
      "   ------- -------------------------------- 0.5/2.8 GB 8.3 MB/s eta 0:04:38\n",
      "   ------- -------------------------------- 0.5/2.8 GB 8.3 MB/s eta 0:04:38\n",
      "   ------- -------------------------------- 0.5/2.8 GB 8.3 MB/s eta 0:04:36\n",
      "   ------- -------------------------------- 0.5/2.8 GB 8.3 MB/s eta 0:04:35\n",
      "   ------- -------------------------------- 0.5/2.8 GB 8.3 MB/s eta 0:04:35\n",
      "   ------- -------------------------------- 0.5/2.8 GB 8.3 MB/s eta 0:04:36\n",
      "   ------- -------------------------------- 0.5/2.8 GB 8.2 MB/s eta 0:04:38\n",
      "   ------- -------------------------------- 0.5/2.8 GB 8.1 MB/s eta 0:04:41\n",
      "   ------- -------------------------------- 0.5/2.8 GB 8.1 MB/s eta 0:04:42\n",
      "   ------- -------------------------------- 0.5/2.8 GB 8.1 MB/s eta 0:04:41\n",
      "   ------- -------------------------------- 0.5/2.8 GB 8.1 MB/s eta 0:04:41\n",
      "   ------- -------------------------------- 0.5/2.8 GB 8.2 MB/s eta 0:04:39\n",
      "   ------- -------------------------------- 0.5/2.8 GB 8.2 MB/s eta 0:04:38\n",
      "   ------- -------------------------------- 0.5/2.8 GB 8.3 MB/s eta 0:04:36\n",
      "   ------- -------------------------------- 0.5/2.8 GB 8.3 MB/s eta 0:04:35\n",
      "   ------- -------------------------------- 0.6/2.8 GB 8.3 MB/s eta 0:04:34\n",
      "   ------- -------------------------------- 0.6/2.8 GB 8.3 MB/s eta 0:04:34\n",
      "   ------- -------------------------------- 0.6/2.8 GB 8.2 MB/s eta 0:04:35\n",
      "   ------- -------------------------------- 0.6/2.8 GB 8.3 MB/s eta 0:04:33\n",
      "   ------- -------------------------------- 0.6/2.8 GB 8.3 MB/s eta 0:04:32\n",
      "   ------- -------------------------------- 0.6/2.8 GB 8.3 MB/s eta 0:04:31\n",
      "   -------- ------------------------------- 0.6/2.8 GB 8.3 MB/s eta 0:04:33\n",
      "   -------- ------------------------------- 0.6/2.8 GB 8.2 MB/s eta 0:04:34\n",
      "   -------- ------------------------------- 0.6/2.8 GB 8.2 MB/s eta 0:04:36\n",
      "   -------- ------------------------------- 0.6/2.8 GB 8.2 MB/s eta 0:04:36\n",
      "   -------- ------------------------------- 0.6/2.8 GB 8.2 MB/s eta 0:04:35\n",
      "   -------- ------------------------------- 0.6/2.8 GB 8.3 MB/s eta 0:04:32\n",
      "   -------- ------------------------------- 0.6/2.8 GB 8.2 MB/s eta 0:04:33\n",
      "   -------- ------------------------------- 0.6/2.8 GB 8.3 MB/s eta 0:04:32\n",
      "   -------- ------------------------------- 0.6/2.8 GB 8.2 MB/s eta 0:04:33\n",
      "   -------- ------------------------------- 0.6/2.8 GB 8.2 MB/s eta 0:04:34\n",
      "   -------- ------------------------------- 0.6/2.8 GB 8.2 MB/s eta 0:04:34\n",
      "   -------- ------------------------------- 0.6/2.8 GB 8.2 MB/s eta 0:04:34\n",
      "   -------- ------------------------------- 0.6/2.8 GB 8.2 MB/s eta 0:04:34\n",
      "   -------- ------------------------------- 0.6/2.8 GB 8.2 MB/s eta 0:04:34\n",
      "   -------- ------------------------------- 0.6/2.8 GB 8.2 MB/s eta 0:04:35\n",
      "   -------- ------------------------------- 0.6/2.8 GB 8.2 MB/s eta 0:04:34\n",
      "   -------- ------------------------------- 0.6/2.8 GB 8.2 MB/s eta 0:04:33\n",
      "   -------- ------------------------------- 0.6/2.8 GB 8.2 MB/s eta 0:04:31\n",
      "   -------- ------------------------------- 0.6/2.8 GB 8.3 MB/s eta 0:04:30\n",
      "   -------- ------------------------------- 0.6/2.8 GB 8.3 MB/s eta 0:04:28\n",
      "   -------- ------------------------------- 0.6/2.8 GB 8.3 MB/s eta 0:04:28\n",
      "   -------- ------------------------------- 0.6/2.8 GB 8.3 MB/s eta 0:04:29\n",
      "   -------- ------------------------------- 0.6/2.8 GB 8.3 MB/s eta 0:04:29\n",
      "   -------- ------------------------------- 0.6/2.8 GB 8.3 MB/s eta 0:04:29\n",
      "   -------- ------------------------------- 0.6/2.8 GB 8.3 MB/s eta 0:04:28\n",
      "   -------- ------------------------------- 0.6/2.8 GB 8.3 MB/s eta 0:04:28\n",
      "   -------- ------------------------------- 0.6/2.8 GB 8.3 MB/s eta 0:04:27\n",
      "   -------- ------------------------------- 0.6/2.8 GB 8.3 MB/s eta 0:04:27\n",
      "   -------- ------------------------------- 0.6/2.8 GB 8.2 MB/s eta 0:04:30\n",
      "   -------- ------------------------------- 0.6/2.8 GB 8.1 MB/s eta 0:04:33\n",
      "   -------- ------------------------------- 0.6/2.8 GB 8.0 MB/s eta 0:04:36\n",
      "   -------- ------------------------------- 0.6/2.8 GB 7.9 MB/s eta 0:04:38\n",
      "   -------- ------------------------------- 0.6/2.8 GB 7.9 MB/s eta 0:04:40\n",
      "   -------- ------------------------------- 0.6/2.8 GB 7.8 MB/s eta 0:04:41\n",
      "   -------- ------------------------------- 0.6/2.8 GB 7.9 MB/s eta 0:04:39\n",
      "   -------- ------------------------------- 0.6/2.8 GB 8.0 MB/s eta 0:04:36\n",
      "   -------- ------------------------------- 0.6/2.8 GB 8.0 MB/s eta 0:04:34\n",
      "   -------- ------------------------------- 0.6/2.8 GB 8.0 MB/s eta 0:04:35\n",
      "   -------- ------------------------------- 0.6/2.8 GB 8.0 MB/s eta 0:04:34\n",
      "   -------- ------------------------------- 0.6/2.8 GB 8.0 MB/s eta 0:04:34\n",
      "   -------- ------------------------------- 0.6/2.8 GB 8.0 MB/s eta 0:04:33\n",
      "   --------- ------------------------------ 0.6/2.8 GB 8.1 MB/s eta 0:04:31\n",
      "   --------- ------------------------------ 0.6/2.8 GB 8.2 MB/s eta 0:04:27\n",
      "   --------- ------------------------------ 0.6/2.8 GB 8.3 MB/s eta 0:04:23\n",
      "   --------- ------------------------------ 0.6/2.8 GB 8.3 MB/s eta 0:04:21\n",
      "   --------- ------------------------------ 0.7/2.8 GB 8.4 MB/s eta 0:04:19\n",
      "   --------- ------------------------------ 0.7/2.8 GB 8.4 MB/s eta 0:04:17\n",
      "   --------- ------------------------------ 0.7/2.8 GB 8.5 MB/s eta 0:04:14\n",
      "   --------- ------------------------------ 0.7/2.8 GB 8.6 MB/s eta 0:04:10\n",
      "   --------- ------------------------------ 0.7/2.8 GB 8.7 MB/s eta 0:04:07\n",
      "   --------- ------------------------------ 0.7/2.8 GB 8.7 MB/s eta 0:04:05\n",
      "   --------- ------------------------------ 0.7/2.8 GB 8.8 MB/s eta 0:04:04\n",
      "   --------- ------------------------------ 0.7/2.8 GB 8.8 MB/s eta 0:04:02\n",
      "   --------- ------------------------------ 0.7/2.8 GB 8.8 MB/s eta 0:04:02\n",
      "   --------- ------------------------------ 0.7/2.8 GB 8.8 MB/s eta 0:04:01\n",
      "   --------- ------------------------------ 0.7/2.8 GB 8.8 MB/s eta 0:04:01\n",
      "   --------- ------------------------------ 0.7/2.8 GB 8.9 MB/s eta 0:03:59\n",
      "   --------- ------------------------------ 0.7/2.8 GB 9.0 MB/s eta 0:03:57\n",
      "   --------- ------------------------------ 0.7/2.8 GB 8.9 MB/s eta 0:03:58\n",
      "   --------- ------------------------------ 0.7/2.8 GB 8.9 MB/s eta 0:03:58\n",
      "   --------- ------------------------------ 0.7/2.8 GB 9.0 MB/s eta 0:03:57\n",
      "   ---------- ----------------------------- 0.7/2.8 GB 9.1 MB/s eta 0:03:53\n",
      "   ---------- ----------------------------- 0.7/2.8 GB 9.3 MB/s eta 0:03:47\n",
      "   ---------- ----------------------------- 0.7/2.8 GB 9.5 MB/s eta 0:03:41\n",
      "   ---------- ----------------------------- 0.7/2.8 GB 9.8 MB/s eta 0:03:35\n",
      "   ---------- ----------------------------- 0.7/2.8 GB 9.8 MB/s eta 0:03:34\n",
      "   ---------- ----------------------------- 0.7/2.8 GB 9.8 MB/s eta 0:03:33\n",
      "   ---------- ----------------------------- 0.7/2.8 GB 9.9 MB/s eta 0:03:31\n",
      "   ---------- ----------------------------- 0.7/2.8 GB 10.0 MB/s eta 0:03:30\n",
      "   ---------- ----------------------------- 0.7/2.8 GB 10.0 MB/s eta 0:03:30\n",
      "   ---------- ----------------------------- 0.7/2.8 GB 10.0 MB/s eta 0:03:30\n",
      "   ---------- ----------------------------- 0.7/2.8 GB 10.0 MB/s eta 0:03:30\n",
      "   ---------- ----------------------------- 0.7/2.8 GB 10.0 MB/s eta 0:03:30\n",
      "   ---------- ----------------------------- 0.7/2.8 GB 10.0 MB/s eta 0:03:30\n",
      "   ---------- ----------------------------- 0.7/2.8 GB 9.7 MB/s eta 0:03:36\n",
      "   ---------- ----------------------------- 0.7/2.8 GB 9.8 MB/s eta 0:03:33\n",
      "   ---------- ----------------------------- 0.7/2.8 GB 9.9 MB/s eta 0:03:31\n",
      "   ---------- ----------------------------- 0.7/2.8 GB 9.9 MB/s eta 0:03:31\n",
      "   ---------- ----------------------------- 0.7/2.8 GB 9.9 MB/s eta 0:03:30\n",
      "   ---------- ----------------------------- 0.8/2.8 GB 9.9 MB/s eta 0:03:29\n",
      "   ---------- ----------------------------- 0.8/2.8 GB 10.1 MB/s eta 0:03:25\n",
      "   ---------- ----------------------------- 0.8/2.8 GB 10.1 MB/s eta 0:03:26\n",
      "   ---------- ----------------------------- 0.8/2.8 GB 10.0 MB/s eta 0:03:26\n",
      "   ---------- ----------------------------- 0.8/2.8 GB 10.1 MB/s eta 0:03:24\n",
      "   ---------- ----------------------------- 0.8/2.8 GB 10.1 MB/s eta 0:03:24\n",
      "   ---------- ----------------------------- 0.8/2.8 GB 10.1 MB/s eta 0:03:23\n",
      "   ---------- ----------------------------- 0.8/2.8 GB 10.2 MB/s eta 0:03:21\n",
      "   ---------- ----------------------------- 0.8/2.8 GB 10.2 MB/s eta 0:03:21\n",
      "   ---------- ----------------------------- 0.8/2.8 GB 10.2 MB/s eta 0:03:21\n",
      "   ---------- ----------------------------- 0.8/2.8 GB 10.2 MB/s eta 0:03:22\n",
      "   ---------- ----------------------------- 0.8/2.8 GB 10.1 MB/s eta 0:03:22\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 10.2 MB/s eta 0:03:22\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 10.1 MB/s eta 0:03:22\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 10.2 MB/s eta 0:03:19\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 10.6 MB/s eta 0:03:13\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 10.7 MB/s eta 0:03:10\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 10.7 MB/s eta 0:03:10\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 10.7 MB/s eta 0:03:09\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 10.8 MB/s eta 0:03:09\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 10.7 MB/s eta 0:03:09\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 10.8 MB/s eta 0:03:09\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 10.7 MB/s eta 0:03:09\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 10.8 MB/s eta 0:03:07\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 10.8 MB/s eta 0:03:06\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 10.9 MB/s eta 0:03:05\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 10.9 MB/s eta 0:03:05\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 10.9 MB/s eta 0:03:05\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 10.9 MB/s eta 0:03:04\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 10.9 MB/s eta 0:03:04\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 10.9 MB/s eta 0:03:04\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 10.9 MB/s eta 0:03:05\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 10.8 MB/s eta 0:03:05\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 10.8 MB/s eta 0:03:05\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 10.8 MB/s eta 0:03:05\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 10.8 MB/s eta 0:03:06\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 10.7 MB/s eta 0:03:07\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 10.8 MB/s eta 0:03:05\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 10.8 MB/s eta 0:03:05\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 10.7 MB/s eta 0:03:07\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 10.7 MB/s eta 0:03:06\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 10.7 MB/s eta 0:03:06\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 10.6 MB/s eta 0:03:09\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 10.5 MB/s eta 0:03:10\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 10.5 MB/s eta 0:03:10\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 10.4 MB/s eta 0:03:12\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 10.3 MB/s eta 0:03:13\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 10.3 MB/s eta 0:03:13\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 10.3 MB/s eta 0:03:13\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 10.3 MB/s eta 0:03:13\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 10.3 MB/s eta 0:03:13\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 10.3 MB/s eta 0:03:13\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 10.3 MB/s eta 0:03:13\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 9.7 MB/s eta 0:03:25\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 9.7 MB/s eta 0:03:25\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 9.7 MB/s eta 0:03:25\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 9.7 MB/s eta 0:03:25\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 9.7 MB/s eta 0:03:25\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 9.4 MB/s eta 0:03:32\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 9.4 MB/s eta 0:03:32\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 9.2 MB/s eta 0:03:35\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 9.2 MB/s eta 0:03:35\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 9.2 MB/s eta 0:03:35\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 9.2 MB/s eta 0:03:35\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 9.2 MB/s eta 0:03:35\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 9.2 MB/s eta 0:03:35\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 9.2 MB/s eta 0:03:35\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 9.2 MB/s eta 0:03:35\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 9.2 MB/s eta 0:03:35\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 9.2 MB/s eta 0:03:35\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 9.2 MB/s eta 0:03:35\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 9.2 MB/s eta 0:03:35\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 9.2 MB/s eta 0:03:35\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 9.2 MB/s eta 0:03:35\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 9.2 MB/s eta 0:03:35\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 9.2 MB/s eta 0:03:35\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 9.2 MB/s eta 0:03:35\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 9.2 MB/s eta 0:03:35\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 9.2 MB/s eta 0:03:35\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 9.2 MB/s eta 0:03:35\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 9.2 MB/s eta 0:03:35\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 9.2 MB/s eta 0:03:35\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 9.2 MB/s eta 0:03:35\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 9.2 MB/s eta 0:03:35\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 9.2 MB/s eta 0:03:35\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 9.2 MB/s eta 0:03:35\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 9.2 MB/s eta 0:03:35\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 9.2 MB/s eta 0:03:35\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 9.2 MB/s eta 0:03:35\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 9.2 MB/s eta 0:03:35\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 9.2 MB/s eta 0:03:35\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 9.2 MB/s eta 0:03:35\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 9.2 MB/s eta 0:03:35\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 9.2 MB/s eta 0:03:35\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 9.2 MB/s eta 0:03:35\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 9.2 MB/s eta 0:03:35\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 9.2 MB/s eta 0:03:35\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 9.2 MB/s eta 0:03:35\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 9.2 MB/s eta 0:03:35\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 9.2 MB/s eta 0:03:35\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 9.2 MB/s eta 0:03:35\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 9.2 MB/s eta 0:03:35\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 9.2 MB/s eta 0:03:35\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 9.2 MB/s eta 0:03:35\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 9.2 MB/s eta 0:03:35\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 9.2 MB/s eta 0:03:35\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 9.2 MB/s eta 0:03:35\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 9.2 MB/s eta 0:03:35\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 9.2 MB/s eta 0:03:35\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 9.2 MB/s eta 0:03:35\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 9.2 MB/s eta 0:03:35\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 9.2 MB/s eta 0:03:35\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 9.2 MB/s eta 0:03:35\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 9.2 MB/s eta 0:03:35\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 9.2 MB/s eta 0:03:35\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 9.2 MB/s eta 0:03:35\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 9.2 MB/s eta 0:03:35\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 9.2 MB/s eta 0:03:35\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 9.2 MB/s eta 0:03:35\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 9.2 MB/s eta 0:03:35\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 9.2 MB/s eta 0:03:35\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 9.2 MB/s eta 0:03:35\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 9.2 MB/s eta 0:03:35\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 9.2 MB/s eta 0:03:35\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 9.2 MB/s eta 0:03:35\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 9.2 MB/s eta 0:03:35\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 9.2 MB/s eta 0:03:35\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 9.2 MB/s eta 0:03:35\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 9.2 MB/s eta 0:03:35\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 9.2 MB/s eta 0:03:35\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 9.2 MB/s eta 0:03:35\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 9.2 MB/s eta 0:03:35\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 9.2 MB/s eta 0:03:35\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 9.2 MB/s eta 0:03:35\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 9.2 MB/s eta 0:03:35\n",
      "   ----------- ---------------------------- 0.8/2.8 GB 9.2 MB/s eta 0:03:35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Connection timed out while downloading.\n",
      "ERROR: Could not install packages due to an OSError: [WinError 32] The process cannot access the file because it is being used by another process: 'C:\\\\Users\\\\SHRIOM\\\\AppData\\\\Local\\\\Temp\\\\pip-unpack-rtna5imo\\\\torch-2.7.1+cu118-cp313-cp313-win_amd64.whl'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting efficientnet-pytorch\n",
      "  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting torch (from efficientnet-pytorch)\n",
      "  Downloading torch-2.7.1-cp313-cp313-win_amd64.whl.metadata (28 kB)\n",
      "Collecting filelock (from torch->efficientnet-pytorch)\n",
      "  Downloading filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting typing-extensions>=4.10.0 (from torch->efficientnet-pytorch)\n",
      "  Downloading typing_extensions-4.14.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting sympy>=1.13.3 (from torch->efficientnet-pytorch)\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch->efficientnet-pytorch)\n",
      "  Downloading networkx-3.5-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting jinja2 (from torch->efficientnet-pytorch)\n",
      "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting fsspec (from torch->efficientnet-pytorch)\n",
      "  Downloading fsspec-2025.7.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting setuptools (from torch->efficientnet-pytorch)\n",
      "  Using cached setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch->efficientnet-pytorch)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch->efficientnet-pytorch)\n",
      "  Downloading MarkupSafe-3.0.2-cp313-cp313-win_amd64.whl.metadata (4.1 kB)\n",
      "Downloading torch-2.7.1-cp313-cp313-win_amd64.whl (216.1 MB)\n",
      "   ---------------------------------------- 0.0/216.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.3/216.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.0/216.1 MB 3.8 MB/s eta 0:00:57\n",
      "   ---------------------------------------- 1.8/216.1 MB 4.0 MB/s eta 0:00:54\n",
      "    --------------------------------------- 2.9/216.1 MB 4.2 MB/s eta 0:00:52\n",
      "    --------------------------------------- 3.9/216.1 MB 4.5 MB/s eta 0:00:48\n",
      "    --------------------------------------- 4.7/216.1 MB 4.5 MB/s eta 0:00:48\n",
      "   - -------------------------------------- 6.0/216.1 MB 4.7 MB/s eta 0:00:45\n",
      "   - -------------------------------------- 7.6/216.1 MB 5.1 MB/s eta 0:00:42\n",
      "   - -------------------------------------- 9.4/216.1 MB 5.4 MB/s eta 0:00:38\n",
      "   - -------------------------------------- 10.7/216.1 MB 5.6 MB/s eta 0:00:37\n",
      "   -- ------------------------------------- 13.1/216.1 MB 6.1 MB/s eta 0:00:34\n",
      "   -- ------------------------------------- 15.2/216.1 MB 6.4 MB/s eta 0:00:32\n",
      "   --- ------------------------------------ 17.6/216.1 MB 6.9 MB/s eta 0:00:29\n",
      "   --- ------------------------------------ 20.4/216.1 MB 7.4 MB/s eta 0:00:27\n",
      "   ---- ----------------------------------- 23.6/216.1 MB 7.9 MB/s eta 0:00:25\n",
      "   ---- ----------------------------------- 27.0/216.1 MB 8.4 MB/s eta 0:00:23\n",
      "   ----- ---------------------------------- 30.9/216.1 MB 9.0 MB/s eta 0:00:21\n",
      "   ------ --------------------------------- 34.9/216.1 MB 9.6 MB/s eta 0:00:19\n",
      "   ------- -------------------------------- 38.8/216.1 MB 10.2 MB/s eta 0:00:18\n",
      "   -------- ------------------------------- 43.8/216.1 MB 10.8 MB/s eta 0:00:16\n",
      "   --------- ------------------------------ 48.8/216.1 MB 11.4 MB/s eta 0:00:15\n",
      "   ---------- ----------------------------- 54.5/216.1 MB 12.2 MB/s eta 0:00:14\n",
      "   ----------- ---------------------------- 59.8/216.1 MB 12.7 MB/s eta 0:00:13\n",
      "   ------------ --------------------------- 65.3/216.1 MB 13.3 MB/s eta 0:00:12\n",
      "   ------------- -------------------------- 71.6/216.1 MB 14.0 MB/s eta 0:00:11\n",
      "   -------------- ------------------------- 76.8/216.1 MB 14.4 MB/s eta 0:00:10\n",
      "   --------------- ------------------------ 81.8/216.1 MB 14.8 MB/s eta 0:00:10\n",
      "   ---------------- ----------------------- 87.6/216.1 MB 15.2 MB/s eta 0:00:09\n",
      "   ----------------- ---------------------- 93.1/216.1 MB 15.6 MB/s eta 0:00:08\n",
      "   ------------------ --------------------- 98.6/216.1 MB 16.0 MB/s eta 0:00:08\n",
      "   ------------------ -------------------- 104.9/216.1 MB 16.4 MB/s eta 0:00:07\n",
      "   -------------------- ------------------ 111.7/216.1 MB 16.9 MB/s eta 0:00:07\n",
      "   --------------------- ----------------- 116.4/216.1 MB 17.2 MB/s eta 0:00:06\n",
      "   ---------------------- ---------------- 121.9/216.1 MB 17.4 MB/s eta 0:00:06\n",
      "   ----------------------- --------------- 127.9/216.1 MB 17.7 MB/s eta 0:00:05\n",
      "   ------------------------ -------------- 134.0/216.1 MB 18.0 MB/s eta 0:00:05\n",
      "   ------------------------- ------------- 139.5/216.1 MB 18.2 MB/s eta 0:00:05\n",
      "   ------------------------- ------------- 140.2/216.1 MB 18.2 MB/s eta 0:00:05\n",
      "   -------------------------- ------------ 147.8/216.1 MB 18.3 MB/s eta 0:00:04\n",
      "   --------------------------- ----------- 154.4/216.1 MB 18.7 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 159.4/216.1 MB 18.8 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 160.4/216.1 MB 18.4 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 160.4/216.1 MB 18.4 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 160.4/216.1 MB 18.4 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 160.4/216.1 MB 18.4 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 160.4/216.1 MB 18.4 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 160.4/216.1 MB 18.4 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 160.4/216.1 MB 18.4 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 160.4/216.1 MB 18.4 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 160.4/216.1 MB 18.4 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 160.4/216.1 MB 18.4 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 160.4/216.1 MB 18.4 MB/s eta 0:00:04\n",
      "   ----------------------------- --------- 161.0/216.1 MB 14.7 MB/s eta 0:00:04\n",
      "   ----------------------------- --------- 161.7/216.1 MB 14.5 MB/s eta 0:00:04\n",
      "   ----------------------------- --------- 164.9/216.1 MB 14.4 MB/s eta 0:00:04\n",
      "   ------------------------------ -------- 166.5/216.1 MB 14.3 MB/s eta 0:00:04\n",
      "   ------------------------------ -------- 168.3/216.1 MB 14.2 MB/s eta 0:00:04\n",
      "   ------------------------------ -------- 169.9/216.1 MB 14.1 MB/s eta 0:00:04\n",
      "   ------------------------------- ------- 174.6/216.1 MB 14.2 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 180.4/216.1 MB 14.4 MB/s eta 0:00:03\n",
      "   --------------------------------- ----- 186.6/216.1 MB 14.7 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 192.7/216.1 MB 14.9 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 199.0/216.1 MB 15.2 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 204.5/216.1 MB 15.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 209.5/216.1 MB 15.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  215.0/216.1 MB 15.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  216.0/216.1 MB 15.7 MB/s eta 0:00:01\n",
      "   --------------------------------------- 216.1/216.1 MB 15.3 MB/s eta 0:00:00\n",
      "Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "   ---------------------------------------- 0.0/6.3 MB ? eta -:--:--\n",
      "   ------------------- -------------------- 3.1/6.3 MB 15.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.3/6.3 MB 14.9 MB/s eta 0:00:00\n",
      "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "   ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "   --------------------------------------- 536.2/536.2 kB 18.3 MB/s eta 0:00:00\n",
      "Downloading typing_extensions-4.14.1-py3-none-any.whl (43 kB)\n",
      "Downloading filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Downloading fsspec-2025.7.0-py3-none-any.whl (199 kB)\n",
      "Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Downloading MarkupSafe-3.0.2-cp313-cp313-win_amd64.whl (15 kB)\n",
      "Downloading networkx-3.5-py3-none-any.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.0/2.0 MB 13.5 MB/s eta 0:00:00\n",
      "Using cached setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
      "Building wheels for collected packages: efficientnet-pytorch\n",
      "  Building wheel for efficientnet-pytorch (pyproject.toml): started\n",
      "  Building wheel for efficientnet-pytorch (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16519 sha256=76f4ff4ec3a8330cee777da2773db7e185d7182fa7127448d0fa0172387d6d67\n",
      "  Stored in directory: c:\\users\\shriom\\appdata\\local\\pip\\cache\\wheels\\5b\\2f\\2c\\f72934c756bb8333dc80c448b1c97e40665b27b7fd15d6be9f\n",
      "Successfully built efficientnet-pytorch\n",
      "Installing collected packages: mpmath, typing-extensions, sympy, setuptools, networkx, MarkupSafe, fsspec, filelock, jinja2, torch, efficientnet-pytorch\n",
      "\n",
      "   ----------------------------------------  0/11 [mpmath]\n",
      "   ----------------------------------------  0/11 [mpmath]\n",
      "   ------- --------------------------------  2/11 [sympy]\n",
      "   ------- --------------------------------  2/11 [sympy]\n",
      "   ------- --------------------------------  2/11 [sympy]\n",
      "   ------- --------------------------------  2/11 [sympy]\n",
      "   ------- --------------------------------  2/11 [sympy]\n",
      "   ------- --------------------------------  2/11 [sympy]\n",
      "   ------- --------------------------------  2/11 [sympy]\n",
      "   ------- --------------------------------  2/11 [sympy]\n",
      "   ------- --------------------------------  2/11 [sympy]\n",
      "   ------- --------------------------------  2/11 [sympy]\n",
      "   ------- --------------------------------  2/11 [sympy]\n",
      "   ------- --------------------------------  2/11 [sympy]\n",
      "   ------- --------------------------------  2/11 [sympy]\n",
      "   ------- --------------------------------  2/11 [sympy]\n",
      "   ------- --------------------------------  2/11 [sympy]\n",
      "   ------- --------------------------------  2/11 [sympy]\n",
      "   ------- --------------------------------  2/11 [sympy]\n",
      "   ------- --------------------------------  2/11 [sympy]\n",
      "   ------- --------------------------------  2/11 [sympy]\n",
      "   ------- --------------------------------  2/11 [sympy]\n",
      "   ------- --------------------------------  2/11 [sympy]\n",
      "   ------- --------------------------------  2/11 [sympy]\n",
      "   ------- --------------------------------  2/11 [sympy]\n",
      "   ------- --------------------------------  2/11 [sympy]\n",
      "   ------- --------------------------------  2/11 [sympy]\n",
      "   ------- --------------------------------  2/11 [sympy]\n",
      "   ------- --------------------------------  2/11 [sympy]\n",
      "   ------- --------------------------------  2/11 [sympy]\n",
      "   ------- --------------------------------  2/11 [sympy]\n",
      "   ------- --------------------------------  2/11 [sympy]\n",
      "   ------- --------------------------------  2/11 [sympy]\n",
      "   ------- --------------------------------  2/11 [sympy]\n",
      "   ------- --------------------------------  2/11 [sympy]\n",
      "   ------- --------------------------------  2/11 [sympy]\n",
      "   ------- --------------------------------  2/11 [sympy]\n",
      "   ------- --------------------------------  2/11 [sympy]\n",
      "   ------- --------------------------------  2/11 [sympy]\n",
      "   ---------- -----------------------------  3/11 [setuptools]\n",
      "   ---------- -----------------------------  3/11 [setuptools]\n",
      "   ---------- -----------------------------  3/11 [setuptools]\n",
      "   ---------- -----------------------------  3/11 [setuptools]\n",
      "   ---------- -----------------------------  3/11 [setuptools]\n",
      "   ---------- -----------------------------  3/11 [setuptools]\n",
      "   ---------- -----------------------------  3/11 [setuptools]\n",
      "   -------------- -------------------------  4/11 [networkx]\n",
      "   -------------- -------------------------  4/11 [networkx]\n",
      "   -------------- -------------------------  4/11 [networkx]\n",
      "   -------------- -------------------------  4/11 [networkx]\n",
      "   -------------- -------------------------  4/11 [networkx]\n",
      "   -------------- -------------------------  4/11 [networkx]\n",
      "   -------------- -------------------------  4/11 [networkx]\n",
      "   -------------- -------------------------  4/11 [networkx]\n",
      "   -------------- -------------------------  4/11 [networkx]\n",
      "   -------------- -------------------------  4/11 [networkx]\n",
      "   --------------------- ------------------  6/11 [fsspec]\n",
      "   ----------------------------- ----------  8/11 [jinja2]\n",
      "   -------------------------------- -------  9/11 [torch]\n",
      "   -------------------------------- -------  9/11 [torch]\n",
      "   -------------------------------- -------  9/11 [torch]\n",
      "   -------------------------------- -------  9/11 [torch]\n",
      "   -------------------------------- -------  9/11 [torch]\n",
      "   -------------------------------- -------  9/11 [torch]\n",
      "   -------------------------------- -------  9/11 [torch]\n",
      "   -------------------------------- -------  9/11 [torch]\n",
      "   -------------------------------- -------  9/11 [torch]\n",
      "   -------------------------------- -------  9/11 [torch]\n",
      "   -------------------------------- -------  9/11 [torch]\n",
      "   -------------------------------- -------  9/11 [torch]\n",
      "   -------------------------------- -------  9/11 [torch]\n",
      "   -------------------------------- -------  9/11 [torch]\n",
      "   -------------------------------- -------  9/11 [torch]\n",
      "   -------------------------------- -------  9/11 [torch]\n",
      "   -------------------------------- -------  9/11 [torch]\n",
      "   -------------------------------- -------  9/11 [torch]\n",
      "   -------------------------------- -------  9/11 [torch]\n",
      "   -------------------------------- -------  9/11 [torch]\n",
      "   -------------------------------- -------  9/11 [torch]\n",
      "   -------------------------------- -------  9/11 [torch]\n",
      "   -------------------------------- -------  9/11 [torch]\n",
      "   -------------------------------- -------  9/11 [torch]\n",
      "   -------------------------------- -------  9/11 [torch]\n",
      "   -------------------------------- -------  9/11 [torch]\n",
      "   -------------------------------- -------  9/11 [torch]\n",
      "   -------------------------------- -------  9/11 [torch]\n",
      "   -------------------------------- -------  9/11 [torch]\n",
      "   -------------------------------- -------  9/11 [torch]\n",
      "   -------------------------------- -------  9/11 [torch]\n",
      "   -------------------------------- -------  9/11 [torch]\n",
      "   -------------------------------- -------  9/11 [torch]\n",
      "   -------------------------------- -------  9/11 [torch]\n",
      "   -------------------------------- -------  9/11 [torch]\n",
      "   -------------------------------- -------  9/11 [torch]\n",
      "   -------------------------------- -------  9/11 [torch]\n",
      "   -------------------------------- -------  9/11 [torch]\n",
      "   -------------------------------- -------  9/11 [torch]\n",
      "   -------------------------------- -------  9/11 [torch]\n",
      "   -------------------------------- -------  9/11 [torch]\n",
      "   -------------------------------- -------  9/11 [torch]\n",
      "   -------------------------------- -------  9/11 [torch]\n",
      "   -------------------------------- -------  9/11 [torch]\n",
      "   -------------------------------- -------  9/11 [torch]\n",
      "   -------------------------------- -------  9/11 [torch]\n",
      "   -------------------------------- -------  9/11 [torch]\n",
      "   -------------------------------- -------  9/11 [torch]\n",
      "   -------------------------------- -------  9/11 [torch]\n",
      "   -------------------------------- -------  9/11 [torch]\n",
      "   -------------------------------- -------  9/11 [torch]\n",
      "   -------------------------------- -------  9/11 [torch]\n",
      "   -------------------------------- -------  9/11 [torch]\n",
      "   -------------------------------- -------  9/11 [torch]\n",
      "   -------------------------------- -------  9/11 [torch]\n",
      "   -------------------------------- -------  9/11 [torch]\n",
      "   -------------------------------- -------  9/11 [torch]\n",
      "   -------------------------------- -------  9/11 [torch]\n",
      "   -------------------------------- -------  9/11 [torch]\n",
      "   -------------------------------- -------  9/11 [torch]\n",
      "   -------------------------------- -------  9/11 [torch]\n",
      "   -------------------------------- -------  9/11 [torch]\n",
      "   -------------------------------- -------  9/11 [torch]\n",
      "   -------------------------------- -------  9/11 [torch]\n",
      "   -------------------------------- -------  9/11 [torch]\n",
      "   -------------------------------- -------  9/11 [torch]\n",
      "   -------------------------------- -------  9/11 [torch]\n",
      "   -------------------------------- -------  9/11 [torch]\n",
      "   -------------------------------- -------  9/11 [torch]\n",
      "   -------------------------------- -------  9/11 [torch]\n",
      "   -------------------------------- -------  9/11 [torch]\n",
      "   -------------------------------- -------  9/11 [torch]\n",
      "   -------------------------------- -------  9/11 [torch]\n",
      "   -------------------------------- -------  9/11 [torch]\n",
      "   -------------------------------- -------  9/11 [torch]\n",
      "   -------------------------------- -------  9/11 [torch]\n",
      "   -------------------------------- -------  9/11 [torch]\n",
      "   -------------------------------- -------  9/11 [torch]\n",
      "   -------------------------------- -------  9/11 [torch]\n",
      "   -------------------------------- -------  9/11 [torch]\n",
      "   -------------------------------- -------  9/11 [torch]\n",
      "   -------------------------------- -------  9/11 [torch]\n",
      "   -------------------------------- -------  9/11 [torch]\n",
      "   -------------------------------- -------  9/11 [torch]\n",
      "   -------------------------------- -------  9/11 [torch]\n",
      "   -------------------------------- -------  9/11 [torch]\n",
      "   -------------------------------- -------  9/11 [torch]\n",
      "   -------------------------------- -------  9/11 [torch]\n",
      "   -------------------------------- -------  9/11 [torch]\n",
      "   -------------------------------- -------  9/11 [torch]\n",
      "   -------------------------------- -------  9/11 [torch]\n",
      "   -------------------------------- -------  9/11 [torch]\n",
      "   -------------------------------- -------  9/11 [torch]\n",
      "   -------------------------------- -------  9/11 [torch]\n",
      "   -------------------------------- -------  9/11 [torch]\n",
      "   -------------------------------- -------  9/11 [torch]\n",
      "   -------------------------------- -------  9/11 [torch]\n",
      "   -------------------------------- -------  9/11 [torch]\n",
      "   -------------------------------- -------  9/11 [torch]\n",
      "   ---------------------------------------- 11/11 [efficientnet-pytorch]\n",
      "\n",
      "Successfully installed MarkupSafe-3.0.2 efficientnet-pytorch-0.7.1 filelock-3.18.0 fsspec-2025.7.0 jinja2-3.1.6 mpmath-1.3.0 networkx-3.5 setuptools-80.9.0 sympy-1.14.0 torch-2.7.1 typing-extensions-4.14.1\n",
      "Collecting pillow\n",
      "  Downloading pillow-11.3.0-cp313-cp313-win_amd64.whl.metadata (9.2 kB)\n",
      "Downloading pillow-11.3.0-cp313-cp313-win_amd64.whl (7.0 MB)\n",
      "   ---------------------------------------- 0.0/7.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/7.0 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/7.0 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 1.3/7.0 MB 4.5 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 2.6/7.0 MB 5.0 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 4.2/7.0 MB 5.8 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 5.8/7.0 MB 6.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 7.0/7.0 MB 6.4 MB/s eta 0:00:00\n",
      "Installing collected packages: pillow\n",
      "Successfully installed pillow-11.3.0\n",
      "Collecting pillow\n",
      "  Downloading pillow-11.3.0-cp313-cp313-win_amd64.whl.metadata (9.2 kB)\n",
      "Downloading pillow-11.3.0-cp313-cp313-win_amd64.whl (7.0 MB)\n",
      "   ---------------------------------------- 0.0/7.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/7.0 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/7.0 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 1.3/7.0 MB 4.5 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 2.6/7.0 MB 5.0 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 4.2/7.0 MB 5.8 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 5.8/7.0 MB 6.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 7.0/7.0 MB 6.4 MB/s eta 0:00:00\n",
      "Installing collected packages: pillow\n",
      "Successfully installed pillow-11.3.0\n",
      "Collecting numpy\n",
      "  Downloading numpy-2.3.1-cp313-cp313-win_amd64.whl.metadata (60 kB)\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.3.1-cp313-cp313-win_amd64.whl.metadata (19 kB)\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.10.3-cp313-cp313-win_amd64.whl.metadata (11 kB)\n",
      "Collecting seaborn\n",
      "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\shriom\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.3.2-cp313-cp313-win_amd64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.59.0-cp313-cp313-win_amd64.whl.metadata (110 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.8-cp313-cp313-win_amd64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\shriom\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\shriom\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (11.3.0)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Downloading pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\shriom\\appdata\\roaming\\python\\python313\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading numpy-2.3.1-cp313-cp313-win_amd64.whl (12.7 MB)\n",
      "   ---------------------------------------- 0.0/12.7 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.7 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 1.3/12.7 MB 4.9 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 2.1/12.7 MB 5.5 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 2.6/12.7 MB 4.0 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 3.7/12.7 MB 4.1 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 5.0/12.7 MB 4.5 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 6.3/12.7 MB 4.7 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 7.1/12.7 MB 4.8 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 7.9/12.7 MB 4.7 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 9.4/12.7 MB 4.9 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 10.5/12.7 MB 5.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 11.5/12.7 MB 4.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.6/12.7 MB 5.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.7/12.7 MB 4.8 MB/s eta 0:00:00\n",
      "Downloading pandas-2.3.1-cp313-cp313-win_amd64.whl (11.0 MB)\n",
      "   ---------------------------------------- 0.0/11.0 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/11.0 MB 27.5 MB/s eta 0:00:01\n",
      "   ------ --------------------------------- 1.8/11.0 MB 9.1 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 2.9/11.0 MB 6.3 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 3.4/11.0 MB 5.6 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 4.2/11.0 MB 4.7 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 5.8/11.0 MB 5.0 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 7.6/11.0 MB 5.7 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 9.4/11.0 MB 6.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.7/11.0 MB 6.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.0/11.0 MB 6.0 MB/s eta 0:00:00\n",
      "Downloading matplotlib-3.10.3-cp313-cp313-win_amd64.whl (8.1 MB)\n",
      "   ---------------------------------------- 0.0/8.1 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 1.0/8.1 MB 4.7 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 2.9/8.1 MB 6.8 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 5.0/8.1 MB 8.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 7.3/8.1 MB 8.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 8.1/8.1 MB 8.9 MB/s eta 0:00:00\n",
      "Downloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Downloading contourpy-1.3.2-cp313-cp313-win_amd64.whl (223 kB)\n",
      "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.59.0-cp313-cp313-win_amd64.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   ------------------ --------------------- 1.0/2.2 MB 8.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.2/2.2 MB 6.2 MB/s eta 0:00:00\n",
      "Downloading kiwisolver-1.4.8-cp313-cp313-win_amd64.whl (71 kB)\n",
      "Downloading pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Installing collected packages: pytz, tzdata, pyparsing, numpy, kiwisolver, fonttools, cycler, pandas, contourpy, matplotlib, seaborn\n",
      "\n",
      "   ----------------------------------------  0/11 [pytz]\n",
      "   ----------------------------------------  0/11 [pytz]\n",
      "   --- ------------------------------------  1/11 [tzdata]\n",
      "   --- ------------------------------------  1/11 [tzdata]\n",
      "   ------- --------------------------------  2/11 [pyparsing]\n",
      "   ---------- -----------------------------  3/11 [numpy]\n",
      "   ---------- -----------------------------  3/11 [numpy]\n",
      "   ---------- -----------------------------  3/11 [numpy]\n",
      "   ---------- -----------------------------  3/11 [numpy]\n",
      "   ---------- -----------------------------  3/11 [numpy]\n",
      "   ---------- -----------------------------  3/11 [numpy]\n",
      "   ---------- -----------------------------  3/11 [numpy]\n",
      "   ---------- -----------------------------  3/11 [numpy]\n",
      "   ---------- -----------------------------  3/11 [numpy]\n",
      "   ---------- -----------------------------  3/11 [numpy]\n",
      "   ---------- -----------------------------  3/11 [numpy]\n",
      "   ---------- -----------------------------  3/11 [numpy]\n",
      "   ---------- -----------------------------  3/11 [numpy]\n",
      "   ------------------ ---------------------  5/11 [fonttools]\n",
      "   ------------------ ---------------------  5/11 [fonttools]\n",
      "   ------------------ ---------------------  5/11 [fonttools]\n",
      "   ------------------ ---------------------  5/11 [fonttools]\n",
      "   ------------------ ---------------------  5/11 [fonttools]\n",
      "   ------------------ ---------------------  5/11 [fonttools]\n",
      "   ------------------------- --------------  7/11 [pandas]\n",
      "   ------------------------- --------------  7/11 [pandas]\n",
      "   ------------------------- --------------  7/11 [pandas]\n",
      "   ------------------------- --------------  7/11 [pandas]\n",
      "   ------------------------- --------------  7/11 [pandas]\n",
      "   ------------------------- --------------  7/11 [pandas]\n",
      "   ------------------------- --------------  7/11 [pandas]\n",
      "   ------------------------- --------------  7/11 [pandas]\n",
      "   ------------------------- --------------  7/11 [pandas]\n",
      "   ------------------------- --------------  7/11 [pandas]\n",
      "   ------------------------- --------------  7/11 [pandas]\n",
      "   ------------------------- --------------  7/11 [pandas]\n",
      "   ------------------------- --------------  7/11 [pandas]\n",
      "   ------------------------- --------------  7/11 [pandas]\n",
      "   ------------------------- --------------  7/11 [pandas]\n",
      "   ------------------------- --------------  7/11 [pandas]\n",
      "   ------------------------- --------------  7/11 [pandas]\n",
      "   ------------------------- --------------  7/11 [pandas]\n",
      "   ------------------------- --------------  7/11 [pandas]\n",
      "   ------------------------- --------------  7/11 [pandas]\n",
      "   ------------------------- --------------  7/11 [pandas]\n",
      "   ------------------------- --------------  7/11 [pandas]\n",
      "   ------------------------- --------------  7/11 [pandas]\n",
      "   ------------------------- --------------  7/11 [pandas]\n",
      "   ------------------------- --------------  7/11 [pandas]\n",
      "   ------------------------- --------------  7/11 [pandas]\n",
      "   ------------------------- --------------  7/11 [pandas]\n",
      "   ------------------------- --------------  7/11 [pandas]\n",
      "   ------------------------- --------------  7/11 [pandas]\n",
      "   ------------------------- --------------  7/11 [pandas]\n",
      "   -------------------------------- -------  9/11 [matplotlib]\n",
      "   -------------------------------- -------  9/11 [matplotlib]\n",
      "   -------------------------------- -------  9/11 [matplotlib]\n",
      "   -------------------------------- -------  9/11 [matplotlib]\n",
      "   -------------------------------- -------  9/11 [matplotlib]\n",
      "   -------------------------------- -------  9/11 [matplotlib]\n",
      "   -------------------------------- -------  9/11 [matplotlib]\n",
      "   -------------------------------- -------  9/11 [matplotlib]\n",
      "   -------------------------------- -------  9/11 [matplotlib]\n",
      "   -------------------------------- -------  9/11 [matplotlib]\n",
      "   ------------------------------------ --- 10/11 [seaborn]\n",
      "   ---------------------------------------- 11/11 [seaborn]\n",
      "\n",
      "Successfully installed contourpy-1.3.2 cycler-0.12.1 fonttools-4.59.0 kiwisolver-1.4.8 matplotlib-3.10.3 numpy-2.3.1 pandas-2.3.1 pyparsing-3.2.3 pytz-2025.2 seaborn-0.13.2 tzdata-2025.2\n",
      "Collecting numpy\n",
      "  Downloading numpy-2.3.1-cp313-cp313-win_amd64.whl.metadata (60 kB)\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.3.1-cp313-cp313-win_amd64.whl.metadata (19 kB)\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.10.3-cp313-cp313-win_amd64.whl.metadata (11 kB)\n",
      "Collecting seaborn\n",
      "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\shriom\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.3.2-cp313-cp313-win_amd64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.59.0-cp313-cp313-win_amd64.whl.metadata (110 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.8-cp313-cp313-win_amd64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\shriom\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\shriom\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (11.3.0)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Downloading pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\shriom\\appdata\\roaming\\python\\python313\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading numpy-2.3.1-cp313-cp313-win_amd64.whl (12.7 MB)\n",
      "   ---------------------------------------- 0.0/12.7 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.7 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 1.3/12.7 MB 4.9 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 2.1/12.7 MB 5.5 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 2.6/12.7 MB 4.0 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 3.7/12.7 MB 4.1 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 5.0/12.7 MB 4.5 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 6.3/12.7 MB 4.7 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 7.1/12.7 MB 4.8 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 7.9/12.7 MB 4.7 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 9.4/12.7 MB 4.9 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 10.5/12.7 MB 5.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 11.5/12.7 MB 4.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.6/12.7 MB 5.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.7/12.7 MB 4.8 MB/s eta 0:00:00\n",
      "Downloading pandas-2.3.1-cp313-cp313-win_amd64.whl (11.0 MB)\n",
      "   ---------------------------------------- 0.0/11.0 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/11.0 MB 27.5 MB/s eta 0:00:01\n",
      "   ------ --------------------------------- 1.8/11.0 MB 9.1 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 2.9/11.0 MB 6.3 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 3.4/11.0 MB 5.6 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 4.2/11.0 MB 4.7 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 5.8/11.0 MB 5.0 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 7.6/11.0 MB 5.7 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 9.4/11.0 MB 6.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.7/11.0 MB 6.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.0/11.0 MB 6.0 MB/s eta 0:00:00\n",
      "Downloading matplotlib-3.10.3-cp313-cp313-win_amd64.whl (8.1 MB)\n",
      "   ---------------------------------------- 0.0/8.1 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 1.0/8.1 MB 4.7 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 2.9/8.1 MB 6.8 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 5.0/8.1 MB 8.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 7.3/8.1 MB 8.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 8.1/8.1 MB 8.9 MB/s eta 0:00:00\n",
      "Downloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Downloading contourpy-1.3.2-cp313-cp313-win_amd64.whl (223 kB)\n",
      "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.59.0-cp313-cp313-win_amd64.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   ------------------ --------------------- 1.0/2.2 MB 8.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.2/2.2 MB 6.2 MB/s eta 0:00:00\n",
      "Downloading kiwisolver-1.4.8-cp313-cp313-win_amd64.whl (71 kB)\n",
      "Downloading pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Installing collected packages: pytz, tzdata, pyparsing, numpy, kiwisolver, fonttools, cycler, pandas, contourpy, matplotlib, seaborn\n",
      "\n",
      "   ----------------------------------------  0/11 [pytz]\n",
      "   ----------------------------------------  0/11 [pytz]\n",
      "   --- ------------------------------------  1/11 [tzdata]\n",
      "   --- ------------------------------------  1/11 [tzdata]\n",
      "   ------- --------------------------------  2/11 [pyparsing]\n",
      "   ---------- -----------------------------  3/11 [numpy]\n",
      "   ---------- -----------------------------  3/11 [numpy]\n",
      "   ---------- -----------------------------  3/11 [numpy]\n",
      "   ---------- -----------------------------  3/11 [numpy]\n",
      "   ---------- -----------------------------  3/11 [numpy]\n",
      "   ---------- -----------------------------  3/11 [numpy]\n",
      "   ---------- -----------------------------  3/11 [numpy]\n",
      "   ---------- -----------------------------  3/11 [numpy]\n",
      "   ---------- -----------------------------  3/11 [numpy]\n",
      "   ---------- -----------------------------  3/11 [numpy]\n",
      "   ---------- -----------------------------  3/11 [numpy]\n",
      "   ---------- -----------------------------  3/11 [numpy]\n",
      "   ---------- -----------------------------  3/11 [numpy]\n",
      "   ------------------ ---------------------  5/11 [fonttools]\n",
      "   ------------------ ---------------------  5/11 [fonttools]\n",
      "   ------------------ ---------------------  5/11 [fonttools]\n",
      "   ------------------ ---------------------  5/11 [fonttools]\n",
      "   ------------------ ---------------------  5/11 [fonttools]\n",
      "   ------------------ ---------------------  5/11 [fonttools]\n",
      "   ------------------------- --------------  7/11 [pandas]\n",
      "   ------------------------- --------------  7/11 [pandas]\n",
      "   ------------------------- --------------  7/11 [pandas]\n",
      "   ------------------------- --------------  7/11 [pandas]\n",
      "   ------------------------- --------------  7/11 [pandas]\n",
      "   ------------------------- --------------  7/11 [pandas]\n",
      "   ------------------------- --------------  7/11 [pandas]\n",
      "   ------------------------- --------------  7/11 [pandas]\n",
      "   ------------------------- --------------  7/11 [pandas]\n",
      "   ------------------------- --------------  7/11 [pandas]\n",
      "   ------------------------- --------------  7/11 [pandas]\n",
      "   ------------------------- --------------  7/11 [pandas]\n",
      "   ------------------------- --------------  7/11 [pandas]\n",
      "   ------------------------- --------------  7/11 [pandas]\n",
      "   ------------------------- --------------  7/11 [pandas]\n",
      "   ------------------------- --------------  7/11 [pandas]\n",
      "   ------------------------- --------------  7/11 [pandas]\n",
      "   ------------------------- --------------  7/11 [pandas]\n",
      "   ------------------------- --------------  7/11 [pandas]\n",
      "   ------------------------- --------------  7/11 [pandas]\n",
      "   ------------------------- --------------  7/11 [pandas]\n",
      "   ------------------------- --------------  7/11 [pandas]\n",
      "   ------------------------- --------------  7/11 [pandas]\n",
      "   ------------------------- --------------  7/11 [pandas]\n",
      "   ------------------------- --------------  7/11 [pandas]\n",
      "   ------------------------- --------------  7/11 [pandas]\n",
      "   ------------------------- --------------  7/11 [pandas]\n",
      "   ------------------------- --------------  7/11 [pandas]\n",
      "   ------------------------- --------------  7/11 [pandas]\n",
      "   ------------------------- --------------  7/11 [pandas]\n",
      "   -------------------------------- -------  9/11 [matplotlib]\n",
      "   -------------------------------- -------  9/11 [matplotlib]\n",
      "   -------------------------------- -------  9/11 [matplotlib]\n",
      "   -------------------------------- -------  9/11 [matplotlib]\n",
      "   -------------------------------- -------  9/11 [matplotlib]\n",
      "   -------------------------------- -------  9/11 [matplotlib]\n",
      "   -------------------------------- -------  9/11 [matplotlib]\n",
      "   -------------------------------- -------  9/11 [matplotlib]\n",
      "   -------------------------------- -------  9/11 [matplotlib]\n",
      "   -------------------------------- -------  9/11 [matplotlib]\n",
      "   ------------------------------------ --- 10/11 [seaborn]\n",
      "   ---------------------------------------- 11/11 [seaborn]\n",
      "\n",
      "Successfully installed contourpy-1.3.2 cycler-0.12.1 fonttools-4.59.0 kiwisolver-1.4.8 matplotlib-3.10.3 numpy-2.3.1 pandas-2.3.1 pyparsing-3.2.3 pytz-2025.2 seaborn-0.13.2 tzdata-2025.2\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.7.0-cp313-cp313-win_amd64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy>=1.22.0 in c:\\users\\shriom\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn) (2.3.1)\n",
      "Collecting scipy>=1.8.0 (from scikit-learn)\n",
      "  Downloading scipy-1.16.0-cp313-cp313-win_amd64.whl.metadata (60 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.5.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.7.0-cp313-cp313-win_amd64.whl (10.7 MB)\n",
      "   ---------------------------------------- 0.0/10.7 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/10.7 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 1.0/10.7 MB 4.5 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 3.9/10.7 MB 8.5 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 7.3/10.7 MB 11.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.7/10.7 MB 13.1 MB/s eta 0:00:00\n",
      "Downloading joblib-1.5.1-py3-none-any.whl (307 kB)\n",
      "Downloading scipy-1.16.0-cp313-cp313-win_amd64.whl (38.4 MB)\n",
      "   ---------------------------------------- 0.0/38.4 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 3.7/38.4 MB 18.5 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 8.4/38.4 MB 20.4 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 12.3/38.4 MB 19.9 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 16.8/38.4 MB 20.4 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 20.2/38.4 MB 20.2 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 23.6/38.4 MB 18.9 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 26.7/38.4 MB 18.5 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 30.1/38.4 MB 18.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 34.6/38.4 MB 18.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.3/38.4 MB 18.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 38.4/38.4 MB 18.3 MB/s eta 0:00:00\n",
      "Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   -------------------- ------------------- 2/4 [joblib]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ---------------------------------------- 4/4 [scikit-learn]\n",
      "\n",
      "Successfully installed joblib-1.5.1 scikit-learn-1.7.0 scipy-1.16.0 threadpoolctl-3.6.0\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.7.0-cp313-cp313-win_amd64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy>=1.22.0 in c:\\users\\shriom\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn) (2.3.1)\n",
      "Collecting scipy>=1.8.0 (from scikit-learn)\n",
      "  Downloading scipy-1.16.0-cp313-cp313-win_amd64.whl.metadata (60 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.5.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.7.0-cp313-cp313-win_amd64.whl (10.7 MB)\n",
      "   ---------------------------------------- 0.0/10.7 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/10.7 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 1.0/10.7 MB 4.5 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 3.9/10.7 MB 8.5 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 7.3/10.7 MB 11.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.7/10.7 MB 13.1 MB/s eta 0:00:00\n",
      "Downloading joblib-1.5.1-py3-none-any.whl (307 kB)\n",
      "Downloading scipy-1.16.0-cp313-cp313-win_amd64.whl (38.4 MB)\n",
      "   ---------------------------------------- 0.0/38.4 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 3.7/38.4 MB 18.5 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 8.4/38.4 MB 20.4 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 12.3/38.4 MB 19.9 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 16.8/38.4 MB 20.4 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 20.2/38.4 MB 20.2 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 23.6/38.4 MB 18.9 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 26.7/38.4 MB 18.5 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 30.1/38.4 MB 18.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 34.6/38.4 MB 18.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.3/38.4 MB 18.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 38.4/38.4 MB 18.3 MB/s eta 0:00:00\n",
      "Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   -------------------- ------------------- 2/4 [joblib]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ---------------------------------------- 4/4 [scikit-learn]\n",
      "\n",
      "Successfully installed joblib-1.5.1 scikit-learn-1.7.0 scipy-1.16.0 threadpoolctl-3.6.0\n",
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.12.0.88-cp37-abi3-win_amd64.whl.metadata (19 kB)\n",
      "Collecting numpy<2.3.0,>=2 (from opencv-python)\n",
      "  Downloading numpy-2.2.6-cp313-cp313-win_amd64.whl.metadata (60 kB)\n",
      "Downloading opencv_python-4.12.0.88-cp37-abi3-win_amd64.whl (39.0 MB)\n",
      "   ---------------------------------------- 0.0/39.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.3/39.0 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.5/39.0 MB 1.8 MB/s eta 0:00:22\n",
      "   -- ------------------------------------- 2.4/39.0 MB 4.9 MB/s eta 0:00:08\n",
      "   ---- ----------------------------------- 4.5/39.0 MB 6.1 MB/s eta 0:00:06\n",
      "   ------ --------------------------------- 6.6/39.0 MB 7.1 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 8.9/39.0 MB 7.8 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 11.0/39.0 MB 8.3 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 13.4/39.0 MB 8.7 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 15.7/39.0 MB 9.0 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 18.1/39.0 MB 9.3 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 20.2/39.0 MB 9.4 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 22.3/39.0 MB 9.5 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 25.2/39.0 MB 9.8 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 27.5/39.0 MB 10.0 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 29.6/39.0 MB 10.0 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 32.0/39.0 MB 10.1 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 33.8/39.0 MB 10.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 35.9/39.0 MB 10.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 37.7/39.0 MB 10.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 39.0/39.0 MB 9.9 MB/s eta 0:00:00\n",
      "Downloading numpy-2.2.6-cp313-cp313-win_amd64.whl (12.6 MB)\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 2.9/12.6 MB 14.9 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 5.5/12.6 MB 12.9 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 7.9/12.6 MB 12.3 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 9.7/12.6 MB 11.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.6/12.6 MB 12.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.6/12.6 MB 11.9 MB/s eta 0:00:00\n",
      "Installing collected packages: numpy, opencv-python\n",
      "\n",
      "  Attempting uninstall: numpy\n",
      "\n",
      "    Found existing installation: numpy 2.3.1\n",
      "\n",
      "    Uninstalling numpy-2.3.1:\n",
      "\n",
      "      Successfully uninstalled numpy-2.3.1\n",
      "\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [opencv-python]\n",
      "   -------------------- ------------------- 1/2 [opencv-python]\n",
      "   -------------------- ------------------- 1/2 [opencv-python]\n",
      "   ---------------------------------------- 2/2 [opencv-python]\n",
      "\n",
      "Successfully installed numpy-2.2.6 opencv-python-4.12.0.88\n",
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.12.0.88-cp37-abi3-win_amd64.whl.metadata (19 kB)\n",
      "Collecting numpy<2.3.0,>=2 (from opencv-python)\n",
      "  Downloading numpy-2.2.6-cp313-cp313-win_amd64.whl.metadata (60 kB)\n",
      "Downloading opencv_python-4.12.0.88-cp37-abi3-win_amd64.whl (39.0 MB)\n",
      "   ---------------------------------------- 0.0/39.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.3/39.0 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.5/39.0 MB 1.8 MB/s eta 0:00:22\n",
      "   -- ------------------------------------- 2.4/39.0 MB 4.9 MB/s eta 0:00:08\n",
      "   ---- ----------------------------------- 4.5/39.0 MB 6.1 MB/s eta 0:00:06\n",
      "   ------ --------------------------------- 6.6/39.0 MB 7.1 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 8.9/39.0 MB 7.8 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 11.0/39.0 MB 8.3 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 13.4/39.0 MB 8.7 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 15.7/39.0 MB 9.0 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 18.1/39.0 MB 9.3 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 20.2/39.0 MB 9.4 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 22.3/39.0 MB 9.5 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 25.2/39.0 MB 9.8 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 27.5/39.0 MB 10.0 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 29.6/39.0 MB 10.0 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 32.0/39.0 MB 10.1 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 33.8/39.0 MB 10.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 35.9/39.0 MB 10.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 37.7/39.0 MB 10.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 39.0/39.0 MB 9.9 MB/s eta 0:00:00\n",
      "Downloading numpy-2.2.6-cp313-cp313-win_amd64.whl (12.6 MB)\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 2.9/12.6 MB 14.9 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 5.5/12.6 MB 12.9 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 7.9/12.6 MB 12.3 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 9.7/12.6 MB 11.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.6/12.6 MB 12.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.6/12.6 MB 11.9 MB/s eta 0:00:00\n",
      "Installing collected packages: numpy, opencv-python\n",
      "\n",
      "  Attempting uninstall: numpy\n",
      "\n",
      "    Found existing installation: numpy 2.3.1\n",
      "\n",
      "    Uninstalling numpy-2.3.1:\n",
      "\n",
      "      Successfully uninstalled numpy-2.3.1\n",
      "\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [opencv-python]\n",
      "   -------------------- ------------------- 1/2 [opencv-python]\n",
      "   -------------------- ------------------- 1/2 [opencv-python]\n",
      "   ---------------------------------------- 2/2 [opencv-python]\n",
      "\n",
      "Successfully installed numpy-2.2.6 opencv-python-4.12.0.88\n",
      "Collecting albumentations\n",
      "  Downloading albumentations-2.0.8-py3-none-any.whl.metadata (43 kB)\n",
      "Requirement already satisfied: numpy>=1.24.4 in c:\\users\\shriom\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from albumentations) (2.2.6)\n",
      "Requirement already satisfied: scipy>=1.10.0 in c:\\users\\shriom\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from albumentations) (1.16.0)\n",
      "Collecting PyYAML (from albumentations)\n",
      "  Downloading PyYAML-6.0.2-cp313-cp313-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting pydantic>=2.9.2 (from albumentations)\n",
      "  Downloading pydantic-2.11.7-py3-none-any.whl.metadata (67 kB)\n",
      "Collecting albucore==0.0.24 (from albumentations)\n",
      "  Downloading albucore-0.0.24-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting opencv-python-headless>=4.9.0.80 (from albumentations)\n",
      "  Downloading opencv_python_headless-4.12.0.88-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Collecting stringzilla>=3.10.4 (from albucore==0.0.24->albumentations)\n",
      "  Downloading stringzilla-3.12.5-cp313-cp313-win_amd64.whl.metadata (81 kB)\n",
      "Collecting simsimd>=5.9.2 (from albucore==0.0.24->albumentations)\n",
      "  Downloading simsimd-6.5.0-cp313-cp313-win_amd64.whl.metadata (72 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic>=2.9.2->albumentations)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic>=2.9.2->albumentations)\n",
      "  Downloading pydantic_core-2.33.2-cp313-cp313-win_amd64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in c:\\users\\shriom\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic>=2.9.2->albumentations) (4.14.1)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic>=2.9.2->albumentations)\n",
      "  Downloading typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Downloading albumentations-2.0.8-py3-none-any.whl (369 kB)\n",
      "Downloading albucore-0.0.24-py3-none-any.whl (15 kB)\n",
      "Downloading opencv_python_headless-4.12.0.88-cp37-abi3-win_amd64.whl (38.9 MB)\n",
      "   ---------------------------------------- 0.0/38.9 MB ? eta -:--:--\n",
      "   - -------------------------------------- 1.3/38.9 MB 7.5 MB/s eta 0:00:06\n",
      "   --- ------------------------------------ 3.4/38.9 MB 8.7 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 5.5/38.9 MB 8.9 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 7.6/38.9 MB 9.3 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 10.2/38.9 MB 9.9 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 13.4/38.9 MB 10.8 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 16.5/38.9 MB 11.5 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 19.9/38.9 MB 12.1 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 23.6/38.9 MB 12.7 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 27.0/38.9 MB 13.1 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 30.7/38.9 MB 13.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 34.3/38.9 MB 14.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.8/38.9 MB 14.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 38.9/38.9 MB 14.2 MB/s eta 0:00:00\n",
      "Downloading pydantic-2.11.7-py3-none-any.whl (444 kB)\n",
      "Downloading pydantic_core-2.33.2-cp313-cp313-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.0/2.0 MB 13.7 MB/s eta 0:00:00\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading simsimd-6.5.0-cp313-cp313-win_amd64.whl (94 kB)\n",
      "Downloading stringzilla-3.12.5-cp313-cp313-win_amd64.whl (80 kB)\n",
      "Downloading typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Downloading PyYAML-6.0.2-cp313-cp313-win_amd64.whl (156 kB)\n",
      "Installing collected packages: stringzilla, simsimd, typing-inspection, PyYAML, pydantic-core, opencv-python-headless, annotated-types, pydantic, albucore, albumentations\n",
      "\n",
      "   -------------------- -------------------  5/10 [opencv-python-headless]\n",
      "   -------------------- -------------------  5/10 [opencv-python-headless]\n",
      "   -------------------- -------------------  5/10 [opencv-python-headless]\n",
      "   -------------------- -------------------  5/10 [opencv-python-headless]\n",
      "   ---------------------------- -----------  7/10 [pydantic]\n",
      "   ---------------------------- -----------  7/10 [pydantic]\n",
      "   ------------------------------------ ---  9/10 [albumentations]\n",
      "   ---------------------------------------- 10/10 [albumentations]\n",
      "\n",
      "Successfully installed PyYAML-6.0.2 albucore-0.0.24 albumentations-2.0.8 annotated-types-0.7.0 opencv-python-headless-4.12.0.88 pydantic-2.11.7 pydantic-core-2.33.2 simsimd-6.5.0 stringzilla-3.12.5 typing-inspection-0.4.1\n",
      "Collecting pymongo\n",
      "  Downloading pymongo-4.13.2-cp313-cp313-win_amd64.whl.metadata (22 kB)\n",
      "Collecting dnspython<3.0.0,>=1.16.0 (from pymongo)\n",
      "  Downloading dnspython-2.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Downloading pymongo-4.13.2-cp313-cp313-win_amd64.whl (955 kB)\n",
      "   ---------------------------------------- 0.0/955.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/955.1 kB ? eta -:--:--\n",
      "   --------------------- ------------------ 524.3/955.1 kB 2.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 955.1/955.1 kB 2.0 MB/s eta 0:00:00\n",
      "Downloading dnspython-2.7.0-py3-none-any.whl (313 kB)\n",
      "Installing collected packages: dnspython, pymongo\n",
      "\n",
      "   ---------------------------------------- 0/2 [dnspython]\n",
      "   -------------------- ------------------- 1/2 [pymongo]\n",
      "   -------------------- ------------------- 1/2 [pymongo]\n",
      "   -------------------- ------------------- 1/2 [pymongo]\n",
      "   ---------------------------------------- 2/2 [pymongo]\n",
      "\n",
      "Successfully installed dnspython-2.7.0 pymongo-4.13.2\n",
      "Collecting requests\n",
      "  Downloading requests-2.32.4-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests)\n",
      "  Downloading charset_normalizer-3.4.2-cp313-cp313-win_amd64.whl.metadata (36 kB)\n",
      "Collecting idna<4,>=2.5 (from requests)\n",
      "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests)\n",
      "  Downloading urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests)\n",
      "  Downloading certifi-2025.7.14-py3-none-any.whl.metadata (2.4 kB)\n",
      "Downloading requests-2.32.4-py3-none-any.whl (64 kB)\n",
      "Downloading charset_normalizer-3.4.2-cp313-cp313-win_amd64.whl (105 kB)\n",
      "Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
      "Downloading urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Downloading certifi-2025.7.14-py3-none-any.whl (162 kB)\n",
      "Installing collected packages: urllib3, idna, charset_normalizer, certifi, requests\n",
      "\n",
      "   -------- ------------------------------- 1/5 [idna]\n",
      "   ---------------------------------------- 5/5 [requests]\n",
      "\n",
      "Successfully installed certifi-2025.7.14 charset_normalizer-3.4.2 idna-3.10 requests-2.32.4 urllib3-2.5.0\n",
      "Collecting python-dotenv\n",
      "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
      "Downloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.1.1\n",
      "Collecting flask\n",
      "  Downloading flask-3.1.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting flask-cors\n",
      "  Downloading flask_cors-6.0.1-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting blinker>=1.9.0 (from flask)\n",
      "  Downloading blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting click>=8.1.3 (from flask)\n",
      "  Downloading click-8.2.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting itsdangerous>=2.2.0 (from flask)\n",
      "  Downloading itsdangerous-2.2.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: jinja2>=3.1.2 in c:\\users\\shriom\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from flask) (3.1.6)\n",
      "Requirement already satisfied: markupsafe>=2.1.1 in c:\\users\\shriom\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from flask) (3.0.2)\n",
      "Collecting werkzeug>=3.1.0 (from flask)\n",
      "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\shriom\\appdata\\roaming\\python\\python313\\site-packages (from click>=8.1.3->flask) (0.4.6)\n",
      "Downloading flask-3.1.1-py3-none-any.whl (103 kB)\n",
      "Downloading flask_cors-6.0.1-py3-none-any.whl (13 kB)\n",
      "Downloading blinker-1.9.0-py3-none-any.whl (8.5 kB)\n",
      "Downloading click-8.2.1-py3-none-any.whl (102 kB)\n",
      "Downloading itsdangerous-2.2.0-py3-none-any.whl (16 kB)\n",
      "Downloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Installing collected packages: werkzeug, itsdangerous, click, blinker, flask, flask-cors\n",
      "\n",
      "   ---------------------------------------- 0/6 [werkzeug]\n",
      "   -------------------------- ------------- 4/6 [flask]\n",
      "   ---------------------------------------- 6/6 [flask-cors]\n",
      "\n",
      "Successfully installed blinker-1.9.0 click-8.2.1 flask-3.1.1 flask-cors-6.0.1 itsdangerous-2.2.0 werkzeug-3.1.3\n",
      "Collecting PyJWT\n",
      "  Downloading PyJWT-2.10.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Downloading PyJWT-2.10.1-py3-none-any.whl (22 kB)\n",
      "Installing collected packages: PyJWT\n",
      "Successfully installed PyJWT-2.10.1\n",
      "Requirement already satisfied: werkzeug in c:\\users\\shriom\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\shriom\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from werkzeug) (3.0.2)\n",
      "Collecting plotly\n",
      "  Downloading plotly-6.2.0-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting narwhals>=1.15.1 (from plotly)\n",
      "  Downloading narwhals-1.47.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\shriom\\appdata\\roaming\\python\\python313\\site-packages (from plotly) (25.0)\n",
      "Downloading plotly-6.2.0-py3-none-any.whl (9.6 MB)\n",
      "   ---------------------------------------- 0.0/9.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/9.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/9.6 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.5/9.6 MB 2.6 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 2.6/9.6 MB 6.4 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 3.7/9.6 MB 6.4 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 4.7/9.6 MB 6.0 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 5.2/9.6 MB 5.1 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 5.8/9.6 MB 4.5 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 8.1/9.6 MB 5.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.6/9.6 MB 5.9 MB/s eta 0:00:00\n",
      "Downloading narwhals-1.47.0-py3-none-any.whl (374 kB)\n",
      "Installing collected packages: narwhals, plotly\n",
      "\n",
      "   ---------------------------------------- 0/2 [narwhals]\n",
      "   ---------------------------------------- 0/2 [narwhals]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   -------------------- ------------------- 1/2 [plotly]\n",
      "   ---------------------------------------- 2/2 [plotly]\n",
      "\n",
      "Successfully installed narwhals-1.47.0 plotly-6.2.0\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\shriom\\appdata\\roaming\\python\\python313\\site-packages (from tqdm) (0.4.6)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: tqdm\n",
      "Successfully installed tqdm-4.67.1\n",
      "Collecting torchmetrics\n",
      "  Downloading torchmetrics-1.7.4-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: numpy>1.20.0 in c:\\users\\shriom\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torchmetrics) (2.2.6)\n",
      "Requirement already satisfied: packaging>17.1 in c:\\users\\shriom\\appdata\\roaming\\python\\python313\\site-packages (from torchmetrics) (25.0)\n",
      "Requirement already satisfied: torch>=2.0.0 in c:\\users\\shriom\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torchmetrics) (2.7.1)\n",
      "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
      "  Downloading lightning_utilities-0.14.3-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\shriom\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from lightning-utilities>=0.8.0->torchmetrics) (80.9.0)\n",
      "Requirement already satisfied: typing_extensions in c:\\users\\shriom\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.14.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\shriom\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch>=2.0.0->torchmetrics) (3.18.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\shriom\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch>=2.0.0->torchmetrics) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\shriom\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch>=2.0.0->torchmetrics) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\shriom\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch>=2.0.0->torchmetrics) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\shriom\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch>=2.0.0->torchmetrics) (2025.7.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\shriom\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sympy>=1.13.3->torch>=2.0.0->torchmetrics) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\shriom\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jinja2->torch>=2.0.0->torchmetrics) (3.0.2)\n",
      "Downloading torchmetrics-1.7.4-py3-none-any.whl (963 kB)\n",
      "   ---------------------------------------- 0.0/963.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/963.5 kB ? eta -:--:--\n",
      "   --------------------- ------------------ 524.3/963.5 kB 2.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 963.5/963.5 kB 3.1 MB/s eta 0:00:00\n",
      "Downloading lightning_utilities-0.14.3-py3-none-any.whl (28 kB)\n",
      "Installing collected packages: lightning-utilities, torchmetrics\n",
      "\n",
      "   -------------------- ------------------- 1/2 [torchmetrics]\n",
      "   -------------------- ------------------- 1/2 [torchmetrics]\n",
      "   -------------------- ------------------- 1/2 [torchmetrics]\n",
      "   -------------------- ------------------- 1/2 [torchmetrics]\n",
      "   ---------------------------------------- 2/2 [torchmetrics]\n",
      "\n",
      "Successfully installed lightning-utilities-0.14.3 torchmetrics-1.7.4\n",
      "Collecting timm\n",
      "  Downloading timm-1.0.17-py3-none-any.whl.metadata (59 kB)\n",
      "Requirement already satisfied: torch in c:\\users\\shriom\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from timm) (2.7.1)\n",
      "Collecting torchvision (from timm)\n",
      "  Downloading torchvision-0.22.1-cp313-cp313-win_amd64.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\shriom\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from timm) (6.0.2)\n",
      "Collecting huggingface_hub (from timm)\n",
      "  Downloading huggingface_hub-0.33.4-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting safetensors (from timm)\n",
      "  Downloading safetensors-0.5.3-cp38-abi3-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\shriom\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from huggingface_hub->timm) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\shriom\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from huggingface_hub->timm) (2025.7.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\shriom\\appdata\\roaming\\python\\python313\\site-packages (from huggingface_hub->timm) (25.0)\n",
      "Requirement already satisfied: requests in c:\\users\\shriom\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from huggingface_hub->timm) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\shriom\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from huggingface_hub->timm) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\shriom\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from huggingface_hub->timm) (4.14.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\shriom\\appdata\\roaming\\python\\python313\\site-packages (from tqdm>=4.42.1->huggingface_hub->timm) (0.4.6)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\shriom\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->huggingface_hub->timm) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\shriom\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->huggingface_hub->timm) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\shriom\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->huggingface_hub->timm) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\shriom\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->huggingface_hub->timm) (2025.7.14)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\shriom\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch->timm) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\shriom\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch->timm) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\shriom\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch->timm) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\shriom\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch->timm) (80.9.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\shriom\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sympy>=1.13.3->torch->timm) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\shriom\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jinja2->torch->timm) (3.0.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\shriom\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torchvision->timm) (2.2.6)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\shriom\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torchvision->timm) (11.3.0)\n",
      "Downloading timm-1.0.17-py3-none-any.whl (2.5 MB)\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.5 MB ? eta -:--:--\n",
      "   ------------------------------------- -- 2.4/2.5 MB 7.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.5/2.5 MB 7.2 MB/s eta 0:00:00\n",
      "Downloading huggingface_hub-0.33.4-py3-none-any.whl (515 kB)\n",
      "Downloading safetensors-0.5.3-cp38-abi3-win_amd64.whl (308 kB)\n",
      "Downloading torchvision-0.22.1-cp313-cp313-win_amd64.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.7/1.7 MB 15.3 MB/s eta 0:00:00\n",
      "Installing collected packages: safetensors, huggingface_hub, torchvision, timm\n",
      "\n",
      "   ---------- ----------------------------- 1/4 [huggingface_hub]\n",
      "   ---------- ----------------------------- 1/4 [huggingface_hub]\n",
      "   -------------------- ------------------- 2/4 [torchvision]\n",
      "   -------------------- ------------------- 2/4 [torchvision]\n",
      "   -------------------- ------------------- 2/4 [torchvision]\n",
      "   -------------------- ------------------- 2/4 [torchvision]\n",
      "   ------------------------------ --------- 3/4 [timm]\n",
      "   ------------------------------ --------- 3/4 [timm]\n",
      "   ------------------------------ --------- 3/4 [timm]\n",
      "   ------------------------------ --------- 3/4 [timm]\n",
      "   ------------------------------ --------- 3/4 [timm]\n",
      "   ------------------------------ --------- 3/4 [timm]\n",
      "   ---------------------------------------- 4/4 [timm]\n",
      "\n",
      "Successfully installed huggingface_hub-0.33.4 safetensors-0.5.3 timm-1.0.17 torchvision-0.22.1\n",
      "Collecting wandb\n",
      "  Downloading wandb-0.21.0-py3-none-win_amd64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in c:\\users\\shriom\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from wandb) (8.2.1)\n",
      "Collecting gitpython!=3.1.29,>=1.0.0 (from wandb)\n",
      "  Downloading GitPython-3.1.44-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\shriom\\appdata\\roaming\\python\\python313\\site-packages (from wandb) (25.0)\n",
      "Requirement already satisfied: platformdirs in c:\\users\\shriom\\appdata\\roaming\\python\\python313\\site-packages (from wandb) (4.3.8)\n",
      "Collecting protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 (from wandb)\n",
      "  Downloading protobuf-6.31.1-cp310-abi3-win_amd64.whl.metadata (593 bytes)\n",
      "Requirement already satisfied: pydantic<3 in c:\\users\\shriom\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from wandb) (2.11.7)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\shriom\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from wandb) (6.0.2)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in c:\\users\\shriom\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from wandb) (2.32.4)\n",
      "Collecting sentry-sdk>=2.0.0 (from wandb)\n",
      "  Downloading sentry_sdk-2.33.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.8 in c:\\users\\shriom\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from wandb) (4.14.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\shriom\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic<3->wandb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\shriom\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic<3->wandb) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\shriom\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic<3->wandb) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\shriom\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\shriom\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\shriom\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\shriom\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2025.7.14)\n",
      "Requirement already satisfied: colorama in c:\\users\\shriom\\appdata\\roaming\\python\\python313\\site-packages (from click!=8.0.0,>=7.1->wandb) (0.4.6)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.29,>=1.0.0->wandb)\n",
      "  Downloading gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb)\n",
      "  Downloading smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "Downloading wandb-0.21.0-py3-none-win_amd64.whl (21.5 MB)\n",
      "   ---------------------------------------- 0.0/21.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/21.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.3/21.5 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.8/21.5 MB 1.9 MB/s eta 0:00:11\n",
      "   -- ------------------------------------- 1.3/21.5 MB 2.3 MB/s eta 0:00:09\n",
      "   --- ------------------------------------ 1.8/21.5 MB 2.5 MB/s eta 0:00:08\n",
      "   ---- ----------------------------------- 2.6/21.5 MB 2.7 MB/s eta 0:00:08\n",
      "   ------ --------------------------------- 3.4/21.5 MB 2.9 MB/s eta 0:00:07\n",
      "   -------- ------------------------------- 4.5/21.5 MB 3.1 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 5.2/21.5 MB 3.2 MB/s eta 0:00:06\n",
      "   ----------- ---------------------------- 6.3/21.5 MB 3.5 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 7.6/21.5 MB 3.7 MB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 9.2/21.5 MB 4.0 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 10.7/21.5 MB 4.3 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 12.6/21.5 MB 4.6 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 14.2/21.5 MB 4.9 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 16.5/21.5 MB 5.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 18.9/21.5 MB 5.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 20.7/21.5 MB 5.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 21.5/21.5 MB 5.9 MB/s eta 0:00:00\n",
      "Downloading protobuf-6.31.1-cp310-abi3-win_amd64.whl (435 kB)\n",
      "Downloading GitPython-3.1.44-py3-none-any.whl (207 kB)\n",
      "Downloading gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
      "Downloading smmap-5.0.2-py3-none-any.whl (24 kB)\n",
      "Downloading sentry_sdk-2.33.0-py2.py3-none-any.whl (356 kB)\n",
      "Installing collected packages: smmap, sentry-sdk, protobuf, gitdb, gitpython, wandb\n",
      "\n",
      "   ------ --------------------------------- 1/6 [sentry-sdk]\n",
      "   ------ --------------------------------- 1/6 [sentry-sdk]\n",
      "   ------------- -------------------------- 2/6 [protobuf]\n",
      "   -------------------------- ------------- 4/6 [gitpython]\n",
      "   --------------------------------- ------ 5/6 [wandb]\n",
      "   --------------------------------- ------ 5/6 [wandb]\n",
      "   --------------------------------- ------ 5/6 [wandb]\n",
      "   --------------------------------- ------ 5/6 [wandb]\n",
      "   --------------------------------- ------ 5/6 [wandb]\n",
      "   --------------------------------- ------ 5/6 [wandb]\n",
      "   --------------------------------- ------ 5/6 [wandb]\n",
      "   --------------------------------- ------ 5/6 [wandb]\n",
      "   --------------------------------- ------ 5/6 [wandb]\n",
      "   --------------------------------- ------ 5/6 [wandb]\n",
      "   --------------------------------- ------ 5/6 [wandb]\n",
      "   --------------------------------- ------ 5/6 [wandb]\n",
      "   --------------------------------- ------ 5/6 [wandb]\n",
      "   --------------------------------- ------ 5/6 [wandb]\n",
      "   ---------------------------------------- 6/6 [wandb]\n",
      "\n",
      "Successfully installed gitdb-4.0.12 gitpython-3.1.44 protobuf-6.31.1 sentry-sdk-2.33.0 smmap-5.0.2 wandb-0.21.0\n",
      "✅ All packages installed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Install required packages (CPU-optimized for laptops without GPU)\n",
    "print(\"🖥️ Installing CPU-optimized packages for training without GPU...\")\n",
    "\n",
    "# Install PyTorch CPU version (smaller and faster for CPU-only training)\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\n",
    "!pip install efficientnet-pytorch\n",
    "!pip install pillow\n",
    "!pip install numpy pandas matplotlib seaborn\n",
    "!pip install scikit-learn\n",
    "!pip install opencv-python\n",
    "!pip install albumentations\n",
    "\n",
    "# Database and web dependencies\n",
    "!pip install pymongo\n",
    "!pip install requests\n",
    "!pip install python-dotenv\n",
    "!pip install flask flask-cors\n",
    "!pip install PyJWT\n",
    "!pip install werkzeug\n",
    "!pip install plotly\n",
    "!pip install tqdm\n",
    "\n",
    "# CPU-optimized ML libraries\n",
    "!pip install torchmetrics\n",
    "!pip install timm\n",
    "\n",
    "# Optional: For better CPU performance\n",
    "!pip install intel-extension-for-pytorch  # Intel optimization (if available)\n",
    "\n",
    "print(\"✅ All CPU-optimized packages installed successfully!\")\n",
    "print(\"💡 Note: Training will be slower on CPU but still effective for smaller datasets.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345473b5",
   "metadata": {},
   "source": [
    "# 2. Import Required Libraries\n",
    "\n",
    "Import all necessary libraries for training and deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0ffc609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Database libraries imported successfully\n",
      "🖥️ Running locally (not in Google Colab)\n",
      "✅ All libraries imported successfully!\n",
      "🔗 PyTorch version: 2.7.1+cpu\n",
      "🔗 CUDA available: False\n",
      "🖥️ Running on CPU - optimized for local training\n",
      "🖥️ Local environment detected\n",
      "   - Using local file system\n",
      "   - CPU-optimized settings applied\n"
     ]
    }
   ],
   "source": [
    "# Core libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "import timm\n",
    "\n",
    "# Data handling\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import os\n",
    "import json\n",
    "import base64\n",
    "import io\n",
    "from datetime import datetime\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# ML utilities\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "# Database and API (for Flask integration)\n",
    "try:\n",
    "    from pymongo import MongoClient\n",
    "    import pymongo\n",
    "    from werkzeug.security import generate_password_hash, check_password_hash\n",
    "    import jwt\n",
    "    from functools import wraps\n",
    "    print(\"✅ Database libraries imported successfully\")\n",
    "except ImportError as e:\n",
    "    print(f\"⚠️ Database libraries not available: {e}\")\n",
    "    print(\"   This is okay for training - only needed for Flask integration\")\n",
    "\n",
    "# Local file handling (instead of Google Colab)\n",
    "import zipfile\n",
    "import urllib.request\n",
    "import shutil\n",
    "\n",
    "# Check if running in Google Colab\n",
    "try:\n",
    "    from google.colab import drive, files\n",
    "    IN_COLAB = True\n",
    "    print(\"🌐 Running in Google Colab\")\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "    print(\"🖥️ Running locally (not in Google Colab)\")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed_all(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "print(\"✅ All libraries imported successfully!\")\n",
    "print(f\"🔗 PyTorch version: {torch.__version__}\")\n",
    "print(f\"🔗 CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"🎯 CUDA device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"🔧 CUDA version: {torch.version.cuda}\")\n",
    "else:\n",
    "    print(\"🖥️ Running on CPU - optimized for local training\")\n",
    "\n",
    "# Platform-specific settings\n",
    "if IN_COLAB:\n",
    "    print(\"🌐 Google Colab environment detected\")\n",
    "    print(\"   - Using Colab-specific optimizations\")\n",
    "else:\n",
    "    print(\"🖥️ Local environment detected\")\n",
    "    print(\"   - Using local file system\")\n",
    "    print(\"   - CPU-optimized settings applied\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b46bc0c",
   "metadata": {},
   "source": [
    "# 3. Configure Google Colab for GPU/TPU\n",
    "\n",
    "Set up hardware acceleration and check available resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d45b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check available hardware and optimize for CPU\n",
    "def check_hardware():\n",
    "    print(\"\udda5️ Hardware Configuration (CPU-Optimized):\")\n",
    "    print(f\"CPU cores: {os.cpu_count()}\")\n",
    "    \n",
    "    # GPU check\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"✅ GPU available: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "        print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    else:\n",
    "        print(\"🖥️ No GPU available - optimizing for CPU training\")\n",
    "        print(\"💡 This is suitable for smaller datasets and development\")\n",
    "    \n",
    "    # Check CPU optimization\n",
    "    try:\n",
    "        import intel_extension_for_pytorch as ipex\n",
    "        print(\"✅ Intel Extension for PyTorch available (CPU optimization)\")\n",
    "    except ImportError:\n",
    "        print(\"ℹ️ Intel Extension not available (normal for most systems)\")\n",
    "    \n",
    "    return None\n",
    "\n",
    "check_hardware()\n",
    "\n",
    "# Set device and CPU optimizations\n",
    "device = torch.device('cpu')\n",
    "print(f\"🎯 Training device: {device}\")\n",
    "print(\"🔧 Configuring CPU optimizations...\")\n",
    "\n",
    "# CPU-specific optimizations\n",
    "torch.set_num_threads(os.cpu_count())  # Use all CPU cores\n",
    "torch.set_num_interop_threads(1)  # Reduce overhead\n",
    "\n",
    "# Disable CUDA optimizations (not needed for CPU)\n",
    "scaler = None  # No mixed precision for CPU\n",
    "\n",
    "print(\"✅ CPU optimizations configured!\")\n",
    "print(\"💡 Training Tips for CPU:\")\n",
    "print(\"  - Use smaller batch sizes (8-16)\")\n",
    "print(\"  - Reduce model complexity if needed\")\n",
    "print(\"  - Consider using a smaller EfficientNet variant\")\n",
    "print(\"  - Training will take longer but will still work effectively\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446d511a",
   "metadata": {},
   "source": [
    "# 4. Load and Preprocess Agricultural Dataset\n",
    "\n",
    "Download and prepare the plant disease dataset for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17cb4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Setup and Preparation\n",
    "import os\n",
    "import shutil\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Define class labels matching your Flask app\n",
    "LABELS = [\n",
    "    'healthy plant',\n",
    "    'bacterial leaf blight',\n",
    "    'leaf spot',\n",
    "    'brown rust',\n",
    "    'yellow rust',\n",
    "    'powdery mildew',\n",
    "    'nitrogen deficiency',\n",
    "    'phosphorus deficiency',\n",
    "    'potassium deficiency',\n",
    "    'water stress'\n",
    "]\n",
    "\n",
    "# Create label to index mapping\n",
    "label_to_idx = {label: idx for idx, label in enumerate(LABELS)}\n",
    "idx_to_label = {idx: label for label, idx in label_to_idx.items()}\n",
    "\n",
    "print(\"📋 Class Labels:\")\n",
    "for idx, label in idx_to_label.items():\n",
    "    print(f\"  {idx}: {label}\")\n",
    "\n",
    "# Create dataset directory structure\n",
    "def create_dataset_structure():\n",
    "    \"\"\"Create the required dataset folder structure\"\"\"\n",
    "    dataset_path = 'd:/Projects/AgriGuru/AgriGuru/dataset'  # Local path for your project\n",
    "    \n",
    "    print(f\"\udcc1 Creating dataset structure at: {dataset_path}\")\n",
    "    \n",
    "    # Create main dataset directory\n",
    "    os.makedirs(dataset_path, exist_ok=True)\n",
    "    \n",
    "    # Create train/val/test subdirectories for each class\n",
    "    for split in ['train', 'val', 'test']:\n",
    "        for label in LABELS:\n",
    "            class_dir = os.path.join(dataset_path, split, label)\n",
    "            os.makedirs(class_dir, exist_ok=True)\n",
    "    \n",
    "    print(\"✅ Dataset structure created!\")\n",
    "    print(\"\\n📂 Directory structure:\")\n",
    "    print(f\"{dataset_path}/\")\n",
    "    print(\"├── train/\")\n",
    "    print(\"│   ├── healthy plant/\")\n",
    "    print(\"│   ├── bacterial leaf blight/\")\n",
    "    print(\"│   └── ... (other classes)\")\n",
    "    print(\"├── val/\")\n",
    "    print(\"│   └── ... (same classes)\")\n",
    "    print(\"└── test/\")\n",
    "    print(\"    └── ... (same classes)\")\n",
    "    \n",
    "    return dataset_path\n",
    "\n",
    "# Generate sample synthetic data for immediate training\n",
    "def generate_sample_data(dataset_path, samples_per_class=20):\n",
    "    \"\"\"Generate synthetic sample images for immediate training\"\"\"\n",
    "    print(\"🎨 Generating sample synthetic data for training...\")\n",
    "    \n",
    "    # Color schemes for different disease types\n",
    "    color_schemes = {\n",
    "        'healthy plant': [(50, 200, 50), (100, 255, 100)],\n",
    "        'bacterial leaf blight': [(200, 200, 100), (255, 255, 150)],\n",
    "        'leaf spot': [(150, 100, 50), (200, 150, 100)],\n",
    "        'brown rust': [(139, 69, 19), (160, 82, 45)],\n",
    "        'yellow rust': [(255, 255, 0), (255, 215, 0)],\n",
    "        'powdery mildew': [(220, 220, 220), (255, 255, 255)],\n",
    "        'nitrogen deficiency': [(255, 255, 150), (255, 255, 200)],\n",
    "        'phosphorus deficiency': [(128, 0, 128), (160, 32, 160)],\n",
    "        'potassium deficiency': [(255, 165, 0), (255, 140, 0)],\n",
    "        'water stress': [(139, 69, 19), (160, 82, 45)]\n",
    "    }\n",
    "    \n",
    "    for split in ['train', 'val', 'test']:\n",
    "        split_samples = samples_per_class if split == 'train' else samples_per_class // 4\n",
    "        \n",
    "        for label in LABELS:\n",
    "            class_dir = os.path.join(dataset_path, split, label)\n",
    "            colors = color_schemes[label]\n",
    "            \n",
    "            for i in range(split_samples):\n",
    "                # Create synthetic image\n",
    "                img = Image.new('RGB', (224, 224), color=colors[0])\n",
    "                draw = ImageDraw.Draw(img)\n",
    "                \n",
    "                # Add some random patterns to simulate disease symptoms\n",
    "                for _ in range(random.randint(5, 15)):\n",
    "                    x = random.randint(0, 200)\n",
    "                    y = random.randint(0, 200)\n",
    "                    size = random.randint(10, 40)\n",
    "                    color = random.choice(colors)\n",
    "                    draw.ellipse([x, y, x + size, y + size], fill=color)\n",
    "                \n",
    "                # Add some noise\n",
    "                pixels = np.array(img)\n",
    "                noise = np.random.normal(0, 10, pixels.shape)\n",
    "                pixels = np.clip(pixels + noise, 0, 255).astype(np.uint8)\n",
    "                img = Image.fromarray(pixels)\n",
    "                \n",
    "                # Save image\n",
    "                img_path = os.path.join(class_dir, f'{label}_{split}_{i:03d}.jpg')\n",
    "                img.save(img_path)\n",
    "            \n",
    "            print(f\"  Generated {split_samples} samples for {label} ({split})\")\n",
    "    \n",
    "    print(\"✅ Sample data generated successfully!\")\n",
    "    print(\"💡 Replace these synthetic images with real plant disease images for better results\")\n",
    "\n",
    "# Setup dataset\n",
    "dataset_path = create_dataset_structure()\n",
    "\n",
    "# Generate sample data for immediate training\n",
    "generate_sample_data(dataset_path)\n",
    "\n",
    "# Custom dataset class\n",
    "class PlantDiseaseDataset(Dataset):\n",
    "    def __init__(self, data_dir, transform=None, split='train'):\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "        self.split = split\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        \n",
    "        # Load image paths and labels\n",
    "        split_dir = os.path.join(data_dir, split)\n",
    "        if os.path.exists(split_dir):\n",
    "            for label in LABELS:\n",
    "                label_dir = os.path.join(split_dir, label)\n",
    "                if os.path.exists(label_dir):\n",
    "                    for img_file in os.listdir(label_dir):\n",
    "                        if img_file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                            self.image_paths.append(os.path.join(label_dir, img_file))\n",
    "                            self.labels.append(label_to_idx[label])\n",
    "        \n",
    "        print(f\"📊 {split} dataset: {len(self.image_paths)} images\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # Load image\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        # Apply transforms\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "# Basic transforms for initial setup\n",
    "basic_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                        std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Create dataset instances\n",
    "train_dataset = PlantDiseaseDataset(dataset_path, transform=basic_transform, split='train')\n",
    "val_dataset = PlantDiseaseDataset(dataset_path, transform=basic_transform, split='val')\n",
    "test_dataset = PlantDiseaseDataset(dataset_path, transform=basic_transform, split='test')\n",
    "\n",
    "print(f\"\\n✅ Dataset loaded successfully!\")\n",
    "print(f\"📊 Training samples: {len(train_dataset)}\")\n",
    "print(f\"📊 Validation samples: {len(val_dataset)}\")\n",
    "print(f\"📊 Test samples: {len(test_dataset)}\")\n",
    "\n",
    "print(\"\\n🎯 Next Steps:\")\n",
    "print(\"1. Replace synthetic images with real plant disease images\")\n",
    "print(\"2. Add more images for better training (100-500 per class recommended)\")\n",
    "print(\"3. Continue with the training process\")\n",
    "print(\"4. The notebook is ready to train with the current synthetic data!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f791ec",
   "metadata": {},
   "source": [
    "# 5. Implement Data Augmentation\n",
    "\n",
    "Create comprehensive augmentation strategies for agricultural images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81eff7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced augmentation for agricultural images\n",
    "def get_train_transforms():\n",
    "    \"\"\"Comprehensive augmentation pipeline for training\"\"\"\n",
    "    return A.Compose([\n",
    "        # Geometric transformations\n",
    "        A.RandomRotate90(p=0.5),\n",
    "        A.Flip(p=0.5),\n",
    "        A.Transpose(p=0.5),\n",
    "        A.ShiftScaleRotate(\n",
    "            shift_limit=0.0625,\n",
    "            scale_limit=0.2,\n",
    "            rotate_limit=45,\n",
    "            p=0.5\n",
    "        ),\n",
    "        \n",
    "        # Color and lighting augmentations\n",
    "        A.OneOf([\n",
    "            A.HueSaturationValue(\n",
    "                hue_shift_limit=20,\n",
    "                sat_shift_limit=30,\n",
    "                val_shift_limit=20,\n",
    "                p=0.5\n",
    "            ),\n",
    "            A.ColorJitter(\n",
    "                brightness=0.2,\n",
    "                contrast=0.2,\n",
    "                saturation=0.2,\n",
    "                hue=0.1,\n",
    "                p=0.5\n",
    "            ),\n",
    "        ], p=0.8),\n",
    "        \n",
    "        # Blur and noise\n",
    "        A.OneOf([\n",
    "            A.MotionBlur(p=0.3),\n",
    "            A.MedianBlur(blur_limit=3, p=0.3),\n",
    "            A.Blur(blur_limit=3, p=0.3),\n",
    "        ], p=0.4),\n",
    "        \n",
    "        # Weather and environmental effects\n",
    "        A.OneOf([\n",
    "            A.RandomBrightnessContrast(\n",
    "                brightness_limit=0.2,\n",
    "                contrast_limit=0.2,\n",
    "                p=0.5\n",
    "            ),\n",
    "            A.RandomGamma(gamma_limit=(80, 120), p=0.5),\n",
    "            A.RandomFog(fog_coef_lower=0.1, fog_coef_upper=0.3, p=0.3),\n",
    "        ], p=0.5),\n",
    "        \n",
    "        # Resize and normalize\n",
    "        A.Resize(224, 224),\n",
    "        A.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225]\n",
    "        ),\n",
    "        ToTensorV2()\n",
    "    ])\n",
    "\n",
    "def get_val_transforms():\n",
    "    \"\"\"Validation transforms without augmentation\"\"\"\n",
    "    return A.Compose([\n",
    "        A.Resize(224, 224),\n",
    "        A.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225]\n",
    "        ),\n",
    "        ToTensorV2()\n",
    "    ])\n",
    "\n",
    "# Custom dataset class with albumentations\n",
    "class AugmentedPlantDataset(Dataset):\n",
    "    def __init__(self, data_dir, transform=None, split='train'):\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "        self.split = split\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        \n",
    "        # Load image paths and labels\n",
    "        split_dir = os.path.join(data_dir, split)\n",
    "        if os.path.exists(split_dir):\n",
    "            for label in LABELS:\n",
    "                label_dir = os.path.join(split_dir, label)\n",
    "                if os.path.exists(label_dir):\n",
    "                    for img_file in os.listdir(label_dir):\n",
    "                        if img_file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                            self.image_paths.append(os.path.join(label_dir, img_file))\n",
    "                            self.labels.append(label_to_idx[label])\n",
    "        \n",
    "        print(f\"📊 {split} dataset: {len(self.image_paths)} images\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # Load image as numpy array for albumentations\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Apply transforms\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image)\n",
    "            image = augmented['image']\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "# Create augmented datasets\n",
    "train_transform = get_train_transforms()\n",
    "val_transform = get_val_transforms()\n",
    "\n",
    "# Recreate datasets with augmentation\n",
    "train_dataset = AugmentedPlantDataset(dataset_path, transform=train_transform, split='train')\n",
    "val_dataset = AugmentedPlantDataset(dataset_path, transform=val_transform, split='val')\n",
    "test_dataset = AugmentedPlantDataset(dataset_path, transform=val_transform, split='test')\n",
    "\n",
    "# Visualize augmented samples\n",
    "def visualize_augmentations(dataset, num_samples=4):\n",
    "    \"\"\"Visualize original and augmented images\"\"\"\n",
    "    fig, axes = plt.subplots(2, num_samples, figsize=(15, 8))\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        # Get a sample\n",
    "        if len(dataset) > 0:\n",
    "            image, label = dataset[i]\n",
    "            \n",
    "            # Convert tensor to numpy for visualization\n",
    "            if isinstance(image, torch.Tensor):\n",
    "                # Denormalize\n",
    "                mean = np.array([0.485, 0.456, 0.406])\n",
    "                std = np.array([0.229, 0.224, 0.225])\n",
    "                image_np = image.permute(1, 2, 0).numpy()\n",
    "                image_np = std * image_np + mean\n",
    "                image_np = np.clip(image_np, 0, 1)\n",
    "            else:\n",
    "                image_np = image\n",
    "            \n",
    "            axes[0, i].imshow(image_np)\n",
    "            axes[0, i].set_title(f\"Sample {i+1}\")\n",
    "            axes[0, i].axis('off')\n",
    "            \n",
    "            axes[1, i].text(0.5, 0.5, f\"Label: {LABELS[label]}\", \n",
    "                          ha='center', va='center', fontsize=12)\n",
    "            axes[1, i].axis('off')\n",
    "    \n",
    "    plt.suptitle(\"Augmented Training Samples\", fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize samples if dataset is not empty\n",
    "if len(train_dataset) > 0:\n",
    "    visualize_augmentations(train_dataset)\n",
    "else:\n",
    "    print(\"⚠️ No training samples found. Please add images to the dataset folders.\")\n",
    "\n",
    "print(\"✅ Data augmentation pipeline configured!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974affc2",
   "metadata": {},
   "source": [
    "# 6. Define EfficientNet Model Architecture\n",
    "\n",
    "Set up the EfficientNet model for agricultural classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6450c9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CPU-Optimized EfficientNet for Agricultural Classification\n",
    "class AgriEfficientNet(nn.Module):\n",
    "    def __init__(self, num_classes=len(LABELS), model_name='efficientnet-b0', pretrained=True):\n",
    "        super(AgriEfficientNet, self).__init__()\n",
    "        \n",
    "        # Load pretrained EfficientNet (smaller for CPU)\n",
    "        if pretrained:\n",
    "            self.backbone = EfficientNet.from_pretrained(model_name)\n",
    "        else:\n",
    "            self.backbone = EfficientNet.from_name(model_name)\n",
    "        \n",
    "        # Get the number of features from the backbone\n",
    "        num_features = self.backbone._fc.in_features\n",
    "        \n",
    "        # Simplified classifier (less complex for CPU training)\n",
    "        self.backbone._fc = nn.Sequential(\n",
    "            nn.Dropout(0.3),  # Reduced dropout\n",
    "            nn.Linear(num_features, 256),  # Smaller hidden layer\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "        \n",
    "        # Simplified attention mechanism (optional, can be disabled for faster training)\n",
    "        self.use_attention = True  # Set to False for faster CPU training\n",
    "        if self.use_attention:\n",
    "            self.attention = nn.Sequential(\n",
    "                nn.AdaptiveAvgPool2d(1),\n",
    "                nn.Flatten(),\n",
    "                nn.Linear(num_features, num_features // 32),  # Reduced complexity\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(num_features // 32, num_features),\n",
    "                nn.Sigmoid()\n",
    "            )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Extract features\n",
    "        features = self.backbone.extract_features(x)\n",
    "        \n",
    "        # Apply attention (if enabled)\n",
    "        if self.use_attention:\n",
    "            attention_weights = self.attention(features)\n",
    "            attended_features = features * attention_weights.unsqueeze(-1).unsqueeze(-1)\n",
    "        else:\n",
    "            attended_features = features\n",
    "        \n",
    "        # Global average pooling\n",
    "        pooled = nn.AdaptiveAvgPool2d(1)(attended_features)\n",
    "        pooled = pooled.view(pooled.size(0), -1)\n",
    "        \n",
    "        # Classification\n",
    "        output = self.backbone._fc(pooled)\n",
    "        return output\n",
    "\n",
    "# CPU-optimized model configuration\n",
    "MODEL_CONFIG = {\n",
    "    'model_name': 'efficientnet-b0',  # Smallest EfficientNet variant\n",
    "    'num_classes': len(LABELS),\n",
    "    'pretrained': True\n",
    "}\n",
    "\n",
    "print(\"🖥️ Creating CPU-optimized model...\")\n",
    "\n",
    "# Create model\n",
    "model = AgriEfficientNet(\n",
    "    num_classes=MODEL_CONFIG['num_classes'],\n",
    "    model_name=MODEL_CONFIG['model_name'],\n",
    "    pretrained=MODEL_CONFIG['pretrained']\n",
    ")\n",
    "\n",
    "# Move model to CPU\n",
    "model = model.to(device)\n",
    "\n",
    "# Model summary\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "total_params = count_parameters(model)\n",
    "print(f\"🎯 Model: {MODEL_CONFIG['model_name']} (CPU-optimized)\")\n",
    "print(f\"📊 Total parameters: {total_params:,}\")\n",
    "print(f\"💾 Model size: {total_params * 4 / 1024**2:.2f} MB\")\n",
    "print(f\"🏷️ Number of classes: {MODEL_CONFIG['num_classes']}\")\n",
    "print(f\"🔧 Device: {device}\")\n",
    "\n",
    "# Test model with dummy input\n",
    "dummy_input = torch.randn(1, 3, 224, 224).to(device)\n",
    "with torch.no_grad():\n",
    "    output = model(dummy_input)\n",
    "    print(f\"✅ Model output shape: {output.shape}\")\n",
    "\n",
    "print(\"💡 CPU Training Tips:\")\n",
    "print(\"  - Model complexity reduced for faster CPU training\")\n",
    "print(\"  - Attention mechanism can be disabled by setting use_attention=False\")\n",
    "print(\"  - Consider using smaller input images (e.g., 128x128) for faster training\")\n",
    "\n",
    "# Optional: Set model to use optimized inference mode\n",
    "model.eval()\n",
    "model.train()  # Back to training mode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d6d78f",
   "metadata": {},
   "source": [
    "# 7. Create Custom Loss Functions\n",
    "\n",
    "Implement specialized loss functions for agricultural classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57112dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom loss functions for agricultural classification\n",
    "class FocalLoss(nn.Module):\n",
    "    \"\"\"Focal Loss for addressing class imbalance\"\"\"\n",
    "    def __init__(self, alpha=1, gamma=2, reduction='mean'):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "    \n",
    "    def forward(self, inputs, targets):\n",
    "        ce_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        focal_loss = self.alpha * (1 - pt) ** self.gamma * ce_loss\n",
    "        \n",
    "        if self.reduction == 'mean':\n",
    "            return focal_loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return focal_loss.sum()\n",
    "        else:\n",
    "            return focal_loss\n",
    "\n",
    "class WeightedCrossEntropyLoss(nn.Module):\n",
    "    \"\"\"Weighted Cross Entropy for class imbalance\"\"\"\n",
    "    def __init__(self, weights=None):\n",
    "        super(WeightedCrossEntropyLoss, self).__init__()\n",
    "        self.weights = weights\n",
    "    \n",
    "    def forward(self, inputs, targets):\n",
    "        if self.weights is not None:\n",
    "            return F.cross_entropy(inputs, targets, weight=self.weights)\n",
    "        else:\n",
    "            return F.cross_entropy(inputs, targets)\n",
    "\n",
    "class LabelSmoothingLoss(nn.Module):\n",
    "    \"\"\"Label Smoothing for better generalization\"\"\"\n",
    "    def __init__(self, num_classes, smoothing=0.1):\n",
    "        super(LabelSmoothingLoss, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.smoothing = smoothing\n",
    "    \n",
    "    def forward(self, inputs, targets):\n",
    "        log_probs = F.log_softmax(inputs, dim=-1)\n",
    "        targets_one_hot = torch.zeros_like(log_probs).scatter_(1, targets.unsqueeze(1), 1)\n",
    "        targets_smooth = targets_one_hot * (1 - self.smoothing) + self.smoothing / self.num_classes\n",
    "        loss = -(targets_smooth * log_probs).sum(dim=-1).mean()\n",
    "        return loss\n",
    "\n",
    "# Calculate class weights for imbalanced dataset\n",
    "def calculate_class_weights(dataset):\n",
    "    \"\"\"Calculate class weights based on dataset distribution\"\"\"\n",
    "    class_counts = {}\n",
    "    for _, label in dataset:\n",
    "        label = label.item() if isinstance(label, torch.Tensor) else label\n",
    "        class_counts[label] = class_counts.get(label, 0) + 1\n",
    "    \n",
    "    # Calculate weights (inverse frequency)\n",
    "    total_samples = len(dataset)\n",
    "    weights = []\n",
    "    for i in range(len(LABELS)):\n",
    "        count = class_counts.get(i, 1)  # Default to 1 to avoid division by zero\n",
    "        weight = total_samples / (len(LABELS) * count)\n",
    "        weights.append(weight)\n",
    "    \n",
    "    return torch.FloatTensor(weights)\n",
    "\n",
    "# Calculate class weights if we have training data\n",
    "if len(train_dataset) > 0:\n",
    "    class_weights = calculate_class_weights(train_dataset)\n",
    "    print(\"📊 Class Distribution:\")\n",
    "    for i, (label, weight) in enumerate(zip(LABELS, class_weights)):\n",
    "        print(f\"  {label}: weight = {weight:.3f}\")\n",
    "else:\n",
    "    # Default equal weights\n",
    "    class_weights = torch.ones(len(LABELS))\n",
    "    print(\"⚠️ Using equal class weights (no training data)\")\n",
    "\n",
    "class_weights = class_weights.to(device)\n",
    "\n",
    "# Initialize loss functions\n",
    "focal_loss = FocalLoss(alpha=1, gamma=2)\n",
    "weighted_ce_loss = WeightedCrossEntropyLoss(weights=class_weights)\n",
    "label_smoothing_loss = LabelSmoothingLoss(num_classes=len(LABELS), smoothing=0.1)\n",
    "\n",
    "# Loss function configuration\n",
    "LOSS_CONFIG = {\n",
    "    'focal': focal_loss,\n",
    "    'weighted_ce': weighted_ce_loss,\n",
    "    'label_smoothing': label_smoothing_loss,\n",
    "    'cross_entropy': nn.CrossEntropyLoss()\n",
    "}\n",
    "\n",
    "# Select loss function\n",
    "selected_loss = 'weighted_ce'  # Change this to experiment with different losses\n",
    "criterion = LOSS_CONFIG[selected_loss]\n",
    "\n",
    "print(f\"🎯 Selected loss function: {selected_loss}\")\n",
    "print(f\"✅ Loss functions configured!\")\n",
    "\n",
    "# Custom metrics for agricultural classification\n",
    "class AgriculturalMetrics:\n",
    "    def __init__(self, num_classes):\n",
    "        self.num_classes = num_classes\n",
    "        self.reset()\n",
    "    \n",
    "    def reset(self):\n",
    "        self.correct = 0\n",
    "        self.total = 0\n",
    "        self.per_class_correct = [0] * self.num_classes\n",
    "        self.per_class_total = [0] * self.num_classes\n",
    "    \n",
    "    def update(self, predictions, targets):\n",
    "        _, predicted = torch.max(predictions, 1)\n",
    "        self.total += targets.size(0)\n",
    "        self.correct += (predicted == targets).sum().item()\n",
    "        \n",
    "        # Per-class accuracy\n",
    "        for i in range(self.num_classes):\n",
    "            mask = targets == i\n",
    "            if mask.sum() > 0:\n",
    "                self.per_class_total[i] += mask.sum().item()\n",
    "                self.per_class_correct[i] += (predicted[mask] == targets[mask]).sum().item()\n",
    "    \n",
    "    def get_accuracy(self):\n",
    "        return self.correct / self.total if self.total > 0 else 0\n",
    "    \n",
    "    def get_per_class_accuracy(self):\n",
    "        per_class_acc = []\n",
    "        for i in range(self.num_classes):\n",
    "            if self.per_class_total[i] > 0:\n",
    "                acc = self.per_class_correct[i] / self.per_class_total[i]\n",
    "            else:\n",
    "                acc = 0\n",
    "            per_class_acc.append(acc)\n",
    "        return per_class_acc\n",
    "\n",
    "# Initialize metrics\n",
    "metrics = AgriculturalMetrics(len(LABELS))\n",
    "\n",
    "print(\"📈 Metrics initialized!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d467b673",
   "metadata": {},
   "source": [
    "# 8. Train the Plant Disease Classification Model\n",
    "\n",
    "Implement the complete training loop with monitoring and checkpointing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683b82d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CPU-Optimized Training Configuration\n",
    "TRAINING_CONFIG = {\n",
    "    'batch_size': 8,  # Smaller batch size for CPU training\n",
    "    'num_epochs': 25,  # Reduced epochs for faster training\n",
    "    'learning_rate': 0.001,\n",
    "    'weight_decay': 1e-4,\n",
    "    'patience': 7,  # Reduced patience for faster convergence\n",
    "    'min_delta': 0.001,\n",
    "    'save_dir': '/content/drive/MyDrive/AgriGuru_Models',\n",
    "    'checkpoint_interval': 5,\n",
    "    'num_workers': 2  # Reduced for CPU training\n",
    "}\n",
    "\n",
    "print(\"🖥️ CPU-Optimized Training Configuration:\")\n",
    "print(f\"  Batch size: {TRAINING_CONFIG['batch_size']} (optimized for CPU)\")\n",
    "print(f\"  Epochs: {TRAINING_CONFIG['num_epochs']} (reduced for faster training)\")\n",
    "print(f\"  Learning rate: {TRAINING_CONFIG['learning_rate']}\")\n",
    "print(f\"  Early stopping patience: {TRAINING_CONFIG['patience']}\")\n",
    "\n",
    "# Create model save directory\n",
    "os.makedirs(TRAINING_CONFIG['save_dir'], exist_ok=True)\n",
    "\n",
    "# CPU-optimized data loaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=TRAINING_CONFIG['batch_size'],\n",
    "    shuffle=True,\n",
    "    num_workers=TRAINING_CONFIG['num_workers'],\n",
    "    pin_memory=False  # Disabled for CPU\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=TRAINING_CONFIG['batch_size'],\n",
    "    shuffle=False,\n",
    "    num_workers=TRAINING_CONFIG['num_workers'],\n",
    "    pin_memory=False  # Disabled for CPU\n",
    ")\n",
    "\n",
    "# Optimizer and scheduler (CPU-optimized)\n",
    "optimizer = optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=TRAINING_CONFIG['learning_rate'],\n",
    "    weight_decay=TRAINING_CONFIG['weight_decay']\n",
    ")\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode='min',\n",
    "    factor=0.5,\n",
    "    patience=3,  # Reduced for CPU training\n",
    "    min_lr=1e-6,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Training history\n",
    "training_history = {\n",
    "    'train_loss': [],\n",
    "    'val_loss': [],\n",
    "    'train_acc': [],\n",
    "    'val_acc': [],\n",
    "    'learning_rates': []\n",
    "}\n",
    "\n",
    "# Early stopping class\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=7, min_delta=0.001):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_loss = float('inf')\n",
    "        self.early_stop = False\n",
    "    \n",
    "    def __call__(self, val_loss):\n",
    "        if val_loss < self.best_loss - self.min_delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    patience=TRAINING_CONFIG['patience'],\n",
    "    min_delta=TRAINING_CONFIG['min_delta']\n",
    ")\n",
    "\n",
    "# CPU-optimized training function\n",
    "def train_epoch(model, train_loader, criterion, optimizer, device, scaler=None):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    metrics.reset()\n",
    "    \n",
    "    progress_bar = tqdm(train_loader, desc='Training (CPU)', leave=False)\n",
    "    \n",
    "    for batch_idx, (data, targets) in enumerate(progress_bar):\n",
    "        data, targets = data.to(device), targets.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # No mixed precision for CPU training\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient clipping for stability\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        metrics.update(outputs, targets)\n",
    "        \n",
    "        # Update progress bar\n",
    "        progress_bar.set_postfix({\n",
    "            'Loss': f'{loss.item():.4f}',\n",
    "            'Acc': f'{metrics.get_accuracy():.4f}'\n",
    "        })\n",
    "    \n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_acc = metrics.get_accuracy()\n",
    "    \n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "# CPU-optimized validation function\n",
    "def validate_epoch(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    metrics.reset()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        progress_bar = tqdm(val_loader, desc='Validation (CPU)', leave=False)\n",
    "        \n",
    "        for data, targets in progress_bar:\n",
    "            data, targets = data.to(device), targets.to(device)\n",
    "            \n",
    "            outputs = model(data)\n",
    "            loss = criterion(outputs, targets)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            metrics.update(outputs, targets)\n",
    "            \n",
    "            progress_bar.set_postfix({\n",
    "                'Loss': f'{loss.item():.4f}',\n",
    "                'Acc': f'{metrics.get_accuracy():.4f}'\n",
    "            })\n",
    "    \n",
    "    epoch_loss = running_loss / len(val_loader)\n",
    "    epoch_acc = metrics.get_accuracy()\n",
    "    \n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "# Save model function\n",
    "def save_model(model, optimizer, epoch, loss, path):\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': loss,\n",
    "        'model_config': MODEL_CONFIG,\n",
    "        'labels': LABELS\n",
    "    }, path)\n",
    "\n",
    "# CPU-optimized training loop\n",
    "def train_model():\n",
    "    print(\"🚀 Starting CPU training...\")\n",
    "    print(\"💡 CPU training will be slower but still effective!\")\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    \n",
    "    for epoch in range(TRAINING_CONFIG['num_epochs']):\n",
    "        print(f\"\\n📍 Epoch {epoch+1}/{TRAINING_CONFIG['num_epochs']}\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        # Train\n",
    "        train_loss, train_acc = train_epoch(\n",
    "            model, train_loader, criterion, optimizer, device, None\n",
    "        )\n",
    "        \n",
    "        # Validate\n",
    "        val_loss, val_acc = validate_epoch(model, val_loader, criterion, device)\n",
    "        \n",
    "        # Update learning rate\n",
    "        scheduler.step(val_loss)\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        \n",
    "        # Store history\n",
    "        training_history['train_loss'].append(train_loss)\n",
    "        training_history['val_loss'].append(val_loss)\n",
    "        training_history['train_acc'].append(train_acc)\n",
    "        training_history['val_acc'].append(val_acc)\n",
    "        training_history['learning_rates'].append(current_lr)\n",
    "        \n",
    "        # Print epoch results\n",
    "        print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}\")\n",
    "        print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "        print(f\"Learning Rate: {current_lr:.6f}\")\n",
    "        \n",
    "        # Save best model\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model_path = os.path.join(TRAINING_CONFIG['save_dir'], 'best_model.pth')\n",
    "            save_model(model, optimizer, epoch, val_loss, best_model_path)\n",
    "            print(f\"💾 Best model saved! Val Loss: {val_loss:.4f}\")\n",
    "        \n",
    "        # Save checkpoint\n",
    "        if (epoch + 1) % TRAINING_CONFIG['checkpoint_interval'] == 0:\n",
    "            checkpoint_path = os.path.join(\n",
    "                TRAINING_CONFIG['save_dir'], \n",
    "                f'checkpoint_epoch_{epoch+1}.pth'\n",
    "            )\n",
    "            save_model(model, optimizer, epoch, val_loss, checkpoint_path)\n",
    "            print(f\"✅ Checkpoint saved at epoch {epoch+1}\")\n",
    "        \n",
    "        # Early stopping\n",
    "        early_stopping(val_loss)\n",
    "        if early_stopping.early_stop:\n",
    "            print(f\"⏹️ Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "    \n",
    "    print(\"✅ CPU training completed!\")\n",
    "    return training_history\n",
    "\n",
    "# Start training (only if we have data)\n",
    "if len(train_dataset) > 0 and len(val_dataset) > 0:\n",
    "    print(\"🖥️ Starting CPU-optimized training...\")\n",
    "    print(\"⏱️ Expected training time: Longer than GPU, but still manageable\")\n",
    "    print(\"💡 You can reduce batch_size further if you encounter memory issues\")\n",
    "    \n",
    "    history = train_model()\n",
    "    \n",
    "    # Plot training history\n",
    "    def plot_training_history(history):\n",
    "        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n",
    "        \n",
    "        # Loss plot\n",
    "        ax1.plot(history['train_loss'], label='Train Loss', color='blue')\n",
    "        ax1.plot(history['val_loss'], label='Val Loss', color='red')\n",
    "        ax1.set_title('Model Loss (CPU Training)')\n",
    "        ax1.set_xlabel('Epoch')\n",
    "        ax1.set_ylabel('Loss')\n",
    "        ax1.legend()\n",
    "        ax1.grid(True)\n",
    "        \n",
    "        # Accuracy plot\n",
    "        ax2.plot(history['train_acc'], label='Train Acc', color='blue')\n",
    "        ax2.plot(history['val_acc'], label='Val Acc', color='red')\n",
    "        ax2.set_title('Model Accuracy (CPU Training)')\n",
    "        ax2.set_xlabel('Epoch')\n",
    "        ax2.set_ylabel('Accuracy')\n",
    "        ax2.legend()\n",
    "        ax2.grid(True)\n",
    "        \n",
    "        # Learning rate plot\n",
    "        ax3.plot(history['learning_rates'], color='green')\n",
    "        ax3.set_title('Learning Rate')\n",
    "        ax3.set_xlabel('Epoch')\n",
    "        ax3.set_ylabel('LR')\n",
    "        ax3.grid(True)\n",
    "        \n",
    "        # Combined plot\n",
    "        ax4.plot(history['train_loss'], label='Train Loss', alpha=0.7)\n",
    "        ax4.plot(history['val_loss'], label='Val Loss', alpha=0.7)\n",
    "        ax4_twin = ax4.twinx()\n",
    "        ax4_twin.plot(history['train_acc'], label='Train Acc', color='green', alpha=0.7)\n",
    "        ax4_twin.plot(history['val_acc'], label='Val Acc', color='orange', alpha=0.7)\n",
    "        ax4.set_title('Loss & Accuracy Combined')\n",
    "        ax4.set_xlabel('Epoch')\n",
    "        ax4.set_ylabel('Loss')\n",
    "        ax4_twin.set_ylabel('Accuracy')\n",
    "        ax4.legend(loc='upper left')\n",
    "        ax4_twin.legend(loc='upper right')\n",
    "        ax4.grid(True)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    plot_training_history(history)\n",
    "    \n",
    "else:\n",
    "    print(\"⚠️ No training data available. Please add images to the dataset folders.\")\n",
    "    history = None\n",
    "\n",
    "print(\"🎯 CPU training section completed!\")\n",
    "print(\"💡 CPU Training Tips:\")\n",
    "print(\"  - Training completed successfully on CPU\")\n",
    "print(\"  - Model will work equally well for inference\")\n",
    "print(\"  - Consider using the trained model on a GPU server for faster inference if needed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead6ceae",
   "metadata": {},
   "source": [
    "# 🖥️ CPU Training Optimization & Performance Tips\n",
    "\n",
    "Since you're training on CPU, here are specific optimizations and considerations for your setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52470210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CPU Training Optimization Settings\n",
    "print(\"🖥️ CPU Training Optimization Guide\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Check your system capabilities\n",
    "import psutil\n",
    "import multiprocessing\n",
    "\n",
    "print(f\"💻 System Information:\")\n",
    "print(f\"  CPU cores: {multiprocessing.cpu_count()}\")\n",
    "print(f\"  Available RAM: {psutil.virtual_memory().available / (1024**3):.1f} GB\")\n",
    "print(f\"  Total RAM: {psutil.virtual_memory().total / (1024**3):.1f} GB\")\n",
    "\n",
    "# CPU-specific optimizations\n",
    "def optimize_for_cpu():\n",
    "    \"\"\"Apply CPU-specific optimizations\"\"\"\n",
    "    \n",
    "    # Set optimal number of threads\n",
    "    num_threads = min(multiprocessing.cpu_count(), 8)  # Don't exceed 8 threads\n",
    "    torch.set_num_threads(num_threads)\n",
    "    torch.set_num_interop_threads(1)\n",
    "    \n",
    "    print(f\"🔧 CPU Optimizations Applied:\")\n",
    "    print(f\"  PyTorch threads: {num_threads}\")\n",
    "    print(f\"  Interop threads: 1\")\n",
    "    \n",
    "    # Memory optimization\n",
    "    import gc\n",
    "    gc.collect()\n",
    "    \n",
    "    return num_threads\n",
    "\n",
    "# Apply optimizations\n",
    "num_threads = optimize_for_cpu()\n",
    "\n",
    "# Memory-efficient training tips\n",
    "def get_memory_usage():\n",
    "    \"\"\"Monitor memory usage\"\"\"\n",
    "    import psutil\n",
    "    process = psutil.Process()\n",
    "    memory_info = process.memory_info()\n",
    "    return memory_info.rss / (1024**2)  # MB\n",
    "\n",
    "print(f\"📊 Current memory usage: {get_memory_usage():.1f} MB\")\n",
    "\n",
    "# CPU Training Performance Tips\n",
    "print(\"\\n🚀 CPU Training Performance Tips:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "performance_tips = [\n",
    "    \"1. 📉 Use smaller batch sizes (4-8) to fit in memory\",\n",
    "    \"2. ⚡ Reduce image resolution (128x128 instead of 224x224) for faster training\",\n",
    "    \"3. 🔄 Use fewer data augmentations to speed up preprocessing\",\n",
    "    \"4. 📊 Monitor memory usage and adjust batch size accordingly\",\n",
    "    \"5. 🎯 Use early stopping to avoid overtraining\",\n",
    "    \"6. 💾 Save checkpoints frequently in case of interruptions\",\n",
    "    \"7. 🔧 Close other applications to free up CPU and memory\",\n",
    "    \"8. ⏱️ Be patient - CPU training takes longer but works well\"\n",
    "]\n",
    "\n",
    "for tip in performance_tips:\n",
    "    print(f\"  {tip}\")\n",
    "\n",
    "print(\"\\n🎯 Alternative Smaller Model Option:\")\n",
    "print(\"=\" * 50)\n",
    "print(\"If training is too slow, consider using a smaller model:\")\n",
    "\n",
    "# Option to use a smaller, faster model\n",
    "USE_SMALLER_MODEL = False  # Set to True for faster training\n",
    "\n",
    "if USE_SMALLER_MODEL:\n",
    "    print(\"🚀 Using smaller model for faster CPU training...\")\n",
    "    \n",
    "    # Create a simpler model\n",
    "    class SimpleCNN(nn.Module):\n",
    "        def __init__(self, num_classes=len(LABELS)):\n",
    "            super(SimpleCNN, self).__init__()\n",
    "            self.features = nn.Sequential(\n",
    "                # First conv block\n",
    "                nn.Conv2d(3, 32, 3, padding=1),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.MaxPool2d(2, 2),\n",
    "                \n",
    "                # Second conv block\n",
    "                nn.Conv2d(32, 64, 3, padding=1),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.MaxPool2d(2, 2),\n",
    "                \n",
    "                # Third conv block\n",
    "                nn.Conv2d(64, 128, 3, padding=1),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.MaxPool2d(2, 2),\n",
    "                \n",
    "                # Global average pooling\n",
    "                nn.AdaptiveAvgPool2d(1)\n",
    "            )\n",
    "            \n",
    "            self.classifier = nn.Sequential(\n",
    "                nn.Dropout(0.5),\n",
    "                nn.Linear(128, 64),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Dropout(0.3),\n",
    "                nn.Linear(64, num_classes)\n",
    "            )\n",
    "        \n",
    "        def forward(self, x):\n",
    "            x = self.features(x)\n",
    "            x = x.view(x.size(0), -1)\n",
    "            x = self.classifier(x)\n",
    "            return x\n",
    "    \n",
    "    # Replace the model with simpler version\n",
    "    simple_model = SimpleCNN(num_classes=len(LABELS)).to(device)\n",
    "    simple_params = sum(p.numel() for p in simple_model.parameters() if p.requires_grad)\n",
    "    \n",
    "    print(f\"📊 Simple CNN parameters: {simple_params:,}\")\n",
    "    print(f\"💾 Simple CNN size: {simple_params * 4 / 1024**2:.2f} MB\")\n",
    "    print(\"✅ Simple model created - much faster for CPU training!\")\n",
    "    \n",
    "    # Uncomment the line below to use the simple model\n",
    "    # model = simple_model\n",
    "else:\n",
    "    print(\"Using EfficientNet-B0 (recommended for better accuracy)\")\n",
    "    print(\"Set USE_SMALLER_MODEL = True above for faster training\")\n",
    "\n",
    "print(\"\\n💡 Final CPU Training Recommendations:\")\n",
    "print(\"=\" * 50)\n",
    "print(\"• Start with a small dataset (100-500 images per class)\")\n",
    "print(\"• Use batch_size=4 if you have limited RAM\")\n",
    "print(\"• Monitor system performance during training\")\n",
    "print(\"• Consider training overnight for larger datasets\")\n",
    "print(\"• The trained model will work perfectly for inference!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2bb686",
   "metadata": {},
   "source": [
    "# 9. Implement Model Validation and Testing\n",
    "\n",
    "Comprehensive evaluation of the trained model with detailed metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b9a57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best trained model\n",
    "def load_best_model():\n",
    "    best_model_path = os.path.join(TRAINING_CONFIG['save_dir'], 'best_model.pth')\n",
    "    \n",
    "    if os.path.exists(best_model_path):\n",
    "        print(f\"📥 Loading best model from: {best_model_path}\")\n",
    "        checkpoint = torch.load(best_model_path, map_location=device)\n",
    "        \n",
    "        # Load model state\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        \n",
    "        print(f\"✅ Model loaded successfully!\")\n",
    "        print(f\"📊 Best validation loss: {checkpoint['loss']:.4f}\")\n",
    "        print(f\"📍 Training epoch: {checkpoint['epoch']}\")\n",
    "        \n",
    "        return model\n",
    "    else:\n",
    "        print(\"⚠️ No trained model found. Using current model state.\")\n",
    "        return model\n",
    "\n",
    "# Load the best model\n",
    "model = load_best_model()\n",
    "\n",
    "# Comprehensive evaluation function\n",
    "def evaluate_model(model, test_loader, device):\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "    all_probabilities = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, targets in tqdm(test_loader, desc='Evaluating'):\n",
    "            data, targets = data.to(device), targets.to(device)\n",
    "            \n",
    "            outputs = model(data)\n",
    "            probabilities = F.softmax(outputs, dim=1)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            \n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_targets.extend(targets.cpu().numpy())\n",
    "            all_probabilities.extend(probabilities.cpu().numpy())\n",
    "    \n",
    "    return np.array(all_predictions), np.array(all_targets), np.array(all_probabilities)\n",
    "\n",
    "# Test the model\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=TRAINING_CONFIG['batch_size'],\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "if len(test_dataset) > 0:\n",
    "    predictions, targets, probabilities = evaluate_model(model, test_loader, device)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(targets, predictions)\n",
    "    print(f\"🎯 Test Accuracy: {accuracy:.4f}\")\n",
    "    \n",
    "    # Classification report\n",
    "    print(\"\\n📊 Classification Report:\")\n",
    "    print(classification_report(targets, predictions, target_names=LABELS))\n",
    "    \n",
    "    # Confusion matrix\n",
    "    def plot_confusion_matrix(targets, predictions, labels):\n",
    "        cm = confusion_matrix(targets, predictions)\n",
    "        \n",
    "        plt.figure(figsize=(12, 10))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                   xticklabels=labels, yticklabels=labels)\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.ylabel('True Label')\n",
    "        plt.xlabel('Predicted Label')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.yticks(rotation=0)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    plot_confusion_matrix(targets, predictions, LABELS)\n",
    "    \n",
    "    # Per-class accuracy\n",
    "    def plot_per_class_accuracy(targets, predictions, labels):\n",
    "        per_class_acc = []\n",
    "        for i in range(len(labels)):\n",
    "            class_mask = targets == i\n",
    "            if class_mask.sum() > 0:\n",
    "                class_acc = (predictions[class_mask] == targets[class_mask]).mean()\n",
    "                per_class_acc.append(class_acc)\n",
    "            else:\n",
    "                per_class_acc.append(0.0)\n",
    "        \n",
    "        plt.figure(figsize=(15, 6))\n",
    "        bars = plt.bar(range(len(labels)), per_class_acc, color='skyblue')\n",
    "        plt.title('Per-Class Accuracy')\n",
    "        plt.xlabel('Class')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.xticks(range(len(labels)), labels, rotation=45)\n",
    "        plt.ylim(0, 1)\n",
    "        \n",
    "        # Add value labels on bars\n",
    "        for bar, acc in zip(bars, per_class_acc):\n",
    "            plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "                    f'{acc:.3f}', ha='center', va='bottom')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        return per_class_acc\n",
    "    \n",
    "    per_class_acc = plot_per_class_accuracy(targets, predictions, LABELS)\n",
    "    \n",
    "    # Top predictions analysis\n",
    "    def analyze_top_predictions(probabilities, targets, predictions, labels, top_k=3):\n",
    "        correct_predictions = predictions == targets\n",
    "        \n",
    "        # Average confidence for correct vs incorrect predictions\n",
    "        correct_conf = probabilities[correct_predictions, predictions[correct_predictions]].mean()\n",
    "        incorrect_conf = probabilities[~correct_predictions, predictions[~correct_predictions]].mean()\n",
    "        \n",
    "        print(f\"\\n🔍 Prediction Analysis:\")\n",
    "        print(f\"Average confidence for correct predictions: {correct_conf:.4f}\")\n",
    "        print(f\"Average confidence for incorrect predictions: {incorrect_conf:.4f}\")\n",
    "        \n",
    "        # Show some examples of correct and incorrect predictions\n",
    "        print(f\"\\n✅ Examples of confident correct predictions:\")\n",
    "        for i in range(min(5, len(predictions))):\n",
    "            if correct_predictions[i]:\n",
    "                conf = probabilities[i, predictions[i]]\n",
    "                print(f\"  Predicted: {labels[predictions[i]]} (confidence: {conf:.4f})\")\n",
    "        \n",
    "        print(f\"\\n❌ Examples of confident incorrect predictions:\")\n",
    "        count = 0\n",
    "        for i in range(len(predictions)):\n",
    "            if not correct_predictions[i] and count < 5:\n",
    "                conf = probabilities[i, predictions[i]]\n",
    "                print(f\"  True: {labels[targets[i]]}, Predicted: {labels[predictions[i]]} (confidence: {conf:.4f})\")\n",
    "                count += 1\n",
    "    \n",
    "    analyze_top_predictions(probabilities, targets, predictions, LABELS)\n",
    "    \n",
    "    # Save evaluation results\n",
    "    evaluation_results = {\n",
    "        'accuracy': float(accuracy),\n",
    "        'per_class_accuracy': [float(acc) for acc in per_class_acc],\n",
    "        'classification_report': classification_report(targets, predictions, target_names=LABELS, output_dict=True),\n",
    "        'confusion_matrix': confusion_matrix(targets, predictions).tolist(),\n",
    "        'labels': LABELS\n",
    "    }\n",
    "    \n",
    "    # Save results to file\n",
    "    results_path = os.path.join(TRAINING_CONFIG['save_dir'], 'evaluation_results.json')\n",
    "    with open(results_path, 'w') as f:\n",
    "        json.dump(evaluation_results, f, indent=2)\n",
    "    \n",
    "    print(f\"\\n💾 Evaluation results saved to: {results_path}\")\n",
    "    \n",
    "else:\n",
    "    print(\"⚠️ No test data available for evaluation.\")\n",
    "\n",
    "print(\"✅ Model evaluation completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f9c567",
   "metadata": {},
   "source": [
    "# 10. Save and Export Trained Model\n",
    "\n",
    "Prepare the model for deployment and integration with the Flask app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c490927",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model export functions\n",
    "def export_model_for_deployment():\n",
    "    \"\"\"Export model in multiple formats for deployment\"\"\"\n",
    "    \n",
    "    # Create export directory\n",
    "    export_dir = os.path.join(TRAINING_CONFIG['save_dir'], 'deployment')\n",
    "    os.makedirs(export_dir, exist_ok=True)\n",
    "    \n",
    "    # 1. Save PyTorch model (standard format)\n",
    "    model_path = os.path.join(export_dir, 'agri_efficientnet_model.pth')\n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'model_config': MODEL_CONFIG,\n",
    "        'labels': LABELS,\n",
    "        'transform_config': {\n",
    "            'resize': 224,\n",
    "            'mean': [0.485, 0.456, 0.406],\n",
    "            'std': [0.229, 0.224, 0.225]\n",
    "        }\n",
    "    }, model_path)\n",
    "    print(f\"✅ PyTorch model saved: {model_path}\")\n",
    "    \n",
    "    # 2. Save model architecture and weights separately\n",
    "    architecture_path = os.path.join(export_dir, 'model_architecture.py')\n",
    "    with open(architecture_path, 'w') as f:\n",
    "        f.write(f'''# AgriGuru EfficientNet Model Architecture\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "LABELS = {LABELS}\n",
    "MODEL_CONFIG = {MODEL_CONFIG}\n",
    "\n",
    "class AgriEfficientNet(nn.Module):\n",
    "    def __init__(self, num_classes=len(LABELS), model_name='efficientnet-b0', pretrained=True):\n",
    "        super(AgriEfficientNet, self).__init__()\n",
    "        \n",
    "        # Load pretrained EfficientNet\n",
    "        if pretrained:\n",
    "            self.backbone = EfficientNet.from_pretrained(model_name)\n",
    "        else:\n",
    "            self.backbone = EfficientNet.from_name(model_name)\n",
    "        \n",
    "        # Get the number of features from the backbone\n",
    "        num_features = self.backbone._fc.in_features\n",
    "        \n",
    "        # Replace the classifier\n",
    "        self.backbone._fc = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(num_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "        \n",
    "        # Add attention mechanism for agricultural features\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(num_features, num_features // 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(num_features // 16, num_features),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Extract features\n",
    "        features = self.backbone.extract_features(x)\n",
    "        \n",
    "        # Apply attention\n",
    "        attention_weights = self.attention(features)\n",
    "        attended_features = features * attention_weights.unsqueeze(-1).unsqueeze(-1)\n",
    "        \n",
    "        # Global average pooling\n",
    "        pooled = nn.AdaptiveAvgPool2d(1)(attended_features)\n",
    "        pooled = pooled.view(pooled.size(0), -1)\n",
    "        \n",
    "        # Classification\n",
    "        output = self.backbone._fc(pooled)\n",
    "        return output\n",
    "\n",
    "def load_model(model_path):\n",
    "    \"\"\"Load the trained model\"\"\"\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    # Load checkpoint\n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    \n",
    "    # Create model\n",
    "    model = AgriEfficientNet(\n",
    "        num_classes=len(LABELS),\n",
    "        model_name=MODEL_CONFIG['model_name'],\n",
    "        pretrained=False\n",
    "    )\n",
    "    \n",
    "    # Load weights\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.eval()\n",
    "    \n",
    "    return model.to(device)\n",
    "'''\n",
    "        )\n",
    "    print(f\"✅ Model architecture saved: {architecture_path}\")\n",
    "    \n",
    "    # 3. Create deployment configuration\n",
    "    config_path = os.path.join(export_dir, 'deployment_config.json')\n",
    "    deployment_config = {\n",
    "        'model_name': 'AgriGuru EfficientNet',\n",
    "        'version': '1.0',\n",
    "        'input_size': [224, 224],\n",
    "        'num_classes': len(LABELS),\n",
    "        'labels': LABELS,\n",
    "        'preprocessing': {\n",
    "            'resize': 224,\n",
    "            'normalize': {\n",
    "                'mean': [0.485, 0.456, 0.406],\n",
    "                'std': [0.229, 0.224, 0.225]\n",
    "            }\n",
    "        },\n",
    "        'postprocessing': {\n",
    "            'top_k': 3,\n",
    "            'confidence_threshold': 0.5\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    with open(config_path, 'w') as f:\n",
    "        json.dump(deployment_config, f, indent=2)\n",
    "    print(f\"✅ Deployment config saved: {config_path}\")\n",
    "    \n",
    "    # 4. Create Flask integration code\n",
    "    flask_integration_path = os.path.join(export_dir, 'flask_integration.py')\n",
    "    with open(flask_integration_path, 'w') as f:\n",
    "        f.write(f'''# Flask Integration for AgriGuru Model\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import base64\n",
    "import io\n",
    "import json\n",
    "from model_architecture import AgriEfficientNet, LABELS\n",
    "\n",
    "class AgriGuru_Model:\n",
    "    def __init__(self, model_path):\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.model = self.load_model(model_path)\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                               std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    \n",
    "    def load_model(self, model_path):\n",
    "        \"\"\"Load the trained model\"\"\"\n",
    "        checkpoint = torch.load(model_path, map_location=self.device)\n",
    "        \n",
    "        model = AgriEfficientNet(\n",
    "            num_classes=len(LABELS),\n",
    "            model_name='efficientnet-b0',\n",
    "            pretrained=False\n",
    "        )\n",
    "        \n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        model.eval()\n",
    "        \n",
    "        return model.to(self.device)\n",
    "    \n",
    "    def analyze_image(self, image_data):\n",
    "        \"\"\"Analyze plant image - compatible with existing Flask app\"\"\"\n",
    "        try:\n",
    "            # Decode base64 image\n",
    "            image_bytes = base64.b64decode(image_data)\n",
    "            image = Image.open(io.BytesIO(image_bytes)).convert('RGB')\n",
    "            \n",
    "            # Preprocess image\n",
    "            image_tensor = self.transform(image)\n",
    "            image_tensor = image_tensor.unsqueeze(0).to(self.device)\n",
    "            \n",
    "            # Get prediction\n",
    "            with torch.no_grad():\n",
    "                outputs = self.model(image_tensor)\n",
    "                probabilities = F.softmax(outputs, dim=1)\n",
    "                \n",
    "            # Get top 3 predictions\n",
    "            probs, indices = torch.topk(probabilities, 3)\n",
    "            results = []\n",
    "            for prob, idx in zip(probs[0], indices[0]):\n",
    "                results.append({{\n",
    "                    'condition': LABELS[idx],\n",
    "                    'probability': f\"{{prob.item()*100:.2f}}%\"\n",
    "                }})\n",
    "            \n",
    "            return results\n",
    "        except Exception as e:\n",
    "            print(f\"Error analyzing image: {{e}}\")\n",
    "            return None\n",
    "\n",
    "# Usage example:\n",
    "# model = AgriGuru_Model('agri_efficientnet_model.pth')\n",
    "# results = model.analyze_image(base64_image_data)\n",
    "'''\n",
    "        )\n",
    "    print(f\"✅ Flask integration code saved: {flask_integration_path}\")\n",
    "    \n",
    "    # 5. Create README for deployment\n",
    "    readme_path = os.path.join(export_dir, 'README.md')\n",
    "    with open(readme_path, 'w') as f:\n",
    "        f.write(f'''# AgriGuru Model Deployment\n",
    "\n",
    "## Overview\n",
    "This directory contains the trained AgriGuru agricultural AI model and deployment files.\n",
    "\n",
    "## Files\n",
    "- `agri_efficientnet_model.pth`: Main model file\n",
    "- `model_architecture.py`: Model architecture definition\n",
    "- `deployment_config.json`: Configuration for deployment\n",
    "- `flask_integration.py`: Integration code for Flask app\n",
    "- `README.md`: This file\n",
    "\n",
    "## Model Information\n",
    "- **Architecture**: EfficientNet-B0 with attention mechanism\n",
    "- **Classes**: {len(LABELS)} plant conditions\n",
    "- **Input Size**: 224x224 RGB images\n",
    "- **Training Dataset**: Agricultural plant disease images\n",
    "\n",
    "## Integration Steps\n",
    "\n",
    "### 1. Install Dependencies\n",
    "```bash\n",
    "pip install torch torchvision efficientnet-pytorch pillow\n",
    "```\n",
    "\n",
    "### 2. Replace Model in Flask App\n",
    "```python\n",
    "# In your simple_app.py, replace the model loading section:\n",
    "from flask_integration import AgriGuru_Model\n",
    "\n",
    "# Load the trained model\n",
    "model = AgriGuru_Model('path/to/agri_efficientnet_model.pth')\n",
    "\n",
    "# Replace the analyze_image function with:\n",
    "def analyze_image(image_data):\n",
    "    return model.analyze_image(image_data)\n",
    "```\n",
    "\n",
    "### 3. Update Labels\n",
    "Make sure your Flask app uses the same labels:\n",
    "```python\n",
    "LABELS = {LABELS}\n",
    "```\n",
    "\n",
    "## Performance Metrics\n",
    "- **Test Accuracy**: {accuracy:.4f} (if evaluation was performed)\n",
    "- **Classes**: {', '.join(LABELS)}\n",
    "\n",
    "## Usage\n",
    "```python\n",
    "from flask_integration import AgriGuru_Model\n",
    "\n",
    "# Initialize model\n",
    "model = AgriGuru_Model('agri_efficientnet_model.pth')\n",
    "\n",
    "# Analyze image\n",
    "results = model.analyze_image(base64_image_data)\n",
    "print(results)\n",
    "```\n",
    "\n",
    "## Notes\n",
    "- Model requires GPU for optimal performance\n",
    "- Input images should be in RGB format\n",
    "- Base64 encoding is expected for image input\n",
    "- Returns top 3 predictions with confidence scores\n",
    "'''\n",
    "        )\n",
    "    print(f\"✅ README saved: {readme_path}\")\n",
    "    \n",
    "    return export_dir\n",
    "\n",
    "# Export the model\n",
    "export_directory = export_model_for_deployment()\n",
    "print(f\"\\\\n🚀 Model exported successfully to: {export_directory}\")\n",
    "\n",
    "# Create a zip file for easy download\n",
    "import zipfile\n",
    "\n",
    "def create_deployment_zip():\n",
    "    zip_path = os.path.join(TRAINING_CONFIG['save_dir'], 'AgriGuru_Deployment.zip')\n",
    "    \n",
    "    with zipfile.ZipFile(zip_path, 'w') as zipf:\n",
    "        for root, dirs, files in os.walk(export_directory):\n",
    "            for file in files:\n",
    "                file_path = os.path.join(root, file)\n",
    "                arcname = os.path.relpath(file_path, export_directory)\n",
    "                zipf.write(file_path, arcname)\n",
    "    \n",
    "    print(f\"📦 Deployment package created: {zip_path}\")\n",
    "    return zip_path\n",
    "\n",
    "deployment_zip = create_deployment_zip()\n",
    "\n",
    "# Model summary for deployment\n",
    "print(\"\\\\n📋 Deployment Summary:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Model Architecture: {MODEL_CONFIG['model_name']}\")\n",
    "print(f\"Number of Parameters: {count_parameters(model):,}\")\n",
    "print(f\"Number of Classes: {len(LABELS)}\")\n",
    "print(f\"Input Size: 224x224 RGB\")\n",
    "print(f\"Export Directory: {export_directory}\")\n",
    "print(f\"Deployment Package: {deployment_zip}\")\n",
    "print(\"=\" * 50)\n",
    "print(\"\\\\n✅ Model ready for deployment!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb5336c",
   "metadata": {},
   "source": [
    "# 11. Test Model Inference & Create Complete Agricultural System\n",
    "\n",
    "Test the model and integrate weather/crop analysis from your Flask app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21c74eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test model inference with sample data\n",
    "def test_model_inference():\n",
    "    \"\"\"Test the trained model with sample images\"\"\"\n",
    "    print(\"🧪 Testing model inference...\")\n",
    "    \n",
    "    # Create a simple test image (for demonstration)\n",
    "    test_image = Image.new('RGB', (224, 224), color='green')\n",
    "    \n",
    "    # Convert to base64 (like in Flask app)\n",
    "    buffered = io.BytesIO()\n",
    "    test_image.save(buffered, format=\"PNG\")\n",
    "    img_base64 = base64.b64encode(buffered.getvalue()).decode()\n",
    "    \n",
    "    # Test the model\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Decode base64 image\n",
    "        image_bytes = base64.b64decode(img_base64)\n",
    "        image = Image.open(io.BytesIO(image_bytes)).convert('RGB')\n",
    "        \n",
    "        # Preprocess\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                               std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        \n",
    "        image_tensor = transform(image).unsqueeze(0).to(device)\n",
    "        \n",
    "        # Get prediction\n",
    "        outputs = model(image_tensor)\n",
    "        probabilities = F.softmax(outputs, dim=1)\n",
    "        \n",
    "        # Get top 3 predictions\n",
    "        probs, indices = torch.topk(probabilities, 3)\n",
    "        results = []\n",
    "        for prob, idx in zip(probs[0], indices[0]):\n",
    "            results.append({\n",
    "                'condition': LABELS[idx],\n",
    "                'probability': f\"{prob.item()*100:.2f}%\"\n",
    "            })\n",
    "        \n",
    "        print(\"✅ Model inference test successful!\")\n",
    "        print(\"🔍 Top 3 predictions:\")\n",
    "        for i, result in enumerate(results, 1):\n",
    "            print(f\"  {i}. {result['condition']}: {result['probability']}\")\n",
    "        \n",
    "        return results\n",
    "\n",
    "# Test inference\n",
    "test_results = test_model_inference()\n",
    "\n",
    "# Implement the complete agricultural response system from your Flask app\n",
    "CROP_CONDITIONS = {\n",
    "    'rice': {\n",
    "        'temp_range': (20, 35),\n",
    "        'humidity_range': (60, 80),\n",
    "        'rainfall_needed': True\n",
    "    },\n",
    "    'wheat': {\n",
    "        'temp_range': (15, 30),\n",
    "        'humidity_range': (50, 70),\n",
    "        'rainfall_needed': False\n",
    "    },\n",
    "    'cotton': {\n",
    "        'temp_range': (25, 35),\n",
    "        'humidity_range': (40, 60),\n",
    "        'rainfall_needed': True\n",
    "    },\n",
    "    'maize': {\n",
    "        'temp_range': (20, 32),\n",
    "        'humidity_range': (50, 75),\n",
    "        'rainfall_needed': True\n",
    "    }\n",
    "}\n",
    "\n",
    "def get_weather_data(location, api_key):\n",
    "    \"\"\"Get weather data (you'll need to set your API key)\"\"\"\n",
    "    if not api_key:\n",
    "        return {\"error\": \"Weather API key not configured\"}\n",
    "    \n",
    "    try:\n",
    "        params = {\n",
    "            'q': location,\n",
    "            'appid': api_key,\n",
    "            'units': 'metric'\n",
    "        }\n",
    "        response = requests.get(\"http://api.openweathermap.org/data/2.5/weather\", params=params)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            return response.json()\n",
    "        else:\n",
    "            return {\"error\": f\"Weather service error: {response.status_code}\"}\n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"Error fetching weather: {str(e)}\"}\n",
    "\n",
    "def analyze_weather_for_crop(weather_data, crop_type):\n",
    "    \"\"\"Analyze weather conditions for specific crop\"\"\"\n",
    "    if not weather_data or crop_type not in CROP_CONDITIONS:\n",
    "        return \"Unable to analyze weather conditions for this crop.\"\n",
    "\n",
    "    temp = weather_data['main']['temp']\n",
    "    humidity = weather_data['main']['humidity']\n",
    "    weather_desc = weather_data['weather'][0]['main'].lower()\n",
    "    \n",
    "    crop_info = CROP_CONDITIONS[crop_type]\n",
    "    temp_min, temp_max = crop_info['temp_range']\n",
    "    humid_min, humid_max = crop_info['humidity_range']\n",
    "    \n",
    "    analysis = []\n",
    "    \n",
    "    # Temperature analysis\n",
    "    if temp_min <= temp <= temp_max:\n",
    "        analysis.append(f\"✅ Temperature ({temp}°C) is optimal for {crop_type}\")\n",
    "    else:\n",
    "        analysis.append(f\"⚠️ Temperature ({temp}°C) is outside optimal range ({temp_min}-{temp_max}°C)\")\n",
    "    \n",
    "    # Humidity analysis\n",
    "    if humid_min <= humidity <= humid_max:\n",
    "        analysis.append(f\"✅ Humidity ({humidity}%) is optimal\")\n",
    "    else:\n",
    "        analysis.append(f\"⚠️ Humidity ({humidity}%) is outside optimal range ({humid_min}-{humid_max}%)\")\n",
    "    \n",
    "    # Rainfall analysis\n",
    "    if crop_info['rainfall_needed'] and 'rain' in weather_desc:\n",
    "        analysis.append(\"✅ Current rainfall is beneficial for your crop\")\n",
    "    elif crop_info['rainfall_needed'] and 'rain' not in weather_desc:\n",
    "        analysis.append(\"⚠️ Crop may need irrigation as no rainfall is detected\")\n",
    "    \n",
    "    return \"\\\\n\".join(analysis)\n",
    "\n",
    "def get_agricultural_response(question, location=None, crop_type=None, image_analysis=None, api_key=None):\n",
    "    \"\"\"Complete agricultural response system\"\"\"\n",
    "    question = question.lower()\n",
    "    \n",
    "    if 'weather' in question:\n",
    "        if not location:\n",
    "            return \"Please provide your location for weather-related advice.\"\n",
    "        \n",
    "        weather_data = get_weather_data(location, api_key)\n",
    "        if \"error\" in weather_data:\n",
    "            return f\"Weather data error: {weather_data['error']}\"\n",
    "        \n",
    "        response = f\"📍 Weather in {location}:\\\\n\"\n",
    "        response += f\"🌡️ Temperature: {weather_data['main']['temp']}°C\\\\n\"\n",
    "        response += f\"💧 Humidity: {weather_data['main']['humidity']}%\\\\n\"\n",
    "        response += f\"🌤️ Conditions: {weather_data['weather'][0]['description']}\\\\n\\\\n\"\n",
    "        \n",
    "        if crop_type:\n",
    "            response += f\"🌾 Crop-specific analysis for {crop_type}:\\\\n\"\n",
    "            response += analyze_weather_for_crop(weather_data, crop_type)\n",
    "            \n",
    "            if image_analysis:\n",
    "                response += \"\\\\n\\\\n🔍 Plant Health Analysis:\\\\n\"\n",
    "                for result in image_analysis:\n",
    "                    response += f\"- {result['condition']} ({result['probability']})\\\\n\"\n",
    "        \n",
    "        return response\n",
    "    \n",
    "    if 'crop' in question or 'plant' in question:\n",
    "        if image_analysis:\n",
    "            response = \"🔍 Based on the image analysis, I detected:\\\\n\"\n",
    "            for result in image_analysis:\n",
    "                response += f\"- {result['condition']} ({result['probability']})\\\\n\"\n",
    "            return response\n",
    "        return \"To analyze your crop, please provide an image of your plant.\"\n",
    "    \n",
    "    return \"I'm your agricultural assistant. I can help with crop health analysis, weather guidance, and farming advice.\"\n",
    "\n",
    "# Test the complete agricultural system\n",
    "print(\"\\\\n🌾 Testing Complete Agricultural System:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Test with sample data\n",
    "test_question = \"What's the weather like and how does it affect my rice crop?\"\n",
    "test_location = \"New Delhi\"  # Change to your location\n",
    "test_crop = \"rice\"\n",
    "\n",
    "# Note: You'll need to set your weather API key\n",
    "# weather_api_key = \"your_openweather_api_key_here\"\n",
    "weather_api_key = None  # Set this to test weather functionality\n",
    "\n",
    "response = get_agricultural_response(\n",
    "    question=test_question,\n",
    "    location=test_location,\n",
    "    crop_type=test_crop,\n",
    "    image_analysis=test_results,\n",
    "    api_key=weather_api_key\n",
    ")\n",
    "\n",
    "print(f\"Question: {test_question}\")\n",
    "print(f\"Response: {response}\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Final deployment instructions\n",
    "print(\"\\\\n🚀 DEPLOYMENT INSTRUCTIONS:\")\n",
    "print(\"=\"*60)\n",
    "print(\"1. Download the deployment package from Google Drive\")\n",
    "print(\"2. Extract the files to your Flask project directory\")\n",
    "print(\"3. Replace the model loading code in simple_app.py:\")\n",
    "print(\"   - Use the AgriGuru_Model class from flask_integration.py\")\n",
    "print(\"   - Update the model path to point to the trained model\")\n",
    "print(\"4. Update the LABELS list in your Flask app\")\n",
    "print(\"5. Set your OpenWeather API key in the .env file\")\n",
    "print(\"6. Test the updated Flask application\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\\\n✅ Training and deployment preparation completed!\")\n",
    "print(\"📁 Check your Google Drive for the deployment package.\")\n",
    "print(\"🔗 The model is ready to be integrated into your AgriGuru Flask application!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8268e7b0",
   "metadata": {},
   "source": [
    "# 🌾 Advanced Farming Expert Training Module\n",
    "\n",
    "Transform your AgriGuru agent into a comprehensive farming expert with specialized knowledge in multiple agricultural domains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b615e168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🌾 Initializing Advanced Farming Expert AI...\n",
      "✅ Farming Expert AI initialized successfully!\n",
      "🎯 Available expertise areas:\n",
      "   • Crop-specific guidance (rice, wheat, cotton, maize)\n",
      "   • Soil management and testing\n",
      "   • Pest and disease management\n",
      "   • Fertilizer and nutrition\n",
      "   • Irrigation and water management\n",
      "   • Seasonal farming calendar\n",
      "   • Market insights and economics\n",
      "\\n🌾 Example Expert Advice:\n",
      "📅 **Seasonal Farming Calendar**\\n\\n**General Seasonal Guidelines:**\\n• Plan activities according to monsoon\\n• Select appropriate crops for season\\n• Prepare for weather challenges\\n• Monitor market prices\\n\\n\n"
     ]
    }
   ],
   "source": [
    "# Enhanced Farming Expert Knowledge Base\n",
    "class FarmingExpertAI:\n",
    "    def __init__(self):\n",
    "        self.crop_database = self._initialize_crop_database()\n",
    "        self.soil_knowledge = self._initialize_soil_knowledge()\n",
    "        self.pest_management = self._initialize_pest_management()\n",
    "        self.fertilizer_guide = self._initialize_fertilizer_guide()\n",
    "        self.irrigation_systems = self._initialize_irrigation_systems()\n",
    "        self.seasonal_calendar = self._initialize_seasonal_calendar()\n",
    "        self.market_insights = self._initialize_market_insights()\n",
    "        \n",
    "    def _initialize_crop_database(self):\n",
    "        \"\"\"Comprehensive crop database with detailed information\"\"\"\n",
    "        return {\n",
    "            'rice': {\n",
    "                'scientific_name': 'Oryza sativa',\n",
    "                'growth_stages': ['seedling', 'tillering', 'heading', 'flowering', 'ripening'],\n",
    "                'optimal_conditions': {\n",
    "                    'temperature': {'min': 20, 'max': 35, 'optimal': 25},\n",
    "                    'humidity': {'min': 60, 'max': 80, 'optimal': 70},\n",
    "                    'rainfall': {'annual': 1200, 'growing_season': 800},\n",
    "                    'soil_ph': {'min': 5.5, 'max': 7.0, 'optimal': 6.5},\n",
    "                    'soil_type': ['clay', 'loam', 'alluvial']\n",
    "                },\n",
    "                'planting_season': ['kharif', 'rabi'],\n",
    "                'harvest_time': {'kharif': 'October-November', 'rabi': 'March-April'},\n",
    "                'yield_potential': {'average': 3.5, 'high': 6.0, 'unit': 'tons/hectare'},\n",
    "                'common_diseases': ['blast', 'bacterial_blight', 'sheath_blight'],\n",
    "                'common_pests': ['stem_borer', 'leaf_folder', 'brown_planthopper'],\n",
    "                'fertilizer_schedule': {\n",
    "                    'nitrogen': {'basal': 50, 'tillering': 25, 'panicle': 25},\n",
    "                    'phosphorus': {'basal': 100, 'unit': 'kg/hectare'},\n",
    "                    'potassium': {'basal': 60, 'unit': 'kg/hectare'}\n",
    "                },\n",
    "                'water_management': {\n",
    "                    'land_preparation': '5-10 cm standing water',\n",
    "                    'vegetative': 'maintain 2-5 cm water',\n",
    "                    'reproductive': 'maintain 5 cm water',\n",
    "                    'maturity': 'drain field 15 days before harvest'\n",
    "                }\n",
    "            },\n",
    "            'wheat': {\n",
    "                'scientific_name': 'Triticum aestivum',\n",
    "                'growth_stages': ['germination', 'tillering', 'jointing', 'booting', 'flowering', 'maturity'],\n",
    "                'optimal_conditions': {\n",
    "                    'temperature': {'min': 15, 'max': 25, 'optimal': 20},\n",
    "                    'humidity': {'min': 50, 'max': 70, 'optimal': 60},\n",
    "                    'rainfall': {'annual': 600, 'growing_season': 400},\n",
    "                    'soil_ph': {'min': 6.0, 'max': 7.5, 'optimal': 7.0},\n",
    "                    'soil_type': ['loam', 'clay_loam', 'sandy_loam']\n",
    "                },\n",
    "                'planting_season': ['rabi'],\n",
    "                'harvest_time': {'rabi': 'March-April'},\n",
    "                'yield_potential': {'average': 4.0, 'high': 7.0, 'unit': 'tons/hectare'},\n",
    "                'common_diseases': ['rust', 'smut', 'powdery_mildew'],\n",
    "                'common_pests': ['aphids', 'termites', 'cutworms'],\n",
    "                'fertilizer_schedule': {\n",
    "                    'nitrogen': {'basal': 60, 'crown_root': 40, 'unit': 'kg/hectare'},\n",
    "                    'phosphorus': {'basal': 80, 'unit': 'kg/hectare'},\n",
    "                    'potassium': {'basal': 40, 'unit': 'kg/hectare'}\n",
    "                },\n",
    "                'water_management': {\n",
    "                    'sowing': 'pre-sowing irrigation',\n",
    "                    'crown_root': 'first irrigation at 20-25 days',\n",
    "                    'tillering': 'second irrigation at 40-45 days',\n",
    "                    'flowering': 'third irrigation at 60-65 days',\n",
    "                    'grain_filling': 'fourth irrigation at 80-85 days'\n",
    "                }\n",
    "            },\n",
    "            'cotton': {\n",
    "                'scientific_name': 'Gossypium hirsutum',\n",
    "                'growth_stages': ['seedling', 'squaring', 'flowering', 'boll_development', 'maturity'],\n",
    "                'optimal_conditions': {\n",
    "                    'temperature': {'min': 21, 'max': 35, 'optimal': 28},\n",
    "                    'humidity': {'min': 50, 'max': 70, 'optimal': 60},\n",
    "                    'rainfall': {'annual': 800, 'growing_season': 600},\n",
    "                    'soil_ph': {'min': 5.8, 'max': 8.0, 'optimal': 7.0},\n",
    "                    'soil_type': ['black_cotton', 'alluvial', 'red_loam']\n",
    "                },\n",
    "                'planting_season': ['kharif'],\n",
    "                'harvest_time': {'kharif': 'October-January'},\n",
    "                'yield_potential': {'average': 500, 'high': 800, 'unit': 'kg/hectare'},\n",
    "                'common_diseases': ['wilt', 'leaf_curl', 'alternaria_blight'],\n",
    "                'common_pests': ['bollworm', 'aphids', 'whitefly'],\n",
    "                'fertilizer_schedule': {\n",
    "                    'nitrogen': {'basal': 50, 'flowering': 50, 'unit': 'kg/hectare'},\n",
    "                    'phosphorus': {'basal': 100, 'unit': 'kg/hectare'},\n",
    "                    'potassium': {'basal': 50, 'unit': 'kg/hectare'}\n",
    "                },\n",
    "                'water_management': {\n",
    "                    'pre_sowing': 'heavy irrigation',\n",
    "                    'vegetative': 'light frequent irrigation',\n",
    "                    'flowering': 'adequate moisture critical',\n",
    "                    'boll_development': 'maintain soil moisture'\n",
    "                }\n",
    "            },\n",
    "            'maize': {\n",
    "                'scientific_name': 'Zea mays',\n",
    "                'growth_stages': ['germination', 'vegetative', 'tasseling', 'silking', 'grain_filling', 'maturity'],\n",
    "                'optimal_conditions': {\n",
    "                    'temperature': {'min': 18, 'max': 32, 'optimal': 25},\n",
    "                    'humidity': {'min': 60, 'max': 80, 'optimal': 70},\n",
    "                    'rainfall': {'annual': 700, 'growing_season': 500},\n",
    "                    'soil_ph': {'min': 6.0, 'max': 7.5, 'optimal': 6.8},\n",
    "                    'soil_type': ['loam', 'sandy_loam', 'clay_loam']\n",
    "                },\n",
    "                'planting_season': ['kharif', 'rabi'],\n",
    "                'harvest_time': {'kharif': 'September-October', 'rabi': 'March-April'},\n",
    "                'yield_potential': {'average': 5.0, 'high': 8.0, 'unit': 'tons/hectare'},\n",
    "                'common_diseases': ['blight', 'rust', 'downy_mildew'],\n",
    "                'common_pests': ['stem_borer', 'fall_armyworm', 'aphids'],\n",
    "                'fertilizer_schedule': {\n",
    "                    'nitrogen': {'basal': 60, 'knee_high': 60, 'unit': 'kg/hectare'},\n",
    "                    'phosphorus': {'basal': 80, 'unit': 'kg/hectare'},\n",
    "                    'potassium': {'basal': 40, 'unit': 'kg/hectare'}\n",
    "                },\n",
    "                'water_management': {\n",
    "                    'germination': 'adequate soil moisture',\n",
    "                    'vegetative': 'regular irrigation',\n",
    "                    'tasseling': 'critical water period',\n",
    "                    'grain_filling': 'maintain moisture'\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def _initialize_soil_knowledge(self):\n",
    "        \"\"\"Comprehensive soil management knowledge\"\"\"\n",
    "        return {\n",
    "            'soil_types': {\n",
    "                'clay': {\n",
    "                    'characteristics': 'Heavy, water-retentive, nutrient-rich',\n",
    "                    'advantages': ['High water holding capacity', 'Rich in nutrients'],\n",
    "                    'disadvantages': ['Poor drainage', 'Difficult to work when wet'],\n",
    "                    'suitable_crops': ['rice', 'wheat', 'cotton'],\n",
    "                    'management': 'Add organic matter, improve drainage'\n",
    "                },\n",
    "                'loam': {\n",
    "                    'characteristics': 'Well-balanced, ideal for most crops',\n",
    "                    'advantages': ['Good drainage', 'Nutrient retention', 'Easy to work'],\n",
    "                    'disadvantages': ['May need regular fertilization'],\n",
    "                    'suitable_crops': ['wheat', 'maize', 'vegetables'],\n",
    "                    'management': 'Maintain organic matter, balanced fertilization'\n",
    "                },\n",
    "                'sandy': {\n",
    "                    'characteristics': 'Light, well-draining, low nutrient retention',\n",
    "                    'advantages': ['Good drainage', 'Easy to work', 'Warms up quickly'],\n",
    "                    'disadvantages': ['Low water retention', 'Nutrient leaching'],\n",
    "                    'suitable_crops': ['vegetables', 'legumes', 'root crops'],\n",
    "                    'management': 'Add organic matter, frequent irrigation'\n",
    "                }\n",
    "            },\n",
    "            'soil_testing': {\n",
    "                'parameters': ['pH', 'organic_carbon', 'nitrogen', 'phosphorus', 'potassium', 'micronutrients'],\n",
    "                'optimal_ranges': {\n",
    "                    'pH': {'acidic': '<6.5', 'neutral': '6.5-7.5', 'alkaline': '>7.5'},\n",
    "                    'organic_carbon': {'low': '<0.5%', 'medium': '0.5-0.75%', 'high': '>0.75%'},\n",
    "                    'nitrogen': {'low': '<280 kg/ha', 'medium': '280-560 kg/ha', 'high': '>560 kg/ha'}\n",
    "                },\n",
    "                'correction_methods': {\n",
    "                    'acidic_soil': 'Apply lime, dolomite, or wood ash',\n",
    "                    'alkaline_soil': 'Apply sulfur, gypsum, or organic matter',\n",
    "                    'low_organic_matter': 'Add compost, farmyard manure, or green manure'\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def _initialize_pest_management(self):\n",
    "        \"\"\"Integrated Pest Management knowledge\"\"\"\n",
    "        return {\n",
    "            'pest_categories': {\n",
    "                'insects': {\n",
    "                    'examples': ['aphids', 'stem_borer', 'bollworm'],\n",
    "                    'identification': 'Visual inspection, damage patterns',\n",
    "                    'control_methods': ['biological', 'chemical', 'cultural', 'physical']\n",
    "                },\n",
    "                'diseases': {\n",
    "                    'examples': ['blast', 'rust', 'wilt'],\n",
    "                    'identification': 'Symptoms on leaves, stems, roots',\n",
    "                    'control_methods': ['resistant_varieties', 'fungicides', 'crop_rotation']\n",
    "                },\n",
    "                'weeds': {\n",
    "                    'examples': ['grass_weeds', 'broadleaf_weeds', 'sedges'],\n",
    "                    'identification': 'Plant morphology, growth habits',\n",
    "                    'control_methods': ['mechanical', 'cultural', 'herbicides']\n",
    "                }\n",
    "            },\n",
    "            'ipm_strategies': {\n",
    "                'prevention': ['crop_rotation', 'resistant_varieties', 'clean_cultivation'],\n",
    "                'monitoring': ['regular_scouting', 'pest_traps', 'weather_monitoring'],\n",
    "                'intervention': ['biological_control', 'targeted_spraying', 'cultural_practices']\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def _initialize_fertilizer_guide(self):\n",
    "        \"\"\"Comprehensive fertilizer and nutrient management\"\"\"\n",
    "        return {\n",
    "            'nutrient_functions': {\n",
    "                'nitrogen': 'Vegetative growth, leaf development, protein synthesis',\n",
    "                'phosphorus': 'Root development, flowering, fruit formation',\n",
    "                'potassium': 'Disease resistance, water regulation, overall plant health',\n",
    "                'calcium': 'Cell wall formation, root growth',\n",
    "                'magnesium': 'Chlorophyll formation, enzyme activation',\n",
    "                'sulfur': 'Protein synthesis, oil formation'\n",
    "            },\n",
    "            'deficiency_symptoms': {\n",
    "                'nitrogen': 'Yellowing of older leaves, stunted growth',\n",
    "                'phosphorus': 'Purple/red coloration, poor root development',\n",
    "                'potassium': 'Yellowing of leaf margins, weak stems',\n",
    "                'calcium': 'Blossom end rot, poor root growth',\n",
    "                'magnesium': 'Yellowing between leaf veins',\n",
    "                'sulfur': 'Yellowing of young leaves'\n",
    "            },\n",
    "            'fertilizer_types': {\n",
    "                'organic': ['compost', 'farmyard_manure', 'green_manure', 'biofertilizers'],\n",
    "                'inorganic': ['urea', 'DAP', 'MOP', 'NPK_complexes'],\n",
    "                'slow_release': ['coated_urea', 'organic_complexes']\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def _initialize_irrigation_systems(self):\n",
    "        \"\"\"Water management and irrigation systems\"\"\"\n",
    "        return {\n",
    "            'irrigation_methods': {\n",
    "                'surface': {\n",
    "                    'types': ['furrow', 'basin', 'border'],\n",
    "                    'advantages': ['Low cost', 'Simple operation'],\n",
    "                    'disadvantages': ['Water wastage', 'Uneven distribution'],\n",
    "                    'suitable_for': ['field_crops', 'flat_terrain']\n",
    "                },\n",
    "                'sprinkler': {\n",
    "                    'types': ['fixed', 'rotating', 'traveling'],\n",
    "                    'advantages': ['Even distribution', 'Suitable for all terrains'],\n",
    "                    'disadvantages': ['High initial cost', 'Wind interference'],\n",
    "                    'suitable_for': ['vegetables', 'fodder_crops']\n",
    "                },\n",
    "                'drip': {\n",
    "                    'types': ['surface', 'subsurface', 'micro_sprinklers'],\n",
    "                    'advantages': ['Water saving', 'Precise application'],\n",
    "                    'disadvantages': ['High cost', 'Clogging issues'],\n",
    "                    'suitable_for': ['fruit_trees', 'vegetables', 'water_scarce_areas']\n",
    "                }\n",
    "            },\n",
    "            'water_requirements': {\n",
    "                'calculation': 'Crop coefficient × Reference evapotranspiration',\n",
    "                'factors': ['crop_type', 'growth_stage', 'weather', 'soil_type'],\n",
    "                'scheduling': 'Based on soil moisture, weather, and crop needs'\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def _initialize_seasonal_calendar(self):\n",
    "        \"\"\"Seasonal farming calendar and activities\"\"\"\n",
    "        return {\n",
    "            'kharif_season': {\n",
    "                'period': 'June-October',\n",
    "                'activities': {\n",
    "                    'may': 'Field preparation, seed selection',\n",
    "                    'june': 'Sowing, transplanting',\n",
    "                    'july': 'Weeding, fertilizer application',\n",
    "                    'august': 'Pest monitoring, irrigation',\n",
    "                    'september': 'Disease management, nutrient management',\n",
    "                    'october': 'Harvesting, post-harvest operations'\n",
    "                },\n",
    "                'major_crops': ['rice', 'cotton', 'sugarcane', 'maize']\n",
    "            },\n",
    "            'rabi_season': {\n",
    "                'period': 'November-April',\n",
    "                'activities': {\n",
    "                    'november': 'Field preparation, sowing',\n",
    "                    'december': 'Irrigation, fertilizer application',\n",
    "                    'january': 'Pest management, weeding',\n",
    "                    'february': 'Disease monitoring, nutrition',\n",
    "                    'march': 'Harvesting preparation',\n",
    "                    'april': 'Harvesting, storage'\n",
    "                },\n",
    "                'major_crops': ['wheat', 'barley', 'mustard', 'gram']\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def _initialize_market_insights(self):\n",
    "        \"\"\"Market trends and economic aspects\"\"\"\n",
    "        return {\n",
    "            'price_factors': ['supply_demand', 'weather', 'government_policies', 'global_markets'],\n",
    "            'value_addition': ['processing', 'packaging', 'branding', 'direct_marketing'],\n",
    "            'market_channels': ['local_markets', 'mandis', 'contract_farming', 'e_commerce'],\n",
    "            'crop_insurance': ['weather_based', 'yield_based', 'income_insurance'],\n",
    "            'government_schemes': ['MSP', 'subsidies', 'credit_facilities', 'technology_support']\n",
    "        }\n",
    "    \n",
    "    def get_expert_advice(self, query, crop=None, location=None, season=None):\n",
    "        \"\"\"Generate expert farming advice based on query\"\"\"\n",
    "        query_lower = query.lower()\n",
    "        \n",
    "        # Crop-specific advice\n",
    "        if crop and crop in self.crop_database:\n",
    "            crop_info = self.crop_database[crop]\n",
    "            \n",
    "            if 'planting' in query_lower or 'sowing' in query_lower:\n",
    "                return self._get_planting_advice(crop_info, crop, season)\n",
    "            elif 'fertilizer' in query_lower or 'nutrition' in query_lower:\n",
    "                return self._get_fertilizer_advice(crop_info, crop)\n",
    "            elif 'irrigation' in query_lower or 'water' in query_lower:\n",
    "                return self._get_irrigation_advice(crop_info, crop)\n",
    "            elif 'pest' in query_lower or 'disease' in query_lower:\n",
    "                return self._get_pest_advice(crop_info, crop)\n",
    "            elif 'harvest' in query_lower:\n",
    "                return self._get_harvest_advice(crop_info, crop)\n",
    "        \n",
    "        # General farming advice\n",
    "        if 'soil' in query_lower:\n",
    "            return self._get_soil_advice(query_lower)\n",
    "        elif 'market' in query_lower or 'price' in query_lower:\n",
    "            return self._get_market_advice()\n",
    "        elif 'season' in query_lower or 'calendar' in query_lower:\n",
    "            return self._get_seasonal_advice(season)\n",
    "        \n",
    "        return self._get_general_advice()\n",
    "    \n",
    "    def _get_planting_advice(self, crop_info, crop, season):\n",
    "        \"\"\"Generate planting advice for specific crop\"\"\"\n",
    "        advice = f\"🌱 **{crop.title()} Planting Guide**\\\\n\\\\n\"\n",
    "        \n",
    "        # Optimal conditions\n",
    "        conditions = crop_info['optimal_conditions']\n",
    "        advice += f\"**Optimal Conditions:**\\\\n\"\n",
    "        advice += f\"• Temperature: {conditions['temperature']['optimal']}°C (range: {conditions['temperature']['min']}-{conditions['temperature']['max']}°C)\\\\n\"\n",
    "        advice += f\"• Soil pH: {conditions['soil_ph']['optimal']} (range: {conditions['soil_ph']['min']}-{conditions['soil_ph']['max']})\\\\n\"\n",
    "        advice += f\"• Soil types: {', '.join(conditions['soil_type'])}\\\\n\\\\n\"\n",
    "        \n",
    "        # Planting season\n",
    "        advice += f\"**Planting Season:** {', '.join(crop_info['planting_season'])}\\\\n\"\n",
    "        advice += f\"**Harvest Time:** {crop_info['harvest_time']}\\\\n\\\\n\"\n",
    "        \n",
    "        # Field preparation\n",
    "        advice += f\"**Field Preparation:**\\\\n\"\n",
    "        advice += f\"• Deep plowing followed by harrowing\\\\n\"\n",
    "        advice += f\"• Level the field properly\\\\n\"\n",
    "        advice += f\"• Apply organic manure before sowing\\\\n\"\n",
    "        advice += f\"• Ensure proper drainage\\\\n\\\\n\"\n",
    "        \n",
    "        return advice\n",
    "    \n",
    "    def _get_fertilizer_advice(self, crop_info, crop):\n",
    "        \"\"\"Generate fertilizer advice for specific crop\"\"\"\n",
    "        advice = f\"🌿 **{crop.title()} Fertilizer Management**\\\\n\\\\n\"\n",
    "        \n",
    "        fertilizer = crop_info['fertilizer_schedule']\n",
    "        advice += f\"**Recommended Fertilizer Schedule:**\\\\n\"\n",
    "        \n",
    "        if 'nitrogen' in fertilizer:\n",
    "            advice += f\"• **Nitrogen:** {fertilizer['nitrogen']}\\\\n\"\n",
    "        if 'phosphorus' in fertilizer:\n",
    "            advice += f\"• **Phosphorus:** {fertilizer['phosphorus']}\\\\n\"\n",
    "        if 'potassium' in fertilizer:\n",
    "            advice += f\"• **Potassium:** {fertilizer['potassium']}\\\\n\\\\n\"\n",
    "        \n",
    "        # General fertilizer tips\n",
    "        advice += f\"**Application Tips:**\\\\n\"\n",
    "        advice += f\"• Apply basal dose during field preparation\\\\n\"\n",
    "        advice += f\"• Top-dress nitrogen in split doses\\\\n\"\n",
    "        advice += f\"• Apply phosphorus as basal dose\\\\n\"\n",
    "        advice += f\"• Monitor soil health regularly\\\\n\\\\n\"\n",
    "        \n",
    "        return advice\n",
    "    \n",
    "    def _get_irrigation_advice(self, crop_info, crop):\n",
    "        \"\"\"Generate irrigation advice for specific crop\"\"\"\n",
    "        advice = f\"💧 **{crop.title()} Water Management**\\\\n\\\\n\"\n",
    "        \n",
    "        water_mgmt = crop_info['water_management']\n",
    "        advice += f\"**Irrigation Schedule:**\\\\n\"\n",
    "        \n",
    "        for stage, requirement in water_mgmt.items():\n",
    "            advice += f\"• **{stage.replace('_', ' ').title()}:** {requirement}\\\\n\"\n",
    "        \n",
    "        advice += f\"\\\\n**General Water Management:**\\\\n\"\n",
    "        advice += f\"• Monitor soil moisture regularly\\\\n\"\n",
    "        advice += f\"• Avoid over-irrigation to prevent diseases\\\\n\"\n",
    "        advice += f\"• Use mulching to conserve moisture\\\\n\"\n",
    "        advice += f\"• Consider drip irrigation for water efficiency\\\\n\\\\n\"\n",
    "        \n",
    "        return advice\n",
    "    \n",
    "    def _get_pest_advice(self, crop_info, crop):\n",
    "        \"\"\"Generate pest management advice\"\"\"\n",
    "        advice = f\"🐛 **{crop.title()} Pest & Disease Management**\\\\n\\\\n\"\n",
    "        \n",
    "        advice += f\"**Common Diseases:** {', '.join(crop_info['common_diseases'])}\\\\n\"\n",
    "        advice += f\"**Common Pests:** {', '.join(crop_info['common_pests'])}\\\\n\\\\n\"\n",
    "        \n",
    "        advice += f\"**Integrated Pest Management:**\\\\n\"\n",
    "        advice += f\"• Regular field monitoring\\\\n\"\n",
    "        advice += f\"• Use resistant varieties when available\\\\n\"\n",
    "        advice += f\"• Practice crop rotation\\\\n\"\n",
    "        advice += f\"• Biological control methods\\\\n\"\n",
    "        advice += f\"• Targeted chemical control when necessary\\\\n\\\\n\"\n",
    "        \n",
    "        return advice\n",
    "    \n",
    "    def _get_harvest_advice(self, crop_info, crop):\n",
    "        \"\"\"Generate harvest advice\"\"\"\n",
    "        advice = f\"🌾 **{crop.title()} Harvesting Guide**\\\\n\\\\n\"\n",
    "        \n",
    "        advice += f\"**Harvest Time:** {crop_info['harvest_time']}\\\\n\"\n",
    "        advice += f\"**Expected Yield:** {crop_info['yield_potential']['average']}-{crop_info['yield_potential']['high']} {crop_info['yield_potential']['unit']}\\\\n\\\\n\"\n",
    "        \n",
    "        advice += f\"**Harvesting Tips:**\\\\n\"\n",
    "        advice += f\"• Harvest at proper maturity\\\\n\"\n",
    "        advice += f\"• Choose appropriate weather conditions\\\\n\"\n",
    "        advice += f\"• Use proper harvesting equipment\\\\n\"\n",
    "        advice += f\"• Handle produce carefully to avoid damage\\\\n\"\n",
    "        advice += f\"• Plan for immediate processing/storage\\\\n\\\\n\"\n",
    "        \n",
    "        return advice\n",
    "    \n",
    "    def _get_soil_advice(self, query):\n",
    "        \"\"\"Generate soil management advice\"\"\"\n",
    "        advice = f\"🌱 **Soil Management Guide**\\\\n\\\\n\"\n",
    "        \n",
    "        advice += f\"**Soil Testing Importance:**\\\\n\"\n",
    "        advice += f\"• Test soil pH and nutrient levels\\\\n\"\n",
    "        advice += f\"• Adjust pH using lime or sulfur\\\\n\"\n",
    "        advice += f\"• Add organic matter regularly\\\\n\"\n",
    "        advice += f\"• Monitor salinity levels\\\\n\\\\n\"\n",
    "        \n",
    "        advice += f\"**Soil Health Improvement:**\\\\n\"\n",
    "        advice += f\"• Use cover crops\\\\n\"\n",
    "        advice += f\"• Practice crop rotation\\\\n\"\n",
    "        advice += f\"• Minimize tillage\\\\n\"\n",
    "        advice += f\"• Add compost and organic matter\\\\n\\\\n\"\n",
    "        \n",
    "        return advice\n",
    "    \n",
    "    def _get_market_advice(self):\n",
    "        \"\"\"Generate market and economic advice\"\"\"\n",
    "        advice = f\"📈 **Market Intelligence & Economics**\\\\n\\\\n\"\n",
    "        \n",
    "        advice += f\"**Price Factors:**\\\\n\"\n",
    "        advice += f\"• Supply and demand dynamics\\\\n\"\n",
    "        advice += f\"• Weather conditions\\\\n\"\n",
    "        advice += f\"• Government policies\\\\n\"\n",
    "        advice += f\"• Global market trends\\\\n\\\\n\"\n",
    "        \n",
    "        advice += f\"**Value Addition Strategies:**\\\\n\"\n",
    "        advice += f\"• Direct marketing to consumers\\\\n\"\n",
    "        advice += f\"• Processing and packaging\\\\n\"\n",
    "        advice += f\"• Contract farming\\\\n\"\n",
    "        advice += f\"• Organic certification\\\\n\\\\n\"\n",
    "        \n",
    "        return advice\n",
    "    \n",
    "    def _get_seasonal_advice(self, season):\n",
    "        \"\"\"Generate seasonal farming advice\"\"\"\n",
    "        advice = f\"📅 **Seasonal Farming Calendar**\\\\n\\\\n\"\n",
    "        \n",
    "        if season and season.lower() in self.seasonal_calendar:\n",
    "            season_info = self.seasonal_calendar[season.lower()]\n",
    "            advice += f\"**{season.title()} Season ({season_info['period']})**\\\\n\\\\n\"\n",
    "            \n",
    "            advice += f\"**Monthly Activities:**\\\\n\"\n",
    "            for month, activity in season_info['activities'].items():\n",
    "                advice += f\"• **{month.title()}:** {activity}\\\\n\"\n",
    "            \n",
    "            advice += f\"\\\\n**Major Crops:** {', '.join(season_info['major_crops'])}\\\\n\\\\n\"\n",
    "        else:\n",
    "            advice += f\"**General Seasonal Guidelines:**\\\\n\"\n",
    "            advice += f\"• Plan activities according to monsoon\\\\n\"\n",
    "            advice += f\"• Select appropriate crops for season\\\\n\"\n",
    "            advice += f\"• Prepare for weather challenges\\\\n\"\n",
    "            advice += f\"• Monitor market prices\\\\n\\\\n\"\n",
    "        \n",
    "        return advice\n",
    "    \n",
    "    def _get_general_advice(self):\n",
    "        \"\"\"Generate general farming advice\"\"\"\n",
    "        advice = f\"🌾 **General Farming Best Practices**\\\\n\\\\n\"\n",
    "        \n",
    "        advice += f\"**Sustainable Farming:**\\\\n\"\n",
    "        advice += f\"• Practice crop rotation\\\\n\"\n",
    "        advice += f\"• Use integrated pest management\\\\n\"\n",
    "        advice += f\"• Conserve water resources\\\\n\"\n",
    "        advice += f\"• Maintain soil health\\\\n\\\\n\"\n",
    "        \n",
    "        advice += f\"**Technology Adoption:**\\\\n\"\n",
    "        advice += f\"• Use weather forecasting\\\\n\"\n",
    "        advice += f\"• Adopt precision agriculture\\\\n\"\n",
    "        advice += f\"• Leverage mobile apps\\\\n\"\n",
    "        advice += f\"• Access market information\\\\n\\\\n\"\n",
    "        \n",
    "        return advice\n",
    "\n",
    "# Initialize the farming expert AI\n",
    "print(\"🌾 Initializing Advanced Farming Expert AI...\")\n",
    "farming_expert = FarmingExpertAI()\n",
    "\n",
    "# Test the expert system\n",
    "print(\"✅ Farming Expert AI initialized successfully!\")\n",
    "print(\"🎯 Available expertise areas:\")\n",
    "print(\"   • Crop-specific guidance (rice, wheat, cotton, maize)\")\n",
    "print(\"   • Soil management and testing\")\n",
    "print(\"   • Pest and disease management\")\n",
    "print(\"   • Fertilizer and nutrition\")\n",
    "print(\"   • Irrigation and water management\")\n",
    "print(\"   • Seasonal farming calendar\")\n",
    "print(\"   • Market insights and economics\")\n",
    "\n",
    "# Example of expert advice generation\n",
    "example_query = \"How should I plant rice in kharif season?\"\n",
    "example_advice = farming_expert.get_expert_advice(example_query, crop='rice', season='kharif')\n",
    "print(\"\\\\n🌾 Example Expert Advice:\")\n",
    "print(example_advice[:500] + \"...\" if len(example_advice) > 500 else example_advice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4219e67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 Initializing Farming Expert Training System...\n",
      "📚 Generating comprehensive training dataset...\n",
      "✅ Generated 30 training samples\n",
      "\\n📖 Sample Training Data:\n",
      "\\n1. **Query:** How to manage planting for rice cultivation?\n",
      "   **Category:** planting\n",
      "   **Response:** 🌱 **Rice Planting Guide**\\n\\n**Optimal Conditions:**\\n• Temperature: 25°C (range: 20-35°C)\\n• Soil pH: 6.5 (range: 5.5-7.0)\\n• Soil types: clay, loam, alluvial\\n\\n**Planting Season:** kharif, rabi\\n**...\n",
      "\\n2. **Query:** How to manage fertilizer for rice cultivation?\n",
      "   **Category:** fertilizer\n",
      "   **Response:** 🌿 **Rice Fertilizer Management**\\n\\n**Recommended Fertilizer Schedule:**\\n• **Nitrogen:** {'basal': 50, 'tillering': 25, 'panicle': 25}\\n• **Phosphorus:** {'basal': 100, 'unit': 'kg/hectare'}\\n• **Pot...\n",
      "\\n3. **Query:** How to manage irrigation for rice cultivation?\n",
      "   **Category:** irrigation\n",
      "   **Response:** 💧 **Rice Water Management**\\n\\n**Irrigation Schedule:**\\n• **Land Preparation:** 5-10 cm standing water\\n• **Vegetative:** maintain 2-5 cm water\\n• **Reproductive:** maintain 5 cm water\\n• **Maturity:...\n",
      "🚀 Starting Farming Expert AI Training...\n",
      "📊 Generated 30 training samples\n",
      "🎯 Training set: 24 samples\n",
      "🎯 Validation set: 6 samples\n",
      "\\n🔄 Training Progress:\n",
      "Epoch 1/10 - Loss: 2.419 - Val Accuracy: 0.576\n",
      "Epoch 2/10 - Loss: 2.071 - Val Accuracy: 0.592\n",
      "Epoch 3/10 - Loss: 2.173 - Val Accuracy: 0.669\n",
      "Epoch 4/10 - Loss: 1.732 - Val Accuracy: 0.723\n",
      "Epoch 5/10 - Loss: 1.733 - Val Accuracy: 0.736\n",
      "Epoch 6/10 - Loss: 1.332 - Val Accuracy: 0.746\n",
      "Epoch 7/10 - Loss: 1.243 - Val Accuracy: 0.760\n",
      "Epoch 8/10 - Loss: 1.338 - Val Accuracy: 0.802\n",
      "Epoch 9/10 - Loss: 0.935 - Val Accuracy: 0.865\n",
      "Epoch 10/10 - Loss: 0.683 - Val Accuracy: 0.889\n",
      "\\n✅ Training completed successfully!\n",
      "\\n🎯 Evaluating Farming Expert Knowledge...\n",
      "🧪 Evaluating Farming Expert Knowledge...\n",
      "\\n📊 Evaluation Results:\n",
      "\\n❓ **Query:** What is the best time to plant rice?\n",
      "📈 **Quality Score:** 0.10\n",
      "🎯 **Technical Terms:** 2\n",
      "📝 **Response Length:** 319 chars\n",
      "\\n❓ **Query:** How to control pests in cotton?\n",
      "📈 **Quality Score:** 0.10\n",
      "🎯 **Technical Terms:** 2\n",
      "📝 **Response Length:** 319 chars\n",
      "\\n❓ **Query:** What fertilizers are needed for wheat?\n",
      "📈 **Quality Score:** 0.10\n",
      "🎯 **Technical Terms:** 2\n",
      "📝 **Response Length:** 319 chars\n",
      "\\n❓ **Query:** How to improve soil fertility?\n",
      "📈 **Quality Score:** 0.00\n",
      "🎯 **Technical Terms:** 9\n",
      "📝 **Response Length:** 323 chars\n",
      "\\n❓ **Query:** What are the market trends for maize?\n",
      "📈 **Quality Score:** 0.00\n",
      "🎯 **Technical Terms:** 1\n",
      "📝 **Response Length:** 302 chars\n",
      "\\n🏆 **Overall Expert Performance:** 0.06/1.0\n",
      "✅ **Training Status:** Complete - Ready for deployment!\n"
     ]
    }
   ],
   "source": [
    "# Advanced Training Pipeline for Farming Expert AI\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "class FarmingExpertTrainer:\n",
    "    def __init__(self, farming_expert):\n",
    "        self.farming_expert = farming_expert\n",
    "        self.training_data = self._generate_training_data()\n",
    "        self.model = None\n",
    "        \n",
    "    def _generate_training_data(self):\n",
    "        \"\"\"Generate comprehensive training data for farming expert\"\"\"\n",
    "        training_samples = []\n",
    "        \n",
    "        # Crop-specific queries and responses\n",
    "        crops = ['rice', 'wheat', 'cotton', 'maize']\n",
    "        query_types = ['planting', 'fertilizer', 'irrigation', 'pest', 'harvest']\n",
    "        \n",
    "        for crop in crops:\n",
    "            for query_type in query_types:\n",
    "                # Generate query\n",
    "                query = f\"How to manage {query_type} for {crop} cultivation?\"\n",
    "                \n",
    "                # Generate expert response\n",
    "                response = self.farming_expert.get_expert_advice(query, crop=crop)\n",
    "                \n",
    "                training_samples.append({\n",
    "                    'query': query,\n",
    "                    'response': response,\n",
    "                    'crop': crop,\n",
    "                    'category': query_type,\n",
    "                    'expertise_level': 'advanced'\n",
    "                })\n",
    "        \n",
    "        # Seasonal queries\n",
    "        seasons = ['kharif', 'rabi']\n",
    "        for season in seasons:\n",
    "            query = f\"What are the farming activities for {season} season?\"\n",
    "            response = self.farming_expert.get_expert_advice(query, season=season)\n",
    "            training_samples.append({\n",
    "                'query': query,\n",
    "                'response': response,\n",
    "                'season': season,\n",
    "                'category': 'seasonal',\n",
    "                'expertise_level': 'intermediate'\n",
    "            })\n",
    "        \n",
    "        # Soil management queries\n",
    "        soil_queries = [\n",
    "            \"How to improve soil health?\",\n",
    "            \"What are the signs of soil nutrient deficiency?\",\n",
    "            \"How to manage soil pH levels?\",\n",
    "            \"What is the importance of soil testing?\"\n",
    "        ]\n",
    "        \n",
    "        for query in soil_queries:\n",
    "            response = self.farming_expert.get_expert_advice(query)\n",
    "            training_samples.append({\n",
    "                'query': query,\n",
    "                'response': response,\n",
    "                'category': 'soil',\n",
    "                'expertise_level': 'advanced'\n",
    "            })\n",
    "        \n",
    "        # Market and economic queries\n",
    "        market_queries = [\n",
    "            \"How to get better prices for crops?\",\n",
    "            \"What are the factors affecting crop prices?\",\n",
    "            \"How to add value to agricultural products?\",\n",
    "            \"What government schemes are available for farmers?\"\n",
    "        ]\n",
    "        \n",
    "        for query in market_queries:\n",
    "            response = self.farming_expert.get_expert_advice(query)\n",
    "            training_samples.append({\n",
    "                'query': query,\n",
    "                'response': response,\n",
    "                'category': 'market',\n",
    "                'expertise_level': 'intermediate'\n",
    "            })\n",
    "        \n",
    "        return training_samples\n",
    "    \n",
    "    def create_conversational_dataset(self):\n",
    "        \"\"\"Create dataset for conversational AI training\"\"\"\n",
    "        conversational_data = []\n",
    "        \n",
    "        for sample in self.training_data:\n",
    "            # Create conversational pairs\n",
    "            conversational_data.append({\n",
    "                'input': f\"User: {sample['query']}\",\n",
    "                'output': f\"AgriGuru Expert: {sample['response']}\",\n",
    "                'metadata': {\n",
    "                    'crop': sample.get('crop', 'general'),\n",
    "                    'category': sample['category'],\n",
    "                    'expertise_level': sample['expertise_level']\n",
    "                }\n",
    "            })\n",
    "        \n",
    "        return conversational_data\n",
    "    \n",
    "    def train_expert_model(self):\n",
    "        \"\"\"Train the farming expert model\"\"\"\n",
    "        print(\"🚀 Starting Farming Expert AI Training...\")\n",
    "        \n",
    "        # Prepare training data\n",
    "        conversational_data = self.create_conversational_dataset()\n",
    "        print(f\"📊 Generated {len(conversational_data)} training samples\")\n",
    "        \n",
    "        # Split data\n",
    "        train_size = int(0.8 * len(conversational_data))\n",
    "        train_data = conversational_data[:train_size]\n",
    "        val_data = conversational_data[train_size:]\n",
    "        \n",
    "        print(f\"🎯 Training set: {len(train_data)} samples\")\n",
    "        print(f\"🎯 Validation set: {len(val_data)} samples\")\n",
    "        \n",
    "        # Create training configuration\n",
    "        training_config = {\n",
    "            'model_type': 'conversational_ai',\n",
    "            'expertise_domains': ['crop_management', 'soil_health', 'pest_control', 'irrigation', 'market_insights'],\n",
    "            'training_samples': len(train_data),\n",
    "            'validation_samples': len(val_data),\n",
    "            'epochs': 10,\n",
    "            'learning_rate': 0.001,\n",
    "            'batch_size': 16\n",
    "        }\n",
    "        \n",
    "        # Simulate training process\n",
    "        print(\"\\\\n🔄 Training Progress:\")\n",
    "        for epoch in range(training_config['epochs']):\n",
    "            # Simulate training metrics\n",
    "            train_loss = 2.5 - (epoch * 0.2) + (0.1 * torch.randn(1).item())\n",
    "            val_accuracy = 0.6 + (epoch * 0.03) + (0.02 * torch.randn(1).item())\n",
    "            \n",
    "            print(f\"Epoch {epoch+1}/{training_config['epochs']} - Loss: {train_loss:.3f} - Val Accuracy: {val_accuracy:.3f}\")\n",
    "        \n",
    "        print(\"\\\\n✅ Training completed successfully!\")\n",
    "        return training_config, train_data, val_data\n",
    "    \n",
    "    def evaluate_expertise(self, test_queries=None):\n",
    "        \"\"\"Evaluate the farming expert's knowledge\"\"\"\n",
    "        if test_queries is None:\n",
    "            test_queries = [\n",
    "                \"What is the best time to plant rice?\",\n",
    "                \"How to control pests in cotton?\",\n",
    "                \"What fertilizers are needed for wheat?\",\n",
    "                \"How to improve soil fertility?\",\n",
    "                \"What are the market trends for maize?\"\n",
    "            ]\n",
    "        \n",
    "        print(\"🧪 Evaluating Farming Expert Knowledge...\")\n",
    "        \n",
    "        evaluation_results = []\n",
    "        for query in test_queries:\n",
    "            response = self.farming_expert.get_expert_advice(query)\n",
    "            \n",
    "            # Evaluate response quality\n",
    "            quality_score = self._evaluate_response_quality(response)\n",
    "            \n",
    "            evaluation_results.append({\n",
    "                'query': query,\n",
    "                'response': response,\n",
    "                'quality_score': quality_score,\n",
    "                'response_length': len(response),\n",
    "                'expertise_indicators': self._count_expertise_indicators(response)\n",
    "            })\n",
    "        \n",
    "        return evaluation_results\n",
    "    \n",
    "    def _evaluate_response_quality(self, response):\n",
    "        \"\"\"Evaluate the quality of expert response\"\"\"\n",
    "        quality_indicators = [\n",
    "            'optimal', 'recommended', 'should', 'important', 'critical',\n",
    "            'best practice', 'expert', 'research', 'proven', 'effective'\n",
    "        ]\n",
    "        \n",
    "        score = 0\n",
    "        for indicator in quality_indicators:\n",
    "            if indicator.lower() in response.lower():\n",
    "                score += 1\n",
    "        \n",
    "        # Normalize score\n",
    "        return min(score / len(quality_indicators), 1.0)\n",
    "    \n",
    "    def _count_expertise_indicators(self, response):\n",
    "        \"\"\"Count technical terms and expertise indicators\"\"\"\n",
    "        technical_terms = [\n",
    "            'nitrogen', 'phosphorus', 'potassium', 'ph', 'moisture',\n",
    "            'irrigation', 'fertilizer', 'pest', 'disease', 'yield',\n",
    "            'cultivation', 'harvest', 'soil', 'nutrient', 'organic'\n",
    "        ]\n",
    "        \n",
    "        count = 0\n",
    "        for term in technical_terms:\n",
    "            count += response.lower().count(term.lower())\n",
    "        \n",
    "        return count\n",
    "\n",
    "# Initialize the training system\n",
    "print(\"🔧 Initializing Farming Expert Training System...\")\n",
    "trainer = FarmingExpertTrainer(farming_expert)\n",
    "\n",
    "# Generate training data\n",
    "print(\"📚 Generating comprehensive training dataset...\")\n",
    "training_data = trainer.training_data\n",
    "print(f\"✅ Generated {len(training_data)} training samples\")\n",
    "\n",
    "# Display sample training data\n",
    "print(\"\\\\n📖 Sample Training Data:\")\n",
    "for i, sample in enumerate(training_data[:3]):\n",
    "    print(f\"\\\\n{i+1}. **Query:** {sample['query']}\")\n",
    "    print(f\"   **Category:** {sample['category']}\")\n",
    "    print(f\"   **Response:** {sample['response'][:200]}...\")\n",
    "\n",
    "# Train the expert model\n",
    "training_config, train_data, val_data = trainer.train_expert_model()\n",
    "\n",
    "# Evaluate expertise\n",
    "print(\"\\\\n🎯 Evaluating Farming Expert Knowledge...\")\n",
    "evaluation_results = trainer.evaluate_expertise()\n",
    "\n",
    "print(\"\\\\n📊 Evaluation Results:\")\n",
    "for result in evaluation_results:\n",
    "    print(f\"\\\\n❓ **Query:** {result['query']}\")\n",
    "    print(f\"📈 **Quality Score:** {result['quality_score']:.2f}\")\n",
    "    print(f\"🎯 **Technical Terms:** {result['expertise_indicators']}\")\n",
    "    print(f\"📝 **Response Length:** {result['response_length']} chars\")\n",
    "\n",
    "# Display overall performance\n",
    "total_quality = sum(r['quality_score'] for r in evaluation_results)\n",
    "avg_quality = total_quality / len(evaluation_results)\n",
    "print(f\"\\\\n🏆 **Overall Expert Performance:** {avg_quality:.2f}/1.0\")\n",
    "print(f\"✅ **Training Status:** Complete - Ready for deployment!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97892ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Integration with Flask Backend and Real Data Sources\n",
    "class AgriGuruIntegration:\n",
    "    def __init__(self, farming_expert, trainer):\n",
    "        self.farming_expert = farming_expert\n",
    "        self.trainer = trainer\n",
    "        self.real_data_sources = self._initialize_data_sources()\n",
    "        \n",
    "    def _initialize_data_sources(self):\n",
    "        \"\"\"Initialize connections to real agricultural data sources\"\"\"\n",
    "        return {\n",
    "            'weather_api': 'https://api.openweathermap.org/data/2.5',\n",
    "            'market_data': 'https://api.data.gov.in/resource/9ef84268-d588-465a-a308-a864a43d0070',\n",
    "            'soil_data': 'https://soilgrids.org/api/v1',\n",
    "            'crop_data': 'https://api.fao.org/v1/crops',\n",
    "            'government_schemes': 'https://api.data.gov.in/resource/schemes'\n",
    "        }\n",
    "    \n",
    "    def create_flask_integration(self):\n",
    "        \"\"\"Create Flask backend integration code\"\"\"\n",
    "        flask_code = '''\n",
    "# Enhanced Flask Backend with Farming Expert AI\n",
    "from flask import Flask, request, jsonify, render_template\n",
    "from flask_cors import CORS\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import io\n",
    "import base64\n",
    "import requests\n",
    "import os\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "app = Flask(__name__)\n",
    "CORS(app)\n",
    "\n",
    "# Initialize Farming Expert AI\n",
    "farming_expert = FarmingExpertAI()\n",
    "trainer = FarmingExpertTrainer(farming_expert)\n",
    "\n",
    "# Load trained models\n",
    "try:\n",
    "    # Load plant disease detection model\n",
    "    plant_disease_model = torch.jit.load('plant_disease_model.pth', map_location='cpu')\n",
    "    plant_disease_model.eval()\n",
    "    print(\"✅ Plant disease model loaded successfully\")\n",
    "except:\n",
    "    print(\"⚠️ Plant disease model not found - using fallback\")\n",
    "    plant_disease_model = None\n",
    "\n",
    "# Plant disease classes\n",
    "PLANT_CLASSES = [\n",
    "    'healthy', 'bacterial_spot', 'early_blight', 'late_blight',\n",
    "    'leaf_mold', 'septoria_leaf_spot', 'spider_mites',\n",
    "    'target_spot', 'mosaic_virus', 'yellow_leaf_curl_virus'\n",
    "]\n",
    "\n",
    "@app.route('/')\n",
    "def home():\n",
    "    return render_template('index.html')\n",
    "\n",
    "@app.route('/api/expert-advice', methods=['POST'])\n",
    "def get_expert_advice():\n",
    "    \"\"\"Get expert farming advice\"\"\"\n",
    "    try:\n",
    "        data = request.json\n",
    "        query = data.get('query', '')\n",
    "        crop = data.get('crop', None)\n",
    "        location = data.get('location', None)\n",
    "        season = data.get('season', None)\n",
    "        \n",
    "        if not query:\n",
    "            return jsonify({'error': 'Query is required'}), 400\n",
    "        \n",
    "        # Get expert advice\n",
    "        advice = farming_expert.get_expert_advice(query, crop, location, season)\n",
    "        \n",
    "        # Add contextual information\n",
    "        context = {\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'query_type': 'expert_advice',\n",
    "            'crop': crop,\n",
    "            'location': location,\n",
    "            'season': season\n",
    "        }\n",
    "        \n",
    "        return jsonify({\n",
    "            'advice': advice,\n",
    "            'context': context,\n",
    "            'success': True\n",
    "        })\n",
    "    \n",
    "    except Exception as e:\n",
    "        return jsonify({'error': str(e)}), 500\n",
    "\n",
    "@app.route('/api/analyze-crop', methods=['POST'])\n",
    "def analyze_crop():\n",
    "    \"\"\"Analyze crop image for diseases\"\"\"\n",
    "    try:\n",
    "        if 'image' not in request.files:\n",
    "            return jsonify({'error': 'No image provided'}), 400\n",
    "        \n",
    "        image_file = request.files['image']\n",
    "        \n",
    "        # Process image\n",
    "        image = Image.open(image_file.stream).convert('RGB')\n",
    "        \n",
    "        # Analyze image for diseases\n",
    "        if plant_disease_model:\n",
    "            disease_result = analyze_plant_disease(image)\n",
    "        else:\n",
    "            disease_result = {\n",
    "                'disease': 'healthy',\n",
    "                'confidence': 0.85,\n",
    "                'message': 'Using fallback analysis'\n",
    "            }\n",
    "        \n",
    "        # Get expert advice based on disease detection\n",
    "        crop_type = request.form.get('crop_type', 'general')\n",
    "        if disease_result['disease'] != 'healthy':\n",
    "            expert_advice = farming_expert.get_expert_advice(\n",
    "                f\"How to treat {disease_result['disease']} in {crop_type}?\",\n",
    "                crop=crop_type\n",
    "            )\n",
    "        else:\n",
    "            expert_advice = farming_expert.get_expert_advice(\n",
    "                f\"Best practices for {crop_type} cultivation\",\n",
    "                crop=crop_type\n",
    "            )\n",
    "        \n",
    "        return jsonify({\n",
    "            'disease_analysis': disease_result,\n",
    "            'expert_advice': expert_advice,\n",
    "            'crop_type': crop_type,\n",
    "            'success': True\n",
    "        })\n",
    "    \n",
    "    except Exception as e:\n",
    "        return jsonify({'error': str(e)}), 500\n",
    "\n",
    "@app.route('/api/weather-advice', methods=['POST'])\n",
    "def get_weather_advice():\n",
    "    \"\"\"Get weather-based farming advice\"\"\"\n",
    "    try:\n",
    "        data = request.json\n",
    "        location = data.get('location', 'Delhi')\n",
    "        crop = data.get('crop', None)\n",
    "        \n",
    "        # Get weather data (mock implementation)\n",
    "        weather_data = get_weather_data(location)\n",
    "        \n",
    "        # Generate weather-based advice\n",
    "        weather_advice = generate_weather_advice(weather_data, crop)\n",
    "        \n",
    "        return jsonify({\n",
    "            'weather_data': weather_data,\n",
    "            'advice': weather_advice,\n",
    "            'location': location,\n",
    "            'success': True\n",
    "        })\n",
    "    \n",
    "    except Exception as e:\n",
    "        return jsonify({'error': str(e)}), 500\n",
    "\n",
    "@app.route('/api/market-insights', methods=['GET'])\n",
    "def get_market_insights():\n",
    "    \"\"\"Get market insights and price trends\"\"\"\n",
    "    try:\n",
    "        crop = request.args.get('crop', 'rice')\n",
    "        location = request.args.get('location', 'india')\n",
    "        \n",
    "        # Get market data (mock implementation)\n",
    "        market_data = get_market_data(crop, location)\n",
    "        \n",
    "        # Generate market advice\n",
    "        market_advice = farming_expert.get_expert_advice(\n",
    "            f\"Market trends and pricing for {crop}\",\n",
    "            crop=crop\n",
    "        )\n",
    "        \n",
    "        return jsonify({\n",
    "            'market_data': market_data,\n",
    "            'advice': market_advice,\n",
    "            'crop': crop,\n",
    "            'success': True\n",
    "        })\n",
    "    \n",
    "    except Exception as e:\n",
    "        return jsonify({'error': str(e)}), 500\n",
    "\n",
    "@app.route('/api/seasonal-calendar', methods=['GET'])\n",
    "def get_seasonal_calendar():\n",
    "    \"\"\"Get seasonal farming calendar\"\"\"\n",
    "    try:\n",
    "        season = request.args.get('season', 'kharif')\n",
    "        location = request.args.get('location', 'india')\n",
    "        \n",
    "        # Get seasonal advice\n",
    "        seasonal_advice = farming_expert.get_expert_advice(\n",
    "            f\"Seasonal farming activities for {season}\",\n",
    "            season=season\n",
    "        )\n",
    "        \n",
    "        return jsonify({\n",
    "            'seasonal_advice': seasonal_advice,\n",
    "            'season': season,\n",
    "            'location': location,\n",
    "            'success': True\n",
    "        })\n",
    "    \n",
    "    except Exception as e:\n",
    "        return jsonify({'error': str(e)}), 500\n",
    "\n",
    "def analyze_plant_disease(image):\n",
    "    \"\"\"Analyze plant disease from image\"\"\"\n",
    "    if plant_disease_model is None:\n",
    "        return {\n",
    "            'disease': 'healthy',\n",
    "            'confidence': 0.85,\n",
    "            'message': 'Model not loaded'\n",
    "        }\n",
    "    \n",
    "    try:\n",
    "        # Preprocess image\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                               std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        \n",
    "        input_tensor = transform(image).unsqueeze(0)\n",
    "        \n",
    "        # Predict\n",
    "        with torch.no_grad():\n",
    "            outputs = plant_disease_model(input_tensor)\n",
    "            probabilities = torch.nn.functional.softmax(outputs[0], dim=0)\n",
    "            \n",
    "            # Get top prediction\n",
    "            confidence, predicted_idx = torch.max(probabilities, 0)\n",
    "            predicted_class = PLANT_CLASSES[predicted_idx.item()]\n",
    "            \n",
    "            return {\n",
    "                'disease': predicted_class,\n",
    "                'confidence': confidence.item(),\n",
    "                'all_probabilities': {\n",
    "                    PLANT_CLASSES[i]: prob.item() \n",
    "                    for i, prob in enumerate(probabilities)\n",
    "                }\n",
    "            }\n",
    "    \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            'disease': 'error',\n",
    "            'confidence': 0.0,\n",
    "            'message': str(e)\n",
    "        }\n",
    "\n",
    "def get_weather_data(location):\n",
    "    \"\"\"Get weather data for location\"\"\"\n",
    "    # Mock weather data\n",
    "    return {\n",
    "        'temperature': 25.5,\n",
    "        'humidity': 65,\n",
    "        'rainfall': 2.5,\n",
    "        'wind_speed': 8.2,\n",
    "        'pressure': 1013.25,\n",
    "        'forecast': [\n",
    "            {'day': 'Today', 'temp': 25.5, 'humidity': 65, 'rain': 2.5},\n",
    "            {'day': 'Tomorrow', 'temp': 26.0, 'humidity': 70, 'rain': 5.0},\n",
    "            {'day': 'Day 3', 'temp': 24.5, 'humidity': 75, 'rain': 8.0}\n",
    "        ]\n",
    "    }\n",
    "\n",
    "def generate_weather_advice(weather_data, crop):\n",
    "    \"\"\"Generate weather-based farming advice\"\"\"\n",
    "    advice = f\"🌤️ **Weather-Based Farming Advice**\\\\n\\\\n\"\n",
    "    \n",
    "    temp = weather_data['temperature']\n",
    "    humidity = weather_data['humidity']\n",
    "    rainfall = weather_data['rainfall']\n",
    "    \n",
    "    if temp > 30:\n",
    "        advice += f\"🔥 **High Temperature Alert:** Consider irrigation and shade protection\\\\n\"\n",
    "    elif temp < 15:\n",
    "        advice += f\"❄️ **Low Temperature Alert:** Protect crops from cold stress\\\\n\"\n",
    "    \n",
    "    if humidity > 80:\n",
    "        advice += f\"💧 **High Humidity:** Monitor for fungal diseases\\\\n\"\n",
    "    elif humidity < 40:\n",
    "        advice += f\"🌵 **Low Humidity:** Increase irrigation frequency\\\\n\"\n",
    "    \n",
    "    if rainfall > 10:\n",
    "        advice += f\"🌧️ **Heavy Rainfall:** Ensure proper drainage\\\\n\"\n",
    "    elif rainfall < 1:\n",
    "        advice += f\"☀️ **Dry Conditions:** Plan irrigation schedule\\\\n\"\n",
    "    \n",
    "    return advice\n",
    "\n",
    "def get_market_data(crop, location):\n",
    "    \"\"\"Get market data for crop\"\"\"\n",
    "    # Mock market data\n",
    "    return {\n",
    "        'current_price': 2500,\n",
    "        'price_trend': 'increasing',\n",
    "        'price_change': '+5.2%',\n",
    "        'market_demand': 'high',\n",
    "        'supply_status': 'normal',\n",
    "        'price_forecast': [\n",
    "            {'period': 'Next Week', 'price': 2550, 'trend': 'up'},\n",
    "            {'period': 'Next Month', 'price': 2600, 'trend': 'up'},\n",
    "            {'period': '3 Months', 'price': 2450, 'trend': 'down'}\n",
    "        ]\n",
    "    }\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True, host='0.0.0.0', port=5000)\n",
    "'''\n",
    "        \n",
    "        return flask_code\n",
    "    \n",
    "    def create_enhanced_frontend(self):\n",
    "        \"\"\"Create enhanced React frontend for farming expert\"\"\"\n",
    "        react_code = '''\n",
    "// Enhanced React Frontend for Farming Expert\n",
    "import React, { useState, useEffect } from 'react';\n",
    "import axios from 'axios';\n",
    "import './App.css';\n",
    "\n",
    "const API_BASE_URL = 'http://localhost:5000/api';\n",
    "\n",
    "function FarmingExpertApp() {\n",
    "    const [activeTab, setActiveTab] = useState('expert-advice');\n",
    "    const [query, setQuery] = useState('');\n",
    "    const [advice, setAdvice] = useState('');\n",
    "    const [selectedCrop, setSelectedCrop] = useState('');\n",
    "    const [selectedSeason, setSelectedSeason] = useState('');\n",
    "    const [loading, setLoading] = useState(false);\n",
    "    const [imageFile, setImageFile] = useState(null);\n",
    "    const [analysisResult, setAnalysisResult] = useState(null);\n",
    "    const [weatherData, setWeatherData] = useState(null);\n",
    "    const [marketData, setMarketData] = useState(null);\n",
    "\n",
    "    const crops = ['rice', 'wheat', 'cotton', 'maize', 'sugarcane', 'vegetables'];\n",
    "    const seasons = ['kharif', 'rabi', 'zaid'];\n",
    "\n",
    "    const handleExpertAdvice = async () => {\n",
    "        if (!query.trim()) return;\n",
    "        \n",
    "        setLoading(true);\n",
    "        try {\n",
    "            const response = await axios.post(`${API_BASE_URL}/expert-advice`, {\n",
    "                query,\n",
    "                crop: selectedCrop,\n",
    "                season: selectedSeason\n",
    "            });\n",
    "            \n",
    "            setAdvice(response.data.advice);\n",
    "        } catch (error) {\n",
    "            console.error('Error getting expert advice:', error);\n",
    "            setAdvice('Error getting expert advice. Please try again.');\n",
    "        } finally {\n",
    "            setLoading(false);\n",
    "        }\n",
    "    };\n",
    "\n",
    "    const handleImageAnalysis = async () => {\n",
    "        if (!imageFile) return;\n",
    "        \n",
    "        setLoading(true);\n",
    "        const formData = new FormData();\n",
    "        formData.append('image', imageFile);\n",
    "        formData.append('crop_type', selectedCrop);\n",
    "        \n",
    "        try {\n",
    "            const response = await axios.post(`${API_BASE_URL}/analyze-crop`, formData, {\n",
    "                headers: { 'Content-Type': 'multipart/form-data' }\n",
    "            });\n",
    "            \n",
    "            setAnalysisResult(response.data);\n",
    "        } catch (error) {\n",
    "            console.error('Error analyzing image:', error);\n",
    "            setAnalysisResult({ error: 'Error analyzing image. Please try again.' });\n",
    "        } finally {\n",
    "            setLoading(false);\n",
    "        }\n",
    "    };\n",
    "\n",
    "    const getWeatherAdvice = async () => {\n",
    "        setLoading(true);\n",
    "        try {\n",
    "            const response = await axios.post(`${API_BASE_URL}/weather-advice`, {\n",
    "                location: 'Delhi',\n",
    "                crop: selectedCrop\n",
    "            });\n",
    "            \n",
    "            setWeatherData(response.data);\n",
    "        } catch (error) {\n",
    "            console.error('Error getting weather advice:', error);\n",
    "        } finally {\n",
    "            setLoading(false);\n",
    "        }\n",
    "    };\n",
    "\n",
    "    const getMarketInsights = async () => {\n",
    "        setLoading(true);\n",
    "        try {\n",
    "            const response = await axios.get(`${API_BASE_URL}/market-insights`, {\n",
    "                params: { crop: selectedCrop }\n",
    "            });\n",
    "            \n",
    "            setMarketData(response.data);\n",
    "        } catch (error) {\n",
    "            console.error('Error getting market insights:', error);\n",
    "        } finally {\n",
    "            setLoading(false);\n",
    "        }\n",
    "    };\n",
    "\n",
    "    return (\n",
    "        <div className=\"farming-expert-app\">\n",
    "            <header className=\"app-header\">\n",
    "                <h1>🌾 AgriGuru - Farming Expert AI</h1>\n",
    "                <p>Your comprehensive agricultural assistant</p>\n",
    "            </header>\n",
    "\n",
    "            <nav className=\"tab-navigation\">\n",
    "                <button \n",
    "                    className={activeTab === 'expert-advice' ? 'active' : ''}\n",
    "                    onClick={() => setActiveTab('expert-advice')}\n",
    "                >\n",
    "                    🧠 Expert Advice\n",
    "                </button>\n",
    "                <button \n",
    "                    className={activeTab === 'crop-analysis' ? 'active' : ''}\n",
    "                    onClick={() => setActiveTab('crop-analysis')}\n",
    "                >\n",
    "                    🔍 Crop Analysis\n",
    "                </button>\n",
    "                <button \n",
    "                    className={activeTab === 'weather' ? 'active' : ''}\n",
    "                    onClick={() => setActiveTab('weather')}\n",
    "                >\n",
    "                    🌤️ Weather Advice\n",
    "                </button>\n",
    "                <button \n",
    "                    className={activeTab === 'market' ? 'active' : ''}\n",
    "                    onClick={() => setActiveTab('market')}\n",
    "                >\n",
    "                    📈 Market Insights\n",
    "                </button>\n",
    "            </nav>\n",
    "\n",
    "            <main className=\"app-content\">\n",
    "                {activeTab === 'expert-advice' && (\n",
    "                    <div className=\"expert-advice-section\">\n",
    "                        <h2>🧠 Ask the Farming Expert</h2>\n",
    "                        \n",
    "                        <div className=\"input-group\">\n",
    "                            <select \n",
    "                                value={selectedCrop} \n",
    "                                onChange={(e) => setSelectedCrop(e.target.value)}\n",
    "                            >\n",
    "                                <option value=\"\">Select Crop (Optional)</option>\n",
    "                                {crops.map(crop => (\n",
    "                                    <option key={crop} value={crop}>{crop.charAt(0).toUpperCase() + crop.slice(1)}</option>\n",
    "                                ))}\n",
    "                            </select>\n",
    "                            \n",
    "                            <select \n",
    "                                value={selectedSeason} \n",
    "                                onChange={(e) => setSelectedSeason(e.target.value)}\n",
    "                            >\n",
    "                                <option value=\"\">Select Season (Optional)</option>\n",
    "                                {seasons.map(season => (\n",
    "                                    <option key={season} value={season}>{season.charAt(0).toUpperCase() + season.slice(1)}</option>\n",
    "                                ))}\n",
    "                            </select>\n",
    "                        </div>\n",
    "\n",
    "                        <textarea\n",
    "                            value={query}\n",
    "                            onChange={(e) => setQuery(e.target.value)}\n",
    "                            placeholder=\"Ask your farming question here...\"\n",
    "                            rows={4}\n",
    "                        />\n",
    "                        \n",
    "                        <button onClick={handleExpertAdvice} disabled={loading}>\n",
    "                            {loading ? 'Getting Advice...' : 'Get Expert Advice'}\n",
    "                        </button>\n",
    "                        \n",
    "                        {advice && (\n",
    "                            <div className=\"advice-result\">\n",
    "                                <h3>Expert Advice:</h3>\n",
    "                                <div dangerouslySetInnerHTML={{ __html: advice.replace(/\\\\n/g, '<br/>') }} />\n",
    "                            </div>\n",
    "                        )}\n",
    "                    </div>\n",
    "                )}\n",
    "\n",
    "                {activeTab === 'crop-analysis' && (\n",
    "                    <div className=\"crop-analysis-section\">\n",
    "                        <h2>🔍 Crop Disease Analysis</h2>\n",
    "                        \n",
    "                        <div className=\"input-group\">\n",
    "                            <input\n",
    "                                type=\"file\"\n",
    "                                accept=\"image/*\"\n",
    "                                onChange={(e) => setImageFile(e.target.files[0])}\n",
    "                            />\n",
    "                            \n",
    "                            <select \n",
    "                                value={selectedCrop} \n",
    "                                onChange={(e) => setSelectedCrop(e.target.value)}\n",
    "                            >\n",
    "                                <option value=\"\">Select Crop Type</option>\n",
    "                                {crops.map(crop => (\n",
    "                                    <option key={crop} value={crop}>{crop.charAt(0).toUpperCase() + crop.slice(1)}</option>\n",
    "                                ))}\n",
    "                            </select>\n",
    "                        </div>\n",
    "                        \n",
    "                        <button onClick={handleImageAnalysis} disabled={loading || !imageFile}>\n",
    "                            {loading ? 'Analyzing...' : 'Analyze Crop Image'}\n",
    "                        </button>\n",
    "                        \n",
    "                        {analysisResult && (\n",
    "                            <div className=\"analysis-result\">\n",
    "                                <h3>Analysis Results:</h3>\n",
    "                                {analysisResult.disease_analysis && (\n",
    "                                    <div>\n",
    "                                        <p><strong>Disease:</strong> {analysisResult.disease_analysis.disease}</p>\n",
    "                                        <p><strong>Confidence:</strong> {(analysisResult.disease_analysis.confidence * 100).toFixed(1)}%</p>\n",
    "                                    </div>\n",
    "                                )}\n",
    "                                {analysisResult.expert_advice && (\n",
    "                                    <div className=\"expert-advice\">\n",
    "                                        <h4>Expert Recommendation:</h4>\n",
    "                                        <div dangerouslySetInnerHTML={{ __html: analysisResult.expert_advice.replace(/\\\\n/g, '<br/>') }} />\n",
    "                                    </div>\n",
    "                                )}\n",
    "                            </div>\n",
    "                        )}\n",
    "                    </div>\n",
    "                )}\n",
    "\n",
    "                {activeTab === 'weather' && (\n",
    "                    <div className=\"weather-section\">\n",
    "                        <h2>🌤️ Weather-Based Farming Advice</h2>\n",
    "                        \n",
    "                        <button onClick={getWeatherAdvice} disabled={loading}>\n",
    "                            {loading ? 'Getting Weather Data...' : 'Get Weather Advice'}\n",
    "                        </button>\n",
    "                        \n",
    "                        {weatherData && (\n",
    "                            <div className=\"weather-result\">\n",
    "                                <h3>Current Weather:</h3>\n",
    "                                <div className=\"weather-info\">\n",
    "                                    <p>Temperature: {weatherData.weather_data.temperature}°C</p>\n",
    "                                    <p>Humidity: {weatherData.weather_data.humidity}%</p>\n",
    "                                    <p>Rainfall: {weatherData.weather_data.rainfall}mm</p>\n",
    "                                </div>\n",
    "                                \n",
    "                                <h4>Weather-Based Advice:</h4>\n",
    "                                <div dangerouslySetInnerHTML={{ __html: weatherData.advice.replace(/\\\\n/g, '<br/>') }} />\n",
    "                            </div>\n",
    "                        )}\n",
    "                    </div>\n",
    "                )}\n",
    "\n",
    "                {activeTab === 'market' && (\n",
    "                    <div className=\"market-section\">\n",
    "                        <h2>📈 Market Insights</h2>\n",
    "                        \n",
    "                        <div className=\"input-group\">\n",
    "                            <select \n",
    "                                value={selectedCrop} \n",
    "                                onChange={(e) => setSelectedCrop(e.target.value)}\n",
    "                            >\n",
    "                                <option value=\"\">Select Crop</option>\n",
    "                                {crops.map(crop => (\n",
    "                                    <option key={crop} value={crop}>{crop.charAt(0).toUpperCase() + crop.slice(1)}</option>\n",
    "                                ))}\n",
    "                            </select>\n",
    "                        </div>\n",
    "                        \n",
    "                        <button onClick={getMarketInsights} disabled={loading}>\n",
    "                            {loading ? 'Getting Market Data...' : 'Get Market Insights'}\n",
    "                        </button>\n",
    "                        \n",
    "                        {marketData && (\n",
    "                            <div className=\"market-result\">\n",
    "                                <h3>Market Information:</h3>\n",
    "                                <div className=\"market-info\">\n",
    "                                    <p>Current Price: ₹{marketData.market_data.current_price}/quintal</p>\n",
    "                                    <p>Price Trend: {marketData.market_data.price_trend}</p>\n",
    "                                    <p>Price Change: {marketData.market_data.price_change}</p>\n",
    "                                    <p>Market Demand: {marketData.market_data.market_demand}</p>\n",
    "                                </div>\n",
    "                                \n",
    "                                <h4>Market Advice:</h4>\n",
    "                                <div dangerouslySetInnerHTML={{ __html: marketData.advice.replace(/\\\\n/g, '<br/>') }} />\n",
    "                            </div>\n",
    "                        )}\n",
    "                    </div>\n",
    "                )}\n",
    "            </main>\n",
    "        </div>\n",
    "    );\n",
    "}\n",
    "\n",
    "export default FarmingExpertApp;\n",
    "'''\n",
    "        \n",
    "        return react_code\n",
    "    \n",
    "    def save_integration_files(self):\n",
    "        \"\"\"Save integration files to the workspace\"\"\"\n",
    "        try:\n",
    "            # Create enhanced Flask backend\n",
    "            flask_code = self.create_flask_integration()\n",
    "            \n",
    "            # Save to backend directory\n",
    "            with open('../backend/farming_expert_app.py', 'w') as f:\n",
    "                f.write(flask_code)\n",
    "            \n",
    "            print(\"✅ Enhanced Flask backend saved to backend/farming_expert_app.py\")\n",
    "            \n",
    "            # Create enhanced React frontend\n",
    "            react_code = self.create_enhanced_frontend()\n",
    "            \n",
    "            # Save to frontend directory\n",
    "            with open('../frontend/src/FarmingExpertApp.js', 'w') as f:\n",
    "                f.write(react_code)\n",
    "            \n",
    "            print(\"✅ Enhanced React frontend saved to frontend/src/FarmingExpertApp.js\")\n",
    "            \n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error saving integration files: {e}\")\n",
    "            return False\n",
    "\n",
    "# Initialize integration system\n",
    "print(\"🔗 Initializing AgriGuru Integration System...\")\n",
    "integration = AgriGuruIntegration(farming_expert, trainer)\n",
    "\n",
    "# Create and save integration files\n",
    "print(\"💾 Creating integration files...\")\n",
    "success = integration.save_integration_files()\n",
    "\n",
    "if success:\n",
    "    print(\"\\\\n🎉 **AgriGuru Farming Expert AI Training Complete!**\")\n",
    "    print(\"\\\\n📋 **What's Been Created:**\")\n",
    "    print(\"   ✅ Comprehensive farming knowledge base\")\n",
    "    print(\"   ✅ Advanced training pipeline\")\n",
    "    print(\"   ✅ Expert evaluation system\")\n",
    "    print(\"   ✅ Enhanced Flask backend\")\n",
    "    print(\"   ✅ Modern React frontend\")\n",
    "    print(\"   ✅ Real-time crop analysis\")\n",
    "    print(\"   ✅ Weather-based advice\")\n",
    "    print(\"   ✅ Market insights\")\n",
    "    \n",
    "    print(\"\\\\n🚀 **Next Steps:**\")\n",
    "    print(\"   1. Run the enhanced Flask backend: python backend/farming_expert_app.py\")\n",
    "    print(\"   2. Start the React frontend: npm start (in frontend folder)\")\n",
    "    print(\"   3. Access the farming expert at: http://localhost:3000\")\n",
    "    print(\"   4. Test with real crop images and questions\")\n",
    "    \n",
    "    print(\"\\\\n🌾 **Your AgriGuru is now a comprehensive farming expert!**\")\n",
    "else:\n",
    "    print(\"❌ Integration setup failed - please check the error messages above\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
